{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lighthouse Labs\n",
    "### W04D04 Optimization\n",
    "Instructor: Socorro Dominguez  \n",
    "January 28, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**AGENDA:**\n",
    "- Issues and Challenges in ML\n",
    "    - Bias in ML\n",
    "- Optimization\n",
    "    - Gradient Descent\n",
    "    - Stochastic Gradient Descent\n",
    "- (Time Permitting 5 min Break)\n",
    "\n",
    "- Regularization\n",
    "    - L1 Regularization\n",
    "    - L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Issues and Challenges in AI\n",
    "\n",
    "What do you think are the most Common Issues that AI poses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have all seen what ML can do to improve our lives. Even now, we trust algorithms and data more than our logic and judgement.\n",
    "\n",
    "However, many times, we fail to see what the limitations are. \n",
    "\n",
    "Remember the last time your GPS asked you to fly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Ethics\n",
    "\n",
    "> We have given lots of data blindly. People use LinkedIn or Dating Sites and answer from the most innocent to the most awkward questions. \n",
    ">\n",
    "> Most of the people don't realize that once they've answered the questions, their data becomes public. \n",
    ">\n",
    "> Optional Readings/Videos:\n",
    ">\n",
    "> [The OK Cupid Case](https://www.forbes.com/sites/emmawoollacott/2016/05/13/intimate-data-of-70000-okcupid-users-released/#af9d9301e15d)  \n",
    "> [Show Me Your Data and I'll Tell You Who You Are\" by Sandra Wachter](https://www.youtube.com/watch?v=YYb1Dtc1B40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. Deterministic Problems\n",
    "\n",
    "> ML is incredibly powerful for sensors and can be used to help calibrate sensors measuring environmental variables (temperature, pressure, and humidity). \n",
    ">\n",
    "> There are currently deterministic models that work fine in order to predict tomorrow's weather. Using an ML model could be possible too. However, the computational cost would be too expensive since ML is stochastic, not deterministic.\n",
    ">\n",
    "> Furthermore ML does not understand physical constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. Data\n",
    "\n",
    "> Lack of Data or Bad Data can bias against a group of people.\n",
    ">\n",
    "> Examples include mamography tests - when females of black heritage were not represented on the dataset making predictions regarding breast cancer not accurate for them.\n",
    ">\n",
    "> When transgender individuals are not represented in voice software, they get outed by applications.\n",
    ">\n",
    "> Optional Readings:  \n",
    "> [Dynamic\n",
    "Sound\n",
    "Identification - Princeton Case Study](https://aiethics.princeton.edu/wp-content/uploads/sites/587/2018/10/Princeton-AI-Ethics-Case-Study-2.pdf)  \n",
    "[Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4. Interpretability\n",
    "\n",
    "> One of the primary problems with ML. An AI consultancy firm trying to pitch to a firm that only uses traditional statistical methods can be stopped dead if they do not see the model as interpretable. \n",
    "Sometimes, a recommendations system can't be explained in business terms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Be wary when calling models “Artificial Intelligence”. They don’t think, they find patterns in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimization\n",
    "\n",
    "What is an Optimization Algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Review of Loss and Loss Function*\n",
    "* In the context of an optimization algorithm, the function used to evaluate a candidate solution (a set of weights) is referred to as the objective function.\n",
    "\n",
    "* The objective function is also called: cost function or loss function.  \n",
    "* The value calculated by the loss function is referred to as “loss”.\n",
    "\n",
    "* We may seek to maximize or minimize the objective function, meaning that we are searching for a candidate solution that has the highest or lowest score respectively.\n",
    "    * By convention, MOST optimization algorithms are concerned with minimization. \n",
    "    * If we ever need to maximize an objective there is a simple solution: just flip the sign on the objective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](img/0_gd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**A way to think a ML process:**  \n",
    "We can start to think of (a lot of) ML as a 3-step process:\n",
    "\n",
    "* Choose your model\n",
    "* Choose your loss function\n",
    "* Choose your optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* The model controls the space of possible functions from $X$ to $y$.\n",
    "    * e.g., a linear model can only learn linear functions.\n",
    "\n",
    "* The loss function tells us how to compare these various functions.\n",
    "    * e.g. , is $y=2x_1+3x_2$ a better model than $y=10x_1-x_2$?\n",
    "\n",
    "* The optimization algorithm finds the minimum of the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Question\n",
    "What is the most common loss function for Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* GD is an iterative optimization algorithm. We use it to find the minimum of a function.\n",
    "  \n",
    "  \n",
    "* To find a local minimum of a function, we start at a random point and take steps to the negative of the gradient of the function at the current point.\n",
    "  \n",
    "  \n",
    "* GD helps us find optimal parameters for linear models and neural networks. \n",
    "  \n",
    "  \n",
    "* Many models, such as logistic regression, have a convex optimization criterion. Convex functions have only one global minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Neural networks are not convex, but finding a local minimum usually suffices.\n",
    "  \n",
    "  \n",
    "* **IMPORTANT** GD and its variants are not ML algorithms. They are solvers of minimization problems where the function to minimize has a gradient.\n",
    "\n",
    "![img](img/1_min.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Ingredients for GD*\n",
    "\n",
    "**Ingredient 1: functions of multiple variables**\n",
    "* We can write such a function as $f(x,y,z)$ (for 3 inputs) or $f(x)$ if $x$ is a vector.\n",
    "    * Example: $f(x,y,z) = x^2 + y^2 + e^z + x^z + xyz$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.08553692318767"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x, y, z):\n",
    "    return x**2 + y**2 + np.exp(z) + np.power(x,z) + x*y*z\n",
    "\n",
    "f(1,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Ingredient 2: vector-valued functions**\n",
    "\n",
    "* Functions with multiple outputs (and may or may not have multiple inputs).\n",
    "    * Example with 1 input and 3 outputs:$$f(x)=\\begin{bmatrix} x^2 \\\\ 2x \\\\ -x\\end{bmatrix}$$\n",
    "    * Example with 3 inputs and 4 outputs:$$f(x,y,z)=\\begin{bmatrix} yz^2 \\\\ 0 \\\\ xyz \\\\ x-y\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.        , -0.54402111])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x,y):\n",
    "    return np.array([x, np.sin(y)]) \n",
    "\n",
    "f(2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Ingredient 3: partial derivatives**  \n",
    "* A partial derivative is a derivative of a multivariable function with respect to one of the input variables.\n",
    "    * When taking this derivative, we treat all the other variables as constants.\n",
    "\n",
    "Example: \n",
    "$f(x,y,z) = x^2 + y^2 + e^x + x^z + xyz$\n",
    "\n",
    "Let's compute $\\frac{\\partial}{\\partial x} f(x,y,z)$\n",
    "\n",
    "$$\\begin{align}\\frac{\\partial}{\\partial x} \\quad x^2 + \\quad y^2 + \\quad e^x + \\quad x^z + \\quad xyz\\\\=\\quad 2x + \\quad 0 +\\quad  e^x + \\quad zx^{z-1} + \\quad yz\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](img/3_deriv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Ingredient 4: gradients**\n",
    "\n",
    "A gradient is just a box holding all the $d$ partial derivatives (assuming you have a function of $d$ variables). \n",
    "For example, when $d=3$:\n",
    "\n",
    "$$\\nabla f(x,y,z)=\\begin{bmatrix}\\frac{\\partial f}{\\partial x}(x,y,z)\\\\ \\frac{\\partial f}{\\partial y}(x,y,z) \\\\\\frac{\\partial f}{\\partial z}(x,y,z)\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](img/4_mderiv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Gradients intuition** \n",
    "Since a gradient is a vector, we can talk about its magnitude and direction.\n",
    "\n",
    "- The magnitude $\\|\\nabla f\\|$ tells us how fast things are changing.\n",
    "- The direction $\\frac{\\nabla f}{\\|\\nabla f \\|}$ tells us the direction of fastest change or the steepest direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The idea of gradient descent relies on the idea of a sequence.\n",
    "\n",
    "You may have seen sequences in math class, e.g.\n",
    "$$x_{i+1} = x_i + 1,\\quad x_0=0$$\n",
    "\n",
    "The sequence is defined by explaining how the next iterate (i.e. the next $x$) is related to the previous one.\n",
    "The sequence is $x_0=0,x_1=1,x_2=2,\\ldots,x_n=n$.\n",
    "\n",
    "In gradient descent the current iterate only depends on the previous one.\n",
    "\n",
    "**Convergence**\n",
    "Some sequences converge and others don't.\n",
    "The one above doesn't coverge, but rather $x$ just keeps growing.\n",
    "Here is a sequence that converges: $$x_{i+1}=x_{i}+ \\left(\\frac12\\right)^{i},\\quad x_0=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also have sequences with multiple variables, e.g.\n",
    "\n",
    "$$\\begin{align*}x_{i+1}=2x_i- x_i y_i\\\\ y_{i+1}=0.5y_i+x_iy_i\\end{align*}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gradient descent is defined as follows:\n",
    "\n",
    "> $$w_{i+1}=w_i - \\alpha_i \\nabla f(w_i)$$\n",
    "\n",
    "* We use $w$ for the iterates instead of $x$ because we're changing the model parameters (weights), $w$.\n",
    "\n",
    "  \n",
    "* This is a multivariate sequence because $w$ is a vector.\n",
    "\n",
    "**Gradient descent as a sequence**\n",
    "\n",
    "* GD defined a sequence of iterates.  \n",
    "\n",
    "* It needs an initial value too, for example by setting $w=0$ or some random numbers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Key idea: we choose the sequence carefully so that it converges to a global minimum of $f$.  \n",
    "One can show that this happens under some reasonable conditions, like sufficiently small $\\alpha$, convex and smooth $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![img](img/2_GD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Magnitude and direction of the gradient**\n",
    "\n",
    "* Note that what we really care about is the direction of the gradient.  \n",
    "  \n",
    "  \n",
    "* The magnitude is useful too - when the function is steeper, we take bigger steps even for a fixed $\\alpha$.  \n",
    "  \n",
    "  \n",
    "* $\\alpha$ is also called the learning rate (a hyperparameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inconveniences of GD\n",
    "Gradient descent is sensitive to the choice of the learning rate $\\alpha$. \n",
    "\n",
    "It is also painfully slow for large datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Proposed Solution: \n",
    "#### Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**SGD** is a version of GD that speeds up the computation by approximating the gradient using smaller batches (subsets) of the training data. This subset of data is called a \"batch\" or \"minibatch\".\n",
    "\n",
    "We can keep updating the parameters until the loss stops decreasing (i.e. loss has converged).\n",
    "\n",
    "**Some definitions:**\n",
    "\n",
    "* *iteration* is each time you update the weights.\n",
    "* *epoch* is the number of iterations it takes to look at $n$ examples. It is a \"full pass through the dataset\" or \"having looked at all training examples once\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For **GD** that each iteration is an epoch. \n",
    "> \\# of iterations = # of epochs.\n",
    "\n",
    "For **SGD**, each iteration involves a subset of the data.\n",
    "What fraction of the data, you might ask?\n",
    "> $$\\frac{\\text{batchsize}}{\\text{n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example:\n",
    "> If $n=1000$ and the batch size is $10$, then it's 1/100 or 1% of the whole training data each time.\n",
    "Thus, we'd need to do $100$ iterations to get to an epoch.\n",
    "\n",
    "**In general:**\n",
    "> $$\\text{iterations per epoch} = \\frac{\\text{n}}{\\text{batchsize}}$$\n",
    "\n",
    "* This gives us a formula:\n",
    "> $$\\frac{\\text{number of iterations}}{\\text{number of epochs}}=\\frac{n}{\\text{batch size}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Learning rate**\n",
    "\n",
    "\n",
    "According to the theory, we need to decrease $\\alpha$ over time, following certain guidelines.\n",
    "Often people leave $\\alpha$ constant and things tend to work out.\n",
    "\n",
    "Use grid search with cross-validation to find your best choice. The choice is important as it can be painfully slow or create divergent behaviours.\n",
    "\n",
    "![img](img/6_lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Advantages of SGD**\n",
    "* Faster for big datasets.\n",
    "* \"Why spend all that time picking a direction for your step? An approximate direction seems fine\"\n",
    "* Generaliztaion of GD.\n",
    "* If your training data does not fit into memory, SGD still works - you just need to fit a batch in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gradient Descent Procedure:\n",
    "\n",
    "1. Initialize the parameters (e.g. randomly)\n",
    "2. Compute the gradient of the loss function with respect to the parameters\n",
    "3. The loss function would increase if we moved the parameters in the direction of this gradient. Hence, move the parameters in the opposite direction of the gradient so that the loss function would decrease.\n",
    "4. The parameters are more accurate now because they result in a lower loss. This is the goal of training.\n",
    "5. Repeat (2) and (3) several times so that the loss gradually decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Optional Readings:\n",
    "[An overview of gradient descent optimization algorithms](https://ruder.io/optimizing-gradient-descent/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Usually\t“true”\tmapping\tfrom\t$x_i$ to\t$y_i$ is\tcomplex.\n",
    "- Might need high-degree polynomial.\n",
    "- Might\tneed to combine many features, and don’t know “relevant” ones.\n",
    "\n",
    "![img](img/7_reg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But complex models will overfit and too simple models will underfit. So, what do we do?\n",
    "\n",
    "**Option 1:** use a less powerful model  \n",
    "**Option 2:** reduce the number of parameters  \n",
    "For linear regression, corresponds to reducing the number of features (dimensionality reduction or feature selection)\n",
    "\n",
    "**Option 3:**  \n",
    "**Regularization:**\tAdd\ta penalty on the complexity of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Data has two main components: signal (pattern) + noise\n",
    "\n",
    "**Example:** Predicting house prices from # of bedrooms, area, age, etc.\n",
    "- *Signal:* degree to which these features influence the price.\n",
    "- *Noise:*  random variation, or variation due to unknown features.\n",
    "\n",
    "Goal of ML: model the pattern, ignore the noise\n",
    "When the model is fitting (trying to predict) the noise, we say that it is overfitting.\n",
    "Overfitting is undesirable, because the noise is random and therefore won’t be the same on new data seen out in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](https://pbs.twimg.com/media/EbI7FNxX0AU_gIR?format=jpg&name=900x900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Regularization** is an umbrella term that encompasses methods that help the learning algorithm build a less complex model. \n",
    "That often leads to higher bias but reduces the variance. ([Bias-variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff))\n",
    "\n",
    "The most used types of regularization are called L1 (Lasso) and L2 (Ridge) regularization. \n",
    "To create a regularized model, we modify the objective function by adding a penalizing term whose value is higher when the model is more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In L2 Regression, the cost function is altered by adding a penalty equivalent to square of the magnitude of the coefficients.\n",
    "\n",
    " > $\\sum_{i=1}^M(\\mathbf{y_i} - \\hat{\\mathbf{y}})^2$ = $\\sum_{i=1}^M(\\mathbf{y_i} - \\sum_{j=0}^p{\\mathbf{w_j}} * {\\mathbf{x_{ij}}})^2 + \\lambda\\sum_{j=0}^p{\\mathbf{w_j}}^2$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So L2 regression puts constraint on the coefficients ($w$). \n",
    "The penalty term ($\\lambda$) regularizes the coefficients such that if the coefficients take large values, the optimization function is penalized. This way, L2 regression shrinks the coefficients, helping to reduce the model complexity and multi-collinearity. \n",
    "\n",
    "When $\\lambda$ → 0 , the cost function becomes similar to the linear regression cost function. So, with a lower $\\lambda$ on the features, the model will be close to a linear regression model.\n",
    "\n",
    "L2 also has the advantage of being differentiable, so gradient descent can be used for optimizing the objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ridge Regression:\n",
    "- Uses L2 penalty (penalizes weights based on their squared sum)\n",
    "- Prevents overfitting when there is a lot of correlation between the features\n",
    "- Model has reduced variance (more consistent model for small variations in the data)\n",
    "- Irrelevant features get small weights, instead of being used by the model to fit noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "L1 regularization produces a sparse model, a model that has most of its parameters equal to zero.\n",
    "\n",
    "So L1 performs feature selection by deciding which features are essential for prediction and which are not. That can be useful in case you want to increase model explainability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The cost function for Lasso (least absolute shrinkage and selection operator) regression can be written as:\n",
    "\n",
    " > $\\sum_{i=1}^M(\\mathbf{y_i} - \\hat{\\mathbf{y}})^2$ = $\\sum_{i=1}^M(\\mathbf{y_i} - \\sum_{j=0}^p{\\mathbf{w_j}} * {\\mathbf{x_{ij}}})^2 + \\lambda\\sum_{j=0}^p\\mid{\\mathbf{w_j}}\\mid$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Lasso Regression**\n",
    "- Uses an L1 penalty (penalizes weights based on their absolute value sum)\n",
    "- Prevents overfitting when there is a lot of collinearity (correlation) between the features\n",
    "- Model has reduced variance (more consistent model for small variations in the data)\n",
    "- Irrelevant features get weights of 0, instead of being used by the model to fit noise\n",
    "- Can be used for feature selection (pick the features with > 0 weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Same as L2 regression cost function, when $\\lambda = 0$, the equation above looks like a linear regression. In L2, we took the square of coefficients, here, absolute values or magnitudes are taken into account. \n",
    "\n",
    "L1 regression can lead to zero coefficients, some of the features are not considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In Lasso and Ridge Regressions, we can pick our $\\lambda$.\n",
    "\n",
    "- If $\\lambda$ is too small, we can overfit (model too complex).\n",
    "- If $\\lambda$ is too large, we can underfit (model ignores prediction error).\n",
    "\n",
    "Like all other hyperparameters, the simplest way to pick it is to try a lot of values and see which works best.\n",
    "\n",
    "Look for: Cross Validation and Search Grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If your  goal is to maximize the performance of the model on the holdout data, then L2 usually gives better results. \n",
    "\n",
    "L1 and L2 regularization methods were also combined in what is called **Elastic Net Regularization** with L1 and L2 regularizations being special cases. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
