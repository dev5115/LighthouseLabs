{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lighthouse Labs\n",
    "### W08D4 NLP II\n",
    "Instructor: Socorro Dominguez  \n",
    "November 05, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Agenda:**\n",
    "* Introduction to NLP modeling\n",
    "\n",
    "* Sentiment analysis\n",
    "    * Supervised learning sentiment analysis\n",
    "\n",
    "* Topic modeling\n",
    "    * LDA (Latent-Dirichlet-Allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seiryu8808/opt/anaconda3/lib/python3.7/site-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "/Users/seiryu8808/opt/anaconda3/lib/python3.7/site-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim \n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from gensim import matutils, models\n",
    "import pyLDAvis.gensim\n",
    "import string\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sentiment Anaysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sentiment analysis (also known as opinion mining or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using Supervised Learning Algorithms for Sentiment Analysis\n",
    "\n",
    "Naive Bayes is popular in text classification tasks. \n",
    "\n",
    "You have used NB before. Today, we will use it for sentiment analysis, which is a problem of assigning positive or negative label to a text based on the sentiment or attitude expressed in  it. \n",
    "\n",
    "For this example, we will use [IMDB movie review data set](https://www.kaggle.com/utathya/imdb-review-dataset). If you want to reproduce this example, you will need to download the data on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading data and preprocessing\n",
    "\n",
    "1. We need to load data CSV as a pandas DataFrame.\n",
    "\n",
    "2. There are three possible labels in the dataset: `pos`, `neg`, and `unsup`. For now, let's discard rows with `unsup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df = pd.read_csv('data/imdb_master.csv', encoding = \"ISO-8859-1\")\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unsup    50000\n",
       "pos      25000\n",
       "neg      25000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# only consider positive and negative reviews\n",
    "imdb_df = imdb_df[imdb_df['label'].str.startswith(('pos','neg'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature extraction\n",
    "\n",
    "The current data is in the form of moview reviews (text paragraphs) and their targets (`pos` or `neg`). \n",
    "We need to encode movie reviews into feature vectors so that we can train supervised machine learning models with `scikit-learn`. \n",
    "\n",
    "How can we do this?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Create word frequency counts (`X_counts`)\n",
    "Turn the text into sparse vector of word frequency counts using [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) from  `scikit-learn`. \n",
    "\n",
    "When you reproduce this, explore the arguments of `CountVectorizer` (e.g., [`stop_words`](https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words), `ngram_range`, `max_features`, `min_df`, and `tokenizer`).  \n",
    "\n",
    "#### Create binarized representation of words (`X_binary`)\n",
    "Create binarized encoding (`X_binary`) of `X_counts`, where you replace word frequencies $\\geq$ 1 by 1.    \n",
    "The intuition behind using binarized representation is that for sentiment analysis word occurrence may matter more than word frequency. For instance, the occurrence of the word _excellent_ tells us a lot and the fact that it occurs four times may not tell us much more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seiryu8808/opt/anaconda3/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/Users/seiryu8808/opt/anaconda3/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, defaultdict\n"
     ]
    }
   ],
   "source": [
    "# For tokenization\n",
    "import nltk\n",
    "# For converting words into frequency counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# initialize movie_vector object and then turn movie reviews train data into a vector \n",
    "movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize, stop_words='english')\n",
    "\n",
    "# use top 5000 words only\n",
    "# movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize, max_features = 5000) \n",
    "X_counts = movie_vec.fit_transform(imdb_df['review'])\n",
    "\n",
    "# Convert raw frequency counts into binarized representation. \n",
    "X_binary = X_counts > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train Naive Bayes classifier\n",
    "\n",
    "1. Split (`X_counts`, `imdb_df.label`) into train (80%) and test (20%).\n",
    "2. Train [multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) on the train set. \n",
    "3. Report train and test accuracies.\n",
    "4. Now repeat steps 1, 2, and 3 with (`X_binary`, `imdb_df.label`). \n",
    "5. Compare your results for `X_counts` and `X_binary` and note your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_NB_train_test_accuracies(X, y, classifier = 'multinominal'):\n",
    "    \"\"\"\n",
    "    Given X, y, and the classifier, this function splits the \n",
    "    data into train and test splits, prints the train and test accuracies,\n",
    "    and returns the model.     \n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.20, \n",
    "                                                        random_state = 12)\n",
    "    if classifier.startswith('multinominal'):\n",
    "        model = MultinomialNB().fit(X_train, y_train)\n",
    "    elif classifier.startswith('bernoulli'):\n",
    "        model = BernoulliNB().fit(X_train, y_train)\n",
    "    print('Training accuracy:', model.score(X_train, y_train))\n",
    "    print('Test accuracy: ', model.score(X_test, y_test))\n",
    "    print('---------')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on binarized encoding \n",
      "Training accuracy: 0.90135\n",
      "Test accuracy:  0.8567\n",
      "---------\n",
      "Evaluation on counts encoding \n",
      "Training accuracy: 0.89905\n",
      "Test accuracy:  0.8558\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation on binarized encoding ')\n",
    "model_binary = get_NB_train_test_accuracies(X_binary, imdb_df.label, classifier = 'bernoulli')\n",
    "\n",
    "print('Evaluation on counts encoding ')\n",
    "model_counts = get_NB_train_test_accuracies(X_counts, imdb_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's play with fake reviews \n",
    "\n",
    "Let's see how the model performs on fake movie reviews. Some examples are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fake_reviews = ['This movie was excellent! The performances were oscar-worthy!',\n",
    "               'Unbelievably disappointing.', \n",
    "               'Full of zany characters and richly applied satire, and some great plot twists',\n",
    "               'This is the greatest screwball comedy ever filmed',\n",
    "               'It was pathetic. The worst part about it was the boxing scenes.', \n",
    "               '''It could have been a great movie. It could have been excellent, \n",
    "                and to all the people who have forgotten about the older, \n",
    "                greater movies before it, will think that as well. \n",
    "                It does have beautiful scenery, some of the best since Lord of the Rings. \n",
    "                The acting is well done, and I really liked the son of the leader of the Samurai.\n",
    "                He was a likeable chap, and I hated to see him die...\n",
    "                But, other than all that, this movie is nothing more than hidden rip-offs.\n",
    "                '''\n",
    "              ]\n",
    "gold_labels = ['pos', 'neg', 'pos', 'pos', 'neg', 'neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Create word count encoding of the reviews.  \n",
    "fake_reviews_counts = movie_vec.transform(fake_reviews)\n",
    "fake_reviews_binary = fake_reviews_counts > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Predict using the Naive Bayes classifier\n",
    "predictions = model_binary.predict(fake_reviews_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos', 'neg', 'pos', 'pos', 'neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(predictions.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Gold labels</th>\n",
       "      <th>NB labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie was excellent! The performances were oscar-worthy!</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unbelievably disappointing.</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full of zany characters and richly applied satire, and some great plot twists</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the greatest screwball comedy ever filmed</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was pathetic. The worst part about it was the boxing scenes.</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It could have been a great movie. It could have been excellent, \\n                and to all the people who have forgotten about the older, \\n                greater movies before it, will think that as well. \\n                It does have beautiful scenery, some of the best since Lord of the Rings. \\n                The acting is well done, and I really liked the son of the leader of the Samurai.\\n                He was a likeable chap, and I hated to see him die...\\n                But, other than all that, this movie is nothing more than hidden rip-offs.\\n</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Review  \\\n",
       "0  This movie was excellent! The performances were oscar-worthy!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "1  Unbelievably disappointing.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "2  Full of zany characters and richly applied satire, and some great plot twists                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "3  This is the greatest screwball comedy ever filmed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "4  It was pathetic. The worst part about it was the boxing scenes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "5  It could have been a great movie. It could have been excellent, \\n                and to all the people who have forgotten about the older, \\n                greater movies before it, will think that as well. \\n                It does have beautiful scenery, some of the best since Lord of the Rings. \\n                The acting is well done, and I really liked the son of the leader of the Samurai.\\n                He was a likeable chap, and I hated to see him die...\\n                But, other than all that, this movie is nothing more than hidden rip-offs.\\n                   \n",
       "\n",
       "  Gold labels NB labels  \n",
       "0  pos         pos       \n",
       "1  neg         neg       \n",
       "2  pos         pos       \n",
       "3  pos         pos       \n",
       "4  neg         neg       \n",
       "5  neg         pos       "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 0)\n",
    "d = {'Review':fake_reviews, 'Gold labels':gold_labels, 'NB labels':predictions}\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Our model works well when there are clear words indicating whether the review is positive or negative, as the features we are using are word features.\n",
    "2. Fails for more complex examples, where understanding the context and overall text is essential to correctly classify reviews. The last example has many positive words in the beginning but the last sentence negates all positivity in the previous text. We need to incorporate deeper linguistic knowledge to correctly classify such cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sentiment Analysis with Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/seiryu8808/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "VADER's SentimentIntensityAnalyzer() takes in a string and returns a dictionary of scores in each of four categories:\n",
    "\n",
    "* negative\n",
    "* neutral\n",
    "* positive\n",
    "* compound (computed by normalizing the scores above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.412, 'neu': 0.588, 'pos': 0.0, 'compound': -0.6818}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'The weather today is horrible. I dont feel like getting out'\n",
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.477, 'neu': 0.523, 'pos': 0.0, 'compound': -0.8074}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'This was the worst film to ever disgrace the screen.'\n",
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Gold labels</th>\n",
       "      <th>NB labels</th>\n",
       "      <th>Vader labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie was excellent! The performances were oscar-worthy!</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unbelievably disappointing.</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full of zany characters and richly applied satire, and some great plot twists</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the greatest screwball comedy ever filmed</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was pathetic. The worst part about it was the boxing scenes.</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          Review  \\\n",
       "0  This movie was excellent! The performances were oscar-worthy!                   \n",
       "1  Unbelievably disappointing.                                                     \n",
       "2  Full of zany characters and richly applied satire, and some great plot twists   \n",
       "3  This is the greatest screwball comedy ever filmed                               \n",
       "4  It was pathetic. The worst part about it was the boxing scenes.                 \n",
       "\n",
       "  Gold labels NB labels Vader labels  \n",
       "0  pos         pos       pos          \n",
       "1  neg         neg       neg          \n",
       "2  pos         pos       pos          \n",
       "3  pos         pos       pos          \n",
       "4  neg         neg       neg          "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Vader_scores'] = df['Review'].apply(lambda review: sid.polarity_scores(review))\n",
    "\n",
    "df['compound']  = df['Vader_scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "df['Vader labels'] = df['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
    "\n",
    "df_labels = df[['Review', 'Gold labels', 'NB labels', 'Vader labels']]\n",
    "\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "10 min Break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topic modeling \n",
    "\n",
    "- Suppose your company has a large collection of documents on a variety of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: A corpus of food magazines \n",
    "<center>\n",
    "<img src=\"images/00_TM_food_magazines.png\" height=\"2000\" width=\"2000\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: A corpus of news articles \n",
    "<center>\n",
    "<img src=\"images/01_TM_NYT_articles.png\" height=\"2000\" width=\"2000\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topic modeling \n",
    "\n",
    "- Suppose your company has a large collection of documents on a variety of topics\n",
    "- Suppose they ask you to \n",
    "    - infer different topics in the documents\n",
    "    - pull all documents about a certain topic    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topic modeling motivation\n",
    "\n",
    "- Humans are pretty good at reading and understanding documents and answering questions such as \n",
    "    - What is it about?  \n",
    "    - What is it related to in terms of content?     \n",
    "- Labeling by hand? \n",
    "    - Probably not\n",
    "- Use topic modeling which automates this process of inferring underlying structure in a large corpus of text documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topic modeling: Input \n",
    "\n",
    "<center>\n",
    "<img src=\"images/02_TM_science_articles.png\" height=\"2000\" width=\"2000\"> \n",
    "</center>\n",
    "(Credit: [Dave Blei's presentation](http://www.cs.columbia.edu/~blei/talks/Blei_Science_2008.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topic modeling: output\n",
    "<center>\n",
    "<img src=\"files/images/TM_topics.png\" height=\"900\" width=\"900\"> \n",
    "</center>\n",
    "\n",
    "(Credit: [Dave Blei's presentation](http://www.cs.columbia.edu/~blei/talks/Blei_Science_2008.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topic modeling: output with interpretation\n",
    "\n",
    "- The labels are assigned manually.  \n",
    "<center>\n",
    "<img src=\"images/03_TM_topics_with_labels.png\" height=\"800\" width=\"800\"> \n",
    "</center>\n",
    "\n",
    "(Credit: [Dave Blei's presentation](http://www.cs.columbia.edu/~blei/talks/Blei_Science_2008.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Topic modeling pipeline \n",
    "\n",
    "- Feed knowlege into the machines; let it read large amount of text\n",
    "    * E.g., Wikipedia or News articles     \n",
    "- Preprocess your corpus \n",
    "    - Be careful with the features (i.e., words)\n",
    "- Train ML models\n",
    "    - For now Latent Dirichlet Allocation (LDA)\n",
    "- Interpret your topics     \n",
    "- Evaluate\n",
    "    - How well your model does on unseen documents? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baysian approach: Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "- Developed by [David Blei](http://www.cs.columbia.edu/~blei/) and colleagues. \n",
    "    * One of the most cited papers in the last 15 years.\n",
    "    \n",
    "- Insight: \n",
    "    - Each document is a random mixture of corpus-wide topics\n",
    "        - Every document is a discrete probability distribution of topics\n",
    "\n",
    "    - Every topic is a mixture words\n",
    "        - Every topic is a discrete probability distribution of words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDA: insight\n",
    "- Each document is a random mixture of corpus-wide topics\n",
    "- Every topic is a mixture words\n",
    "<center>\n",
    "<img src=\"images/04_TM_dist_topics_words_blei.png\" height=\"1000\" width=\"1000\"> \n",
    "</center>\n",
    "\n",
    "(Credit: [Dave Blei's presentation](http://www.cs.columbia.edu/~blei/talks/Blei_Science_2008.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Every document is a discrete probability distribution of topics\n",
    "\n",
    "- Assume two topics: Topic 1 (topic model) and Topic 2 (fashion model)\n",
    "- Document 1: 100% topic models\n",
    "- Document 4: 100% fashion models\n",
    "- Document 7: 60% topic models + 40% fashion model\n",
    "\n",
    "<blockquote>\n",
    "Document 1: probabilistic topic model<br>\n",
    "Document 2: probabilistic topic model<br>\n",
    "Document 3: probabilistic topic model<br>\n",
    "Document 4: famous fashion model<br>\n",
    "Document 5: famous fashion model<br>\n",
    "Document 6: famous fashion model<br>\n",
    "Document 7: famous fashion model at probabilistic topic model conference<br>    \n",
    "</blockquote>\n",
    "    \n",
    "(Credit: The example is adapted from [Topic models tutorial](http://topicmodels.info/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Every topic is a discrete probability distribution of words\n",
    "\n",
    "- Assume two topics: Topic 1 (topic model) and Topic 2 (fashion model)\n",
    "- Topic 1: _model_ (0.33), _probabilistic_ (0.32), _topic_ (0.32), ...    \n",
    "- Topic 2: _model_ (0.33), _famous_ (0.32), _fashion_ (0.32), ...    \n",
    "\n",
    "<blockquote>\n",
    "Document 1: probabilistic topic model<br>\n",
    "Document 2: probabilistic topic model<br>\n",
    "Document 3: probabilistic topic model<br>\n",
    "Document 4: famous fashion model<br>\n",
    "Document 5: famous fashion model<br>\n",
    "Document 6: famous fashion model<br>\n",
    "Document 7: famous fashion model at probabilistic topic model conference<br>    \n",
    "</blockquote>\n",
    "    \n",
    "(Credit: The example is adapted from [Topic models tutorial](http://topicmodels.info/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDA model\n",
    "\n",
    "- Observable features: words\n",
    "- All other parameters are hidden or latent\n",
    "\n",
    "<center>\n",
    "<img src=\"images/05_TM_topic_model_blei.png\" height=\"700\" width=\"700\"> \n",
    "</center>\n",
    "\n",
    "(Adapted from [David Blei's paper](http://www.cs.columbia.edu/~blei/papers/BleiNgJordan2003.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDA: Hyperparameters\n",
    "\n",
    "- $\\alpha$ \n",
    "   - High alpha &rarr; every document contains a mixture of most of the topics\n",
    "   - Low alpha &rarr; every document is representative of only a few topic\n",
    "- $\\beta$\n",
    "    - High beta &rarr; Every topic contains a mixture of most of the words\n",
    "    - Low beta &rarr; Every topic contains a mixture of only few words\n",
    "\n",
    "<center>\n",
    "<img src=\"images/05_TM_topic_model_blei.png\" height=\"600\" width=\"600\"> \n",
    "</center>\n",
    "\n",
    "(Adapted from [David Blei's paper](http://www.cs.columbia.edu/~blei/papers/BleiNgJordan2003.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDA learning: goals\n",
    "\n",
    "Infer the underlying topic structure in the documents. In particular, \n",
    "- Learn the probability distribution of topics in each document\n",
    "- Learn the discrete probability distribution of words in each topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDA learning: intuition\n",
    "\n",
    "Intuition: A word in a document is likely to belong to the same topic as the other words in that document. \n",
    "\n",
    "<blockquote>\n",
    "Document 1: probabilistic (Topic 1) topic (Topic 1) model (Topic ?) <br>\n",
    "Document 1: probabilistic (Topic 1) topic (Topic 1) model (Topic 1)\n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "Document 8: famous (Topic 2) fashion (Topic 2) model (Topic ?)\n",
    "    <br>\n",
    "Document 8: famous (Topic 2) fashion (Topic 2) model (Topic 2)    \n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDA algorithm \n",
    "\n",
    "- Choose the number of topics you think are there in your corpus\n",
    "    * Example: k = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDA algorithm\n",
    "\n",
    "- Repeat the following steps till the topics make sense:     \n",
    "- Randomly assign each words in each document to one of the topics\n",
    "    * Example: The word _probabilistic_ is randomly assigned to topic 2 (fashion).\n",
    "- Go through every word and its topic assignment in each document, looking at\n",
    "    * How often the topic occurs in the document?\n",
    "    * How often the word occurs with the topic overall? \n",
    "    * Example: Seems like topic 2 does not occur in Document 1 and the word _probabilistic_ doesn't occur much in topic 2 (fashion). So the word _probabilistic_ should probably be assigned to topic 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDA topics in Science journal\n",
    "\n",
    "<center>\n",
    "<img src=\"images/03_TM_topics_with_labels.png\" height=\"800\" width=\"800\"> \n",
    "</center>\n",
    "\n",
    "(Credit: [Dave Blei's presentation](http://www.cs.columbia.edu/~blei/talks/Blei_Science_2008.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training LDA with [Gensim](https://radimrehurek.com/gensim/models/ldamodel.html)\n",
    "\n",
    "You need\n",
    "\n",
    "- Document-term matrix \n",
    "- Pick number of topics: `num_topics`\n",
    "- Pick number of passes: `passes`\n",
    "\n",
    "\n",
    "\n",
    "* *Disclaimer: You can also check out Sklearn's model. However, Gensim is more used in NLP.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>famous fashion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>probabilistic topic model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id                       text\n",
       "0   1       famous fashion model     \n",
       "1   2       famous fashion model     \n",
       "2   3       famous fashion model     \n",
       "3   4       famous fashion model     \n",
       "4   5       famous fashion model     \n",
       "5   6       famous fashion model     \n",
       "6   7       famous fashion model     \n",
       "7   8       famous fashion model     \n",
       "8   9       famous fashion model     \n",
       "9   10      famous fashion model     \n",
       "10  11      famous fashion model     \n",
       "11  12      famous fashion model     \n",
       "12  13      probabilistic topic model\n",
       "13  14      probabilistic topic model\n",
       "14  15      probabilistic topic model\n",
       "15  16      probabilistic topic model\n",
       "16  17      probabilistic topic model\n",
       "17  18      probabilistic topic model\n",
       "18  19      probabilistic topic model\n",
       "19  20      probabilistic topic model\n",
       "20  21      probabilistic topic model\n",
       "21  22      probabilistic topic model\n",
       "22  23      probabilistic topic model\n",
       "23  24      probabilistic topic model\n",
       "24  25      probabilistic topic model\n",
       "25  26      probabilistic topic model"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df = pd.read_csv('data/toy_lda_data.csv')\n",
    "toy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['famous', 'fashion', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model'],\n",
       " ['probabilistic', 'topic', 'model']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [doc.split() for doc in toy_df['text'].tolist()]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1), (3, 1), (4, 1)]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vocabulary for the lda model and \n",
    "# convert our corpus into document-term matrix for Lda\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in corpus]\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus=doc_term_matrix, \n",
    "                      id2word=dictionary, \n",
    "                      num_topics=2, \n",
    "                      passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.326*\"model\" + 0.320*\"fashion\" + 0.320*\"famous\" + 0.017*\"probabilistic\" + 0.016*\"topic\"'),\n",
       " (1,\n",
       "  '0.325*\"topic\" + 0.325*\"probabilistic\" + 0.324*\"model\" + 0.013*\"famous\" + 0.013*\"fashion\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el818721406650701663525920540594\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el818721406650701663525920540594_data = {\"mdsDat\": {\"x\": [0.17295700311660767, -0.17295700311660767], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [47.25359930002092, 52.74640069997908]}, \"tinfo\": {\"Term\": [\"fashion\", \"famous\", \"topic\", \"probabilistic\", \"model\", \"fashion\", \"famous\", \"model\", \"probabilistic\", \"topic\", \"topic\", \"probabilistic\", \"model\", \"famous\", \"fashion\"], \"Freq\": [12.0, 12.0, 13.0, 13.0, 25.0, 11.798316185810998, 11.784911821852518, 12.023578263173722, 0.6442320017850065, 0.606769149708063, 13.388092097299896, 13.351256613582258, 13.350480471474768, 0.5327725114781765, 0.5195916597457063], \"Total\": [12.0, 12.0, 13.0, 13.0, 25.0, 12.317907845556705, 12.317684333330694, 25.37405873464849, 13.995488615367265, 13.99486124700796, 13.99486124700796, 13.995488615367265, 25.37405873464849, 12.317684333330694, 12.317907845556705], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [5.0, 4.0, 3.0, 2.0, 1.0, -1.1390999555587769, -1.1402000188827515, -1.1202000379562378, -4.046800136566162, -4.1066999435424805, -1.1226999759674072, -1.1253999471664429, -1.125499963760376, -4.346700191497803, -4.371699810028076], \"loglift\": [5.0, 4.0, 3.0, 2.0, 1.0, 0.7065, 0.7054, 0.0028, -2.3288, -2.3887, 0.5954, 0.5926, -0.0025, -2.501, -2.5261]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.9742090863238746, 0.08118409052698955, 0.9741914090004026, 0.08118261741670021, 0.4729239466768436, 0.5123342755665806, 0.07145159611662179, 0.9288707495160832, 0.07145479918307841, 0.9289123893800193], \"Term\": [\"famous\", \"famous\", \"fashion\", \"fashion\", \"model\", \"model\", \"probabilistic\", \"probabilistic\", \"topic\", \"topic\"]}, \"R\": 5, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el818721406650701663525920540594\", ldavis_el818721406650701663525920540594_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el818721406650701663525920540594\", ldavis_el818721406650701663525920540594_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el818721406650701663525920540594\", ldavis_el818721406650701663525920540594_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x    y  topics  cluster       Freq\n",
       "topic                                           \n",
       "0      0.172957  0.0  1       1        47.253599\n",
       "1     -0.172957  0.0  2       1        52.746401, topic_info=            Term       Freq      Total Category  logprob  loglift\n",
       "1  fashion        12.000000  12.000000  Default  5.0000   5.0000 \n",
       "0  famous         12.000000  12.000000  Default  4.0000   4.0000 \n",
       "4  topic          13.000000  13.000000  Default  3.0000   3.0000 \n",
       "3  probabilistic  13.000000  13.000000  Default  2.0000   2.0000 \n",
       "2  model          25.000000  25.000000  Default  1.0000   1.0000 \n",
       "1  fashion        11.798316  12.317908  Topic1  -1.1391   0.7065 \n",
       "0  famous         11.784912  12.317684  Topic1  -1.1402   0.7054 \n",
       "2  model          12.023578  25.374059  Topic1  -1.1202   0.0028 \n",
       "3  probabilistic  0.644232   13.995489  Topic1  -4.0468  -2.3288 \n",
       "4  topic          0.606769   13.994861  Topic1  -4.1067  -2.3887 \n",
       "4  topic          13.388092  13.994861  Topic2  -1.1227   0.5954 \n",
       "3  probabilistic  13.351257  13.995489  Topic2  -1.1254   0.5926 \n",
       "2  model          13.350480  25.374059  Topic2  -1.1255  -0.0025 \n",
       "0  famous         0.532773   12.317684  Topic2  -4.3467  -2.5010 \n",
       "1  fashion        0.519592   12.317908  Topic2  -4.3717  -2.5261 , token_table=      Topic      Freq           Term\n",
       "term                                \n",
       "0     1      0.974209  famous       \n",
       "0     2      0.081184  famous       \n",
       "1     1      0.974191  fashion      \n",
       "1     2      0.081183  fashion      \n",
       "2     1      0.472924  model        \n",
       "2     2      0.512334  model        \n",
       "3     1      0.071452  probabilistic\n",
       "3     2      0.928871  probabilistic\n",
       "4     1      0.071455  topic        \n",
       "4     2      0.928912  topic        , R=5, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda, doc_term_matrix, dictionary, sort_topics=False)\n",
    "vis\n",
    "\n",
    "# END SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tips when you build an LDA model on a large corpus \n",
    "\n",
    "- Preprocessing is crucial!! \n",
    "    - Tokenize, remove punctuation, convert text to lower case\n",
    "    - Discard words with length < threshold or word frequency < threshold        \n",
    "    - Stoplist: Remove most commonly used words in English \n",
    "    - Lemmatization: Consider the root form of the word. \n",
    "    - Restrict to specific part of speech\n",
    "        * Only consider nouns, verbs, and adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complex Topic modeling with LDA\n",
    "\n",
    "Let's explore the topics in `scikit-learn`'s [20 newsgroups text dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) using [`gensim`'s `ldamodel`](https://radimrehurek.com/gensim/models/ldamodel.html). \n",
    "\n",
    "Usually, topic modeling is used for discovering the abstract \"topics\" that occur in a collection of documents when you do not know the actual topics present in the documents. But since 20 newsgroups text dataset is labeled with categories (e.g., sports, hardware, religion), you will be able to cross-check the topics discovered by your model with the actual topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo &lt;guykuo@u.washington.edu&gt;\\n</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\\nSubject: PB questions...\\nOrganization: Purdue University Engineering Computer Network\\nDistribution: usa\\nLines: 36\\n\\nwell folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i'm in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i'd heard the 185c was supposed to make an\\nappearence \"this summer\" but haven't heard anymore on it - and since i\\ndon't have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo's just went through recently?\\n\\n* what's the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don't really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i've only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i'll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\  twillis@ecn.purdue.edu    \\    Purdue Electrical Engineering\\n---------------------------------------------------------------------------\\n\"Convictions are more dangerous enemies of truth than lies.\"  - F. W.\\nNietzsche\\n</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: Weitek P9000 ?\\nOrganization: Harris Computer Systems Division\\nLines: 14\\nDistribution: world\\nNNTP-Posting-Host: amber.ssd.csd.harris.com\\nX-Newsreader: TIN [version 1.1 PL9]\\n\\nRobert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n&gt; abraxis@iastate.edu writes in article &lt;abraxis.734340159@class1.iastate.edu&gt;:\\n&gt; &gt; Anyone know about the Weitek P9000 graphics chip?\\n&gt; As far as the low-level stuff goes, it looks pretty nice.  It's got this\\n&gt; quadrilateral fill command that requires just the four points.\\n\\nDo you have Weitek's address/phone number?  I'd like to get some information\\nabout this chip.\\n\\n--\\nJoe Green\\t\\t\\t\\tHarris Corporation\\njgreen@csd.harris.com\\t\\t\\tComputer Systems Division\\n\"The only thing that really scares me is a person with no sense of humor.\"\\n\\t\\t\\t\\t\\t\\t-- Jonathan Winters\\n</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDowell)\\nSubject: Re: Shuttle Launch Question\\nOrganization: Smithsonian Astrophysical Observatory, Cambridge, MA,  USA\\nDistribution: sci\\nLines: 23\\n\\nFrom article &lt;C5owCB.n3p@world.std.com&gt;, by tombaker@world.std.com (Tom A Baker):\\n&gt;&gt;In article &lt;C5JLwx.4H9.1@cs.cmu.edu&gt;, ETRAT@ttacs1.ttu.edu (Pack Rat) writes...\\n&gt;&gt;&gt;\"Clear caution &amp; warning memory.  Verify no unexpected\\n&gt;&gt;&gt;errors. ...\".  I am wondering what an \"expected error\" might\\n&gt;&gt;&gt;be.  Sorry if this is a really dumb question, but\\n&gt; \\n&gt; Parity errors in memory or previously known conditions that were waivered.\\n&gt;    \"Yes that is an error, but we already knew about it\"\\n&gt; I'd be curious as to what the real meaning of the quote is.\\n&gt; \\n&gt; tom\\n\\n\\nMy understanding is that the 'expected errors' are basically\\nknown bugs in the warning system software - things are checked\\nthat don't have the right values in yet because they aren't\\nset till after launch, and suchlike. Rather than fix the code\\nand possibly introduce new bugs, they just tell the crew\\n'ok, if you see a warning no. 213 before liftoff, ignore it'.\\n\\n - Jonathan\\n\\n\\n</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\\nSubject: PB questions...\\nOrganization: Purdue University Engineering Computer Network\\nDistribution: usa\\nLines: 36\\n\\nwell folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i'm in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i'd heard the 185c was supposed to make an\\nappearence \"this summer\" but haven't heard anymore on it - and since i\\ndon't have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo's just went through recently?\\n\\n* what's the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don't really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i've only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i'll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\  twillis@ecn.purdue.edu    \\    Purdue Electrical Engineering\\n---------------------------------------------------------------------------\\n\"Convictions are more dangerous enemies of truth than lies.\"  - F. W.\\nNietzsche\\n   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: Weitek P9000 ?\\nOrganization: Harris Computer Systems Division\\nLines: 14\\nDistribution: world\\nNNTP-Posting-Host: amber.ssd.csd.harris.com\\nX-Newsreader: TIN [version 1.1 PL9]\\n\\nRobert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\\n> > Anyone know about the Weitek P9000 graphics chip?\\n> As far as the low-level stuff goes, it looks pretty nice.  It's got this\\n> quadrilateral fill command that requires just the four points.\\n\\nDo you have Weitek's address/phone number?  I'd like to get some information\\nabout this chip.\\n\\n--\\nJoe Green\\t\\t\\t\\tHarris Corporation\\njgreen@csd.harris.com\\t\\t\\tComputer Systems Division\\n\"The only thing that really scares me is a person with no sense of humor.\"\\n\\t\\t\\t\\t\\t\\t-- Jonathan Winters\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDowell)\\nSubject: Re: Shuttle Launch Question\\nOrganization: Smithsonian Astrophysical Observatory, Cambridge, MA,  USA\\nDistribution: sci\\nLines: 23\\n\\nFrom article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\\n>>In article <C5JLwx.4H9.1@cs.cmu.edu>, ETRAT@ttacs1.ttu.edu (Pack Rat) writes...\\n>>>\"Clear caution & warning memory.  Verify no unexpected\\n>>>errors. ...\".  I am wondering what an \"expected error\" might\\n>>>be.  Sorry if this is a really dumb question, but\\n> \\n> Parity errors in memory or previously known conditions that were waivered.\\n>    \"Yes that is an error, but we already knew about it\"\\n> I'd be curious as to what the real meaning of the quote is.\\n> \\n> tom\\n\\n\\nMy understanding is that the 'expected errors' are basically\\nknown bugs in the warning system software - things are checked\\nthat don't have the right values in yet because they aren't\\nset till after launch, and suchlike. Rather than fix the code\\nand possibly introduce new bugs, they just tell the crew\\n'ok, if you see a warning no. 213 before liftoff, ignore it'.\\n\\n - Jonathan\\n\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\n",
       "             target_name  target  \n",
       "0  rec.autos              7       \n",
       "1  comp.sys.mac.hardware  4       \n",
       "2  comp.sys.mac.hardware  4       \n",
       "3  comp.graphics          1       \n",
       "4  sci.space              14      "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'text':[], 'target_name':[], 'target':[]}\n",
    "data['text'] = newsgroups_train.data\n",
    "data['target_name'] = [newsgroups_train.target_names[target] for target in newsgroups_train.target]\n",
    "data['target'] = [target for target in newsgroups_train.target]\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "We want our topic model to identify interesting and important patterns instead of noise. For that we need to \"normalize\" our text. Preprocessing is a crucial step when you do topic modeling and it markedly affects the results. For this example, let's use a popular Python NLP library called [spaCy](https://spacy.io/). It is a fast, easy-to-use, industrial-strength, and a powerful library. \n",
    "\n",
    "spaCy is a powerful library and it can do many other things, but we'll be using it for preprocessing.  With this library, you can run the NLP pipeline by simply calling the function `nlp`. You can then access information about each token in a `for` loop. \n",
    "\n",
    "```\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.pos_)\n",
    "    print(token.lemma_)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Load English model for SpaCy\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text, \n",
    "               min_token_len = 2 , \n",
    "               irrelevant_pos = ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE']): \n",
    "    \"\"\"\n",
    "    Given text, min_token_len, and irrelevant_pos carry out preprocessing of the text \n",
    "    and return a preprocessed string. \n",
    "    \n",
    "    Keyword arguments:\n",
    "    text -- (str) the text to be preprocessed\n",
    "    min_token_len -- (int) min_token_length required\n",
    "    irrelevant_pos -- (list) a list of irrelevant pos tags\n",
    "    \n",
    "    Returns: (str) the preprocessed text\n",
    "    \"\"\"\n",
    "    # Remove Emails\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "    \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove distracting characters\n",
    "    text = re.sub(r'''[\\*\\~]+''', \"\", text)\n",
    "\n",
    "    doc = nlp(text)\n",
    "    clean_text = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.is_stop == False # Check if it's not a stopword\n",
    "            and token.is_alpha # Check if it's an alphanumerics char\n",
    "            and len(token) > min_token_len # Check if the word meets minimum threshold\n",
    "            and token.pos_ not in irrelevant_pos): # Check if the POS is in the acceptable POS tags\n",
    "            lemma = token.lemma_ # Take the lemma of the word\n",
    "            clean_text.append(lemma)  \n",
    "    return \" \".join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(preprocess)\n",
    "#df.to_csv('data/clean_text.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build dictionary and document-term co-occurrence matrix\n",
    "\n",
    "We need two things to build `gensim`'s `LdaModel`: a dictionary and a document-term co-occurrence matrix. Let's\n",
    "\n",
    "1. Create a dictionary using `gensim`'s [`corpora.Dictionary`](https://radimrehurek.com/gensim/corpora/dictionary.html) method. Optionally, you can exclude extremes using the [`filter_extremes`](https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.filter_extremes) method of your `corpora.Dictionary` object. \n",
    "2. Create the document-term co-occurrence matrix using `corpora.Dictionary`'s `doc2bow` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_corpus = [doc.split() for doc in df['clean_text'].tolist()]\n",
    "# Create a vocabulary for the lda model and \n",
    "# convert our corpus into document-term matrix for Lda\n",
    "dictionary = corpora.Dictionary(preprocessed_corpus)\n",
    "\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n= 100000)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in preprocessed_corpus]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build a topic model\n",
    "\n",
    "Let's actually build a topic model.  \n",
    "\n",
    "1. Build an LDA model using `gensim`'s [`models.LdaModel`](https://radimrehurek.com/gensim/models/ldamodel.html) with `num_topics` = 10. Note: If you get many warnings when you build your model, update your gensim installation.  See [here](https://github.com/RaRe-Technologies/gensim/pull/2296).\n",
    "2. Print LDA topics with the `model.print_topics()` methods, where `model` is your LDA model. \n",
    "3. Experiment with a few choices of `num_topics` hyperparameter. \n",
    "4. Experiment with a few choices of `passes` hyperparameter. \n",
    "5. Settle on the hyperparameters, where the topics make sense to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus=doc_term_matrix, \n",
    "                      id2word=dictionary, \n",
    "                      num_topics=10, \n",
    "                      passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.023*\"game\" + 0.019*\"team\" + 0.015*\"play\" + 0.012*\"player\" + 0.011*\"win\" + 0.008*\"season\" + 0.006*\"score\" + 0.006*\"hockey\" + 0.006*\"NHL\" + 0.006*\"fan\"'),\n",
       " (1,\n",
       "  '0.029*\"God\" + 0.013*\"Jesus\" + 0.007*\"Bible\" + 0.006*\"life\" + 0.006*\"Christ\" + 0.006*\"faith\" + 0.006*\"Christians\" + 0.005*\"book\" + 0.005*\"belief\" + 0.005*\"word\"'),\n",
       " (2,\n",
       "  '0.010*\"car\" + 0.007*\"buy\" + 0.007*\"gun\" + 0.006*\"power\" + 0.005*\"drive\" + 0.005*\"little\" + 0.004*\"USA\" + 0.004*\"wire\" + 0.004*\"high\" + 0.004*\"ground\"'),\n",
       " (3,\n",
       "  '0.035*\"key\" + 0.014*\"chip\" + 0.012*\"encryption\" + 0.008*\"science\" + 0.007*\"Clipper\" + 0.007*\"algorithm\" + 0.006*\"government\" + 0.006*\"escrow\" + 0.006*\"secret\" + 0.005*\"bit\"'),\n",
       " (4,\n",
       "  '0.014*\"information\" + 0.013*\"list\" + 0.011*\"send\" + 0.009*\"available\" + 0.008*\"address\" + 0.008*\"group\" + 0.008*\"file\" + 0.007*\"public\" + 0.007*\"internet\" + 0.007*\"email\"'),\n",
       " (5,\n",
       "  '0.010*\"law\" + 0.007*\"state\" + 0.006*\"government\" + 0.005*\"man\" + 0.005*\"child\" + 0.005*\"fact\" + 0.004*\"opinion\" + 0.004*\"person\" + 0.004*\"claim\" + 0.004*\"consider\"'),\n",
       " (6,\n",
       "  '0.013*\"Israel\" + 0.008*\"israeli\" + 0.008*\"Jews\" + 0.007*\"turkish\" + 0.007*\"war\" + 0.006*\"kill\" + 0.006*\"Armenians\" + 0.006*\"armenian\" + 0.005*\"attack\" + 0.005*\"food\"'),\n",
       " (7,\n",
       "  '0.009*\"car\" + 0.008*\"bike\" + 0.006*\"sale\" + 0.005*\"price\" + 0.005*\"ride\" + 0.004*\"sell\" + 0.004*\"buy\" + 0.004*\"old\" + 0.004*\"engine\" + 0.004*\"New\"'),\n",
       " (8,\n",
       "  '0.007*\"gun\" + 0.007*\"space\" + 0.006*\"Space\" + 0.006*\"NASA\" + 0.005*\"President\" + 0.005*\"program\" + 0.004*\"launch\" + 0.004*\"rate\" + 0.004*\"money\" + 0.004*\"firearm\"'),\n",
       " (9,\n",
       "  '0.014*\"file\" + 0.010*\"drive\" + 0.009*\"program\" + 0.009*\"card\" + 0.009*\"window\" + 0.007*\"Windows\" + 0.007*\"version\" + 0.006*\"set\" + 0.006*\"image\" + 0.006*\"disk\"')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualization and interpretation\n",
    "\n",
    "Once we have settled on the number of topics and passes, let's visualize the topics and interpret them. In particular,  \n",
    "\n",
    "1. Visualize the topics using [pyLDAvis](https://github.com/bmabey/pyLDAvis), which is a Python library for interactive topic model visualization. Note: Use `sort_topics=False`. Otherwise the topic ids in the previous exercise won't match with the topics here.\n",
    "2. Using the words in each topic and their corresponding weights, manually assign a label (e.g., sports, politics, religion) to each topic.\n",
    "3. Create a dictionary with keys as the topic id and your manually-assigned topic label as the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "topic_labels = {0:'Automobiles',\n",
    "              1:'Hardware, graphic cards',\n",
    "              2:'Politics and guns',\n",
    "              3:'Medicine',\n",
    "              4:'Windows, graphic cards, technology',\n",
    "              5:'Sports',\n",
    "              6:'Religion',\n",
    "              7:'Windows, technology', \n",
    "              8:'Space',\n",
    "              9:'Security, cryptography'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el818721406648530071849217669371\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el818721406648530071849217669371_data = {\"mdsDat\": {\"x\": [0.08571016298216066, 0.12451812971813002, -0.003980018544071841, -0.09582957363466589, -0.21773294115042388, 0.14229440624512912, 0.17222382869529107, 0.009874612702673511, -0.005645986469124144, -0.21143262054509884], \"y\": [-0.22320524924980364, 0.11464696426454714, -0.10130981595342649, 0.13934676003235807, 0.08419864097058916, 0.10731047662155861, 0.09078046947417703, -0.20036892107167426, 0.023337822102263518, -0.03473714719058919], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [8.22293567624207, 10.58989675424956, 10.087342115587132, 6.344695446469839, 7.339930589928842, 12.595414344502295, 8.682405408892746, 9.235252959783049, 10.55555279229903, 16.346573912045432]}, \"tinfo\": {\"Term\": [\"God\", \"key\", \"game\", \"file\", \"team\", \"Jesus\", \"car\", \"chip\", \"Israel\", \"play\", \"card\", \"player\", \"information\", \"window\", \"law\", \"program\", \"gun\", \"drive\", \"win\", \"encryption\", \"Windows\", \"list\", \"buy\", \"israeli\", \"bike\", \"season\", \"available\", \"Bible\", \"send\", \"Jews\", \"player\", \"season\", \"hockey\", \"game\", \"baseball\", \"playoff\", \"NHL\", \"Detroit\", \"Montreal\", \"Leafs\", \"Hockey\", \"coach\", \"Wings\", \"ESPN\", \"simm\", \"pitcher\", \"score\", \"hitter\", \"Pens\", \"Cubs\", \"Braves\", \"Alomar\", \"DET\", \"VESA\", \"VAN\", \"Sox\", \"puck\", \"CAL\", \"TOR\", \"QUE\", \"Roger\", \"BOS\", \"team\", \"league\", \"Cup\", \"play\", \"fan\", \"win\", \"stat\", \"Rangers\", \"Jose\", \"Minnesota\", \"pitch\", \"Boston\", \"Toronto\", \"goal\", \"hit\", \"lose\", \"shot\", \"Chicago\", \"Pittsburgh\", \"San\", \"period\", \"well\", \"second\", \"bad\", \"New\", \"pick\", \"great\", \"David\", \"Jesus\", \"Bible\", \"Lord\", \"Banks\", \"scripture\", \"doctrine\", \"God\", \"Holy\", \"sin\", \"Spirit\", \"revelation\", \"eternal\", \"Satan\", \"bible\", \"Son\", \"CHI\", \"verse\", \"salvation\", \"Testament\", \"catholic\", \"PIT\", \"BUF\", \"intellect\", \"STL\", \"shameful\", \"resurrection\", \"Weiss\", \"chastity\", \"Skepticism\", \"heaven\", \"Christ\", \"Christians\", \"faith\", \"Christian\", \"church\", \"Gordon\", \"Christianity\", \"Church\", \"prayer\", \"god\", \"biblical\", \"belief\", \"christian\", \"disease\", \"atheist\", \"truth\", \"worship\", \"love\", \"evidence\", \"life\", \"book\", \"religion\", \"word\", \"die\", \"exist\", \"Paul\", \"true\", \"man\", \"claim\", \"reason\", \"accept\", \"follow\", \"John\", \"fact\", \"militia\", \"detector\", \"voltage\", \"revolver\", \"Intergraph\", \"sensor\", \"aluminum\", \"Oracle\", \"volt\", \"Novell\", \"Hezbollah\", \"UPS\", \"NETCOM\", \"Amanda\", \"Beth\", \"SHO\", \"wagon\", \"watt\", \"fuse\", \"Myrto\", \"Keller\", \"Templeton\", \"steering\", \"Hard\", \"Borland\", \"BeHanna\", \"InterCon\", \"Frost\", \"convertible\", \"copper\", \"wire\", \"outlet\", \"wiring\", \"radar\", \"circuit\", \"cop\", \"auto\", \"receiver\", \"amp\", \"Express\", \"battery\", \"Online\", \"Communication\", \"ground\", \"car\", \"automatic\", \"buy\", \"Reserve\", \"Communications\", \"screw\", \"gun\", \"light\", \"police\", \"NEC\", \"power\", \"unit\", \"USA\", \"Texas\", \"switch\", \"little\", \"cheap\", \"speed\", \"sell\", \"drive\", \"well\", \"high\", \"control\", \"carry\", \"company\", \"opinion\", \"bad\", \"driver\", \"old\", \"end\", \"price\", \"pay\", \"hear\", \"current\", \"escrow\", \"DES\", \"NSA\", \"encrypt\", \"crypto\", \"Clipper\", \"wiretap\", \"key\", \"cipher\", \"decrypt\", \"methodology\", \"Jupiter\", \"Sternlight\", \"physics\", \"comet\", \"Baalke\", \"plaintext\", \"blah\", \"ink\", \"homeopathy\", \"Toal\", \"NIST\", \"CMOS\", \"cryptosystem\", \"atom\", \"Denning\", \"clipper\", \"Hellman\", \"escrowe\", \"Allah\", \"encryption\", \"Chip\", \"secure\", \"science\", \"tap\", \"algorithm\", \"secret\", \"chip\", \"PGP\", \"scheme\", \"random\", \"rsa\", \"cryptography\", \"security\", \"Key\", \"theory\", \"enforcement\", \"block\", \"method\", \"phone\", \"agency\", \"code\", \"government\", \"bit\", \"law\", \"message\", \"datum\", \"example\", \"value\", \"exist\", \"led\", \"RISC\", \"recipient\", \"Vesselin\", \"CompuServe\", \"Hamburg\", \"telnet\", \"relay\", \"Nyx\", \"odometer\", \"Type\", \"Rider\", \"Singapore\", \"infrastructure\", \"projection\", \"Bontchev\", \"Micro\", \"authorization\", \"Virus\", \"Cliff\", \"cd\", \"Kipling\", \"alias\", \"fpu\", \"Standards\", \"Bethesda\", \"nickname\", \"countersteere\", \"Operation\", \"symmetric\", \"anonymous\", \"mailing\", \"Electronic\", \"forum\", \"newsgroup\", \"list\", \"Information\", \"van\", \"Board\", \"internet\", \"information\", \"address\", \"archive\", \"Administration\", \"faq\", \"Security\", \"request\", \"network\", \"send\", \"license\", \"Public\", \"copy\", \"Denver\", \"access\", \"email\", \"site\", \"review\", \"privacy\", \"FTP\", \"user\", \"available\", \"public\", \"group\", \"electronic\", \"product\", \"message\", \"FAQ\", \"contact\", \"service\", \"National\", \"file\", \"issue\", \"book\", \"provide\", \"phone\", \"company\", \"info\", \"computer\", \"moral\", \"morality\", \"homosexual\", \"sex\", \"gay\", \"BATF\", \"Waco\", \"ATF\", \"cult\", \"motto\", \"homosexuality\", \"Cramer\", \"libertarian\", \"Sabbath\", \"abortion\", \"Livesey\", \"Rushdie\", \"Atheists\", \"justification\", \"Sandvik\", \"Beauchaine\", \"Davidians\", \"Roby\", \"GOD\", \"marriage\", \"Livni\", \"jury\", \"Mozumder\", \"Islam\", \"Tavares\", \"sexual\", \"islamic\", \"Clayton\", \"Constitution\", \"society\", \"Schneider\", \"FBI\", \"guilty\", \"objective\", \"Koresh\", \"law\", \"atheism\", \"crime\", \"abuse\", \"action\", \"male\", \"state\", \"child\", \"judge\", \"argument\", \"freedom\", \"government\", \"human\", \"person\", \"court\", \"man\", \"death\", \"opinion\", \"claim\", \"fact\", \"religious\", \"consider\", \"country\", \"act\", \"fire\", \"kill\", \"wrong\", \"rule\", \"religion\", \"life\", \"evidence\", \"feel\", \"reason\", \"group\", \"issue\", \"woman\", \"make\", \"Israel\", \"israeli\", \"turkish\", \"Armenians\", \"armenian\", \"Turkey\", \"Turks\", \"soldier\", \"Armenia\", \"arab\", \"village\", \"MSG\", \"Argic\", \"Serdar\", \"Greece\", \"Arabs\", \"massacre\", \"Lebanon\", \"lebanese\", \"genocide\", \"Palestine\", \"Israelis\", \"Azerbaijan\", \"palestinian\", \"Bosnia\", \"Nazi\", \"Armenian\", \"Gaza\", \"Davidian\", \"Palestinians\", \"territory\", \"occupy\", \"Jews\", \"war\", \"greek\", \"food\", \"civilian\", \"border\", \"jewish\", \"attack\", \"kill\", \"peace\", \"land\", \"live\", \"country\", \"happen\", \"leave\", \"government\", \"state\", \"force\", \"call\", \"Center\", \"bike\", \"BMW\", \"tire\", \"helmet\", \"rider\", \"motorcycle\", \"Honda\", \"SALE\", \"Dare\", \"Islanders\", \"Toyota\", \"Sale\", \"drain\", \"Pts\", \"fluid\", \"Oilers\", \"Canucks\", \"Daryl\", \"Annual\", \"AAA\", \"captain\", \"forsale\", \"Whalers\", \"Bure\", \"valve\", \"Halifax\", \"muscle\", \"Nye\", \"xxdate\", \"Keenan\", \"biker\", \"Ottawa\", \"temperature\", \"AMA\", \"ride\", \"Buffalo\", \"oil\", \"engine\", \"Murray\", \"ticket\", \"cool\", \"dog\", \"sale\", \"insurance\", \"wheel\", \"mile\", \"water\", \"brake\", \"car\", \"seat\", \"air\", \"price\", \"sell\", \"usa\", \"Distribution\", \"Nntp\", \"offer\", \"Canada\", \"Posting\", \"buy\", \"New\", \"old\", \"turn\", \"John\", \"State\", \"Reply\", \"condition\", \"Article\", \"pay\", \"week\", \"great\", \"change\", \"big\", \"drive\", \"Space\", \"NASA\", \"orbit\", \"satellite\", \"Gun\", \"lunar\", \"Mars\", \"spacecraft\", \"Moon\", \"Senate\", \"Shuttle\", \"homicide\", \"shuttle\", \"Propulsion\", \"JPL\", \"funding\", \"Veal\", \"Zoology\", \"landing\", \"ADL\", \"Venus\", \"atmosphere\", \"launcher\", \"Kratz\", \"Senator\", \"payload\", \"ozone\", \"Alaska\", \"orbital\", \"Observatory\", \"launch\", \"Henry\", \"firearm\", \"Jet\", \"fund\", \"solar\", \"mission\", \"billion\", \"Earth\", \"moon\", \"investment\", \"probe\", \"tax\", \"health\", \"President\", \"space\", \"Medical\", \"flight\", \"rocket\", \"gun\", \"Clinton\", \"drug\", \"States\", \"rate\", \"increase\", \"money\", \"bill\", \"job\", \"project\", \"United\", \"cost\", \"April\", \"program\", \"report\", \"Center\", \"high\", \"pay\", \"control\", \"support\", \"National\", \"Windows\", \"DOS\", \"Mac\", \"graphic\", \"SCSI\", \"controller\", \"IDE\", \"mouse\", \"font\", \"widget\", \"interface\", \"printer\", \"Motif\", \"motherboard\", \"JPEG\", \"meg\", \"ISA\", \"app\", \"cache\", \"xterm\", \"cpu\", \"ATI\", \"menu\", \"Quadra\", \"pixel\", \"bios\", \"workstation\", \"vga\", \"Xlib\", \"Diamond\", \"Apple\", \"screen\", \"card\", \"format\", \"jumper\", \"window\", \"entry\", \"port\", \"keyboard\", \"client\", \"upgrade\", \"color\", \"ram\", \"disk\", \"floppy\", \"video\", \"display\", \"file\", \"image\", \"software\", \"memory\", \"mode\", \"program\", \"drive\", \"version\", \"driver\", \"monitor\", \"server\", \"set\", \"application\", \"machine\", \"support\", \"available\", \"source\"], \"Freq\": [2875.0, 2114.0, 1781.0, 2719.0, 1522.0, 1256.0, 1696.0, 1213.0, 1039.0, 1364.0, 1475.0, 902.0, 1717.0, 1478.0, 1686.0, 2108.0, 1436.0, 2382.0, 1079.0, 800.0, 1092.0, 1367.0, 1328.0, 668.0, 678.0, 645.0, 1502.0, 696.0, 1576.0, 789.0, 900.913404680471, 644.7128280784264, 445.4293160421205, 1778.0798735057103, 336.8440578161934, 301.2685939863144, 442.7606992690234, 230.04272425868413, 215.28498919684165, 181.3861577039365, 218.02150359180706, 167.38551996069242, 155.4669495159696, 147.6763521788026, 137.0697194888954, 135.07515685362, 469.40329981086234, 132.84785655998508, 126.01217903535156, 124.48887177505486, 119.74641525511544, 118.0548089547128, 136.44873351096976, 109.6439481469026, 118.72282112538498, 107.46489327705333, 103.2291491769789, 101.79797062653573, 107.25811169281585, 97.34327069451452, 258.6925764699465, 122.07056764996295, 1450.8167318845515, 329.5080078730984, 196.05161052312792, 1147.3534859024278, 428.1760950147382, 858.1521724222468, 210.9060712474085, 155.2505585848755, 174.82467169299315, 169.79101764420287, 174.8639760891585, 262.2086220346304, 308.9503636640622, 306.67106994011385, 334.7966528045477, 328.1131714389625, 213.75950538335658, 244.57380878602171, 243.9626760011605, 245.84412109002716, 237.83135276350646, 297.1702617400211, 260.1988415897184, 271.9977106404212, 251.19510033726993, 227.09720656958768, 239.06199941770532, 236.0262586317128, 1255.3334201036303, 694.760694797774, 281.89097548367033, 270.7207021632088, 232.7758191383404, 198.7692394110992, 2862.5963510507054, 186.56096908087565, 383.9803843584654, 166.49301526114385, 153.31941841236215, 194.13508824579432, 141.79865652244865, 134.77787057592468, 133.94305551412037, 128.2874466217827, 120.98706305393215, 113.9254057716063, 107.85618687003387, 108.74284130112362, 102.11639279598472, 95.6585879827808, 88.91836503062595, 87.75006592211939, 85.6081415761888, 87.82180011778192, 82.62969822687877, 81.96071215488531, 80.67771393482204, 181.74524636656588, 567.4725604780479, 550.8827992066584, 555.672770885833, 371.2165476577488, 425.39430633427264, 329.5871265044409, 308.574398144057, 265.8510581305218, 148.16626874217627, 347.35129315960614, 168.32450238788826, 490.9940331823545, 419.8415736414704, 276.68724259225445, 396.15876301737114, 454.98692136691625, 174.82221897935176, 432.6177159407296, 457.77287165773987, 590.5978274615668, 535.2471521693328, 381.7852191076876, 465.2110360576647, 373.96311538083614, 454.31195114515896, 354.717577976362, 426.07197494814886, 452.26461591089856, 419.2308530665457, 416.1608272191981, 334.9618351033946, 374.0179904412554, 360.43963477462916, 358.21013481033765, 213.8372669153603, 200.9750341920526, 138.6020820102215, 95.82319727449756, 93.29192487113808, 95.5631943824309, 70.15859741622727, 67.62448323931167, 67.12900090845895, 65.5815915026744, 65.55902349981349, 65.14066236086788, 64.13775449489927, 63.83825482806621, 61.77983027846331, 59.98454952854174, 59.80137423384324, 58.43039852740085, 57.44571014140513, 57.132622032986944, 57.12101673941954, 57.093341299485054, 57.05073685422161, 56.41264513072009, 55.32033495788545, 55.256165162809175, 54.33244472955944, 53.84842920428406, 52.870249753821376, 50.35397836954567, 413.2592857077905, 187.6241715236406, 165.67598551106443, 200.3601696742447, 267.7390970886132, 217.92891120037436, 224.3376922189906, 116.39101255538534, 135.74312486429105, 111.57170805441564, 182.58580118046729, 188.14544031824332, 98.55700559356656, 402.1606587613169, 934.6044370487207, 158.07470102856172, 713.6461620004013, 159.40943719776402, 205.5787073529723, 160.36821725057848, 672.9918049016978, 368.4555403717357, 281.1052266730499, 155.9900579326798, 606.8536190879151, 243.95645484348606, 417.6431728889583, 249.10470709749612, 245.1583090164617, 439.25013557305476, 256.84060190634153, 322.4621499639093, 331.1415135933877, 507.4503964798585, 383.9292134260914, 405.16821906010614, 334.42115293697725, 277.0936395253323, 275.4047507888979, 298.56672309967365, 290.5689419620967, 269.9214462312454, 279.66397662092925, 274.36843961972573, 258.305273047342, 257.68684107891, 264.42429287458646, 252.2306136930749, 351.04615725785413, 313.31342720827865, 298.1386538160479, 268.95768806370535, 213.4886942457994, 410.3334987965615, 165.1342360451789, 2100.277387651855, 133.19207810382244, 105.49007507279602, 104.9510028226309, 85.63104751219122, 84.7523469921603, 78.00444935326377, 72.74286614943257, 71.6556975075808, 69.79741423060224, 65.81603267579489, 65.67941623214273, 57.98376074311618, 56.861715013762286, 54.715910044699584, 53.37945210648401, 51.93671486756143, 51.59648731107722, 50.57237268046679, 315.23978526404005, 49.35684869131326, 48.21989048098943, 47.045839216365145, 745.9235803108791, 201.98976379126952, 300.9073022455468, 459.0250626884912, 188.20003933248955, 389.93584496653085, 339.22688720043266, 846.6251392805943, 217.62133295571584, 160.10057687292002, 165.12662649881483, 125.6454847084538, 121.74637266314693, 300.0449148647451, 113.36754436602193, 237.95319068980342, 196.59497171537228, 213.37049541299, 228.98525667832445, 302.91839664177286, 197.30697996564533, 301.8024413368899, 372.9068509031185, 322.2504073690714, 267.0876908238714, 228.98488038207566, 221.09911863447863, 216.2141243542817, 203.66647019131645, 203.3320125106468, 93.99605617071046, 114.52263816070206, 71.49377131651785, 70.02634771682803, 65.03954367128053, 64.85385849381632, 62.95765437611773, 60.371528672132115, 57.909760080507326, 55.726775208554635, 55.390843325423056, 54.55335952189186, 53.70841880607403, 51.38114469675649, 50.02890419193323, 45.53747693725932, 44.56746566395919, 44.34104156082952, 43.84234342091582, 42.74629420691782, 42.47715207329418, 42.31844882601742, 41.545215391053304, 40.830464302233466, 47.45321413438552, 39.4329059245244, 39.38749131331704, 38.63704781460627, 37.871767075826774, 37.825844588431245, 296.9222839483641, 167.56272011848637, 81.19052239284508, 80.68160626771699, 349.6973270896641, 865.641845986022, 179.27577996948793, 87.17372308889725, 91.54011203219605, 472.8795847812867, 960.0709593147067, 581.5893703686708, 238.08879381989462, 120.61561266714041, 142.05882249998658, 120.59100082583109, 321.1693895393097, 256.4396019736529, 746.5907015781462, 231.5856891376909, 218.21121310617167, 442.30495456176243, 146.81067334705384, 371.63464402291345, 463.35402022648043, 338.9218389281341, 178.33293604149156, 199.2679472250945, 183.91151258458027, 435.7913698947234, 598.2151407724343, 497.30181898035664, 562.1706356371436, 177.85904725029368, 290.1916829799668, 444.44938518181146, 242.16412133821046, 273.80672650466437, 272.3634874853637, 291.10276449238546, 560.1100448957768, 359.22282715225606, 360.8311017481321, 353.3955686305529, 284.91838033360307, 252.1684760925068, 254.27911279222548, 254.29313984885115, 438.86417428315684, 293.30414601535404, 259.6258796675667, 256.8079308500719, 234.50781312426287, 215.51347519993575, 172.80720923611472, 141.98248577120896, 141.047563998557, 128.14154046569396, 121.90171958215224, 117.90666271033965, 104.8205315465777, 101.20362530608259, 97.82063972188651, 94.7425070016345, 88.69682110317055, 81.96830463047783, 80.76369521510728, 77.62110445067741, 73.70712679271318, 72.41002537533099, 68.7114035715869, 66.17280522412223, 191.5272805687753, 64.58808079450185, 64.43276312286179, 63.69311761410392, 276.4143538956981, 60.81385099838646, 215.33875578841815, 199.33459603023152, 150.19079819083314, 184.68272024940677, 309.43593532941253, 98.64530704404004, 378.60730884818554, 126.36909987973249, 307.920427730792, 258.45272804647885, 1220.5035420171755, 195.73597100132156, 426.9729897074539, 185.86086582992118, 430.79667491894344, 182.738880335757, 806.8011210470431, 583.2878208582814, 259.91165588317483, 423.943800556319, 221.8612679763433, 676.1205741402471, 463.15421191942994, 517.6923712952355, 252.41025847922458, 587.5754877849175, 357.32936193132633, 524.1834118551952, 505.6971297588488, 543.4553917897487, 280.6272636014441, 481.77670045487395, 378.3127067430645, 309.36101210433105, 330.8301128476629, 416.15729095352646, 391.0717612317499, 356.95170239574196, 341.4453062056651, 404.4733349435032, 354.84707358897504, 346.92623892792153, 375.2063533102633, 370.181655440885, 344.58790388693626, 322.27760457071736, 333.7954733871793, 1038.2606001428694, 667.1801542293329, 606.6967789061923, 513.8921090300898, 477.7280808553479, 356.0985031923442, 343.4811787839021, 307.96164946903536, 297.8450409043135, 285.1107672161758, 275.43967971696117, 267.3567908996406, 240.24612840088074, 239.95894277569207, 218.05187477663193, 164.7286676085557, 161.64351051777197, 153.02069441601185, 149.5168695842173, 185.82317460607754, 140.71183994393593, 140.00599611371808, 136.8218459967993, 136.29031037626484, 138.0048703518027, 134.7154716047469, 130.24628120048752, 127.56244589998357, 113.77359753048077, 107.30496923306873, 156.88959477160518, 179.3799024840333, 640.5158710344342, 549.4797824702588, 237.9202833897648, 383.6714510124581, 212.94907560361054, 208.12278175626224, 346.86774918458633, 389.9127128979504, 529.9018780039497, 279.74717801533995, 274.97638358154586, 364.5815218022307, 289.9907867844802, 315.53779621826834, 302.83777577643417, 307.2172135208358, 276.1994685957144, 242.07032355814243, 246.52643059549524, 241.88084360155793, 677.85141347144, 208.0644604021572, 181.16022244472646, 173.0629216282661, 165.01406464081666, 214.0081408954903, 143.5327055853108, 134.6826387876494, 116.64331724380799, 116.09398288627591, 78.40264006495674, 81.61902731655182, 75.05630853081165, 72.88768644405224, 70.42868539227513, 66.03672383274304, 65.64228090965635, 62.94870359916463, 61.850075456821585, 60.011618959722945, 108.82976175246309, 60.07389808663396, 58.456841857067936, 55.44344500079969, 55.588431619702966, 54.60151539335903, 78.76901680821236, 52.97831239654413, 64.76380542367164, 51.130006871394905, 69.53750557299139, 168.88539197141517, 94.25444784876973, 74.66653654224329, 409.2702645907639, 110.88244728863734, 244.34276185044536, 341.59585837135813, 129.858684251639, 184.51298982675834, 191.72026714648672, 216.8860451495961, 525.8888831905933, 278.8654613697411, 132.37913268954426, 245.65776431449294, 247.6185222078016, 137.18387604210687, 760.6023588480094, 133.99465729888823, 194.45628859485453, 430.5732558210694, 391.3675108261944, 309.28467644822024, 229.10557500402808, 288.49030484980824, 286.9055952221509, 274.60788173413096, 318.44214246740694, 358.18040442691193, 334.99086281021647, 342.2246544031933, 296.50260581553334, 323.63559277460865, 273.01371866245387, 279.99380903030067, 221.7581189328485, 240.42660166301513, 253.56031606960286, 243.34073735707634, 260.5510364903817, 261.36892168897174, 243.799168532951, 246.80171218632105, 646.5348363182992, 560.7595880237457, 344.96656063503667, 287.1579211903481, 177.33722441468097, 170.66823637563402, 162.9641307242015, 133.58992376368326, 131.7941594467054, 131.16722963548108, 126.67802172543921, 117.98352533647927, 111.46642086081141, 100.37691509667191, 100.19013576001056, 96.2919822557372, 86.04734837655401, 85.52144820528595, 83.34969062615177, 80.52745148714779, 75.8733987265077, 72.86453676012455, 72.73041989859102, 72.58770661981869, 72.48168027611338, 71.87108539663483, 69.41209270825098, 68.9696119843758, 68.74532838639615, 67.61775436473282, 431.5332821661286, 169.9871891326218, 393.9698487458733, 100.16539570014865, 277.7374999708757, 114.53239132526382, 254.648972427467, 244.056818382201, 301.8868590220654, 261.9059716362404, 92.89112830057663, 152.49730003746754, 322.21326438074095, 303.9159149157074, 526.9791810391326, 715.0651267476435, 136.729720236196, 161.87804905223163, 178.5715493600596, 719.5724549545757, 345.7639232578964, 345.9701677119468, 249.67035419546136, 405.8686350248773, 302.699408841935, 401.98859602085423, 178.48694160145033, 318.8596066691126, 254.66186415500516, 243.20026047084318, 367.4242050586865, 306.0415892062047, 483.4851819663557, 330.1057144616564, 317.05803411877446, 354.7036407088054, 292.3321644317773, 279.358982507205, 268.7323732333028, 257.1800173520466, 1091.892933534623, 729.4288270597218, 655.0924990717899, 584.6094493778081, 524.5971678195951, 477.107825273249, 424.44870119594856, 416.6523764951171, 406.86194293363144, 390.01505345809346, 390.6289955360527, 382.19567630586124, 332.3676948814309, 227.97301697991168, 207.01331164231684, 205.22742889641793, 204.54553235696977, 194.36198627533574, 192.55752153006006, 187.50567734587486, 186.76697554456382, 172.8953244967731, 164.9703620901112, 166.12109952977653, 160.49762995606787, 156.0073571327578, 155.0770183639612, 154.42275244967328, 149.39297326764657, 148.89698649007897, 495.70637789003644, 576.2184647896751, 1422.5205274077498, 609.8523863630485, 179.798582149297, 1388.3780515209985, 695.2429752208021, 465.81233953035843, 341.6134873481402, 339.96721197147195, 317.4360978633935, 784.7524841722919, 297.19381928434495, 882.9259804969613, 288.3564537778501, 598.58440556996, 659.0036598449581, 2116.44541947276, 927.878045284929, 832.905248980445, 608.3304218691674, 533.8966775250825, 1448.3437254749776, 1541.583350869476, 1061.4304475766191, 815.461293832179, 528.3850590200861, 591.3861160374764, 929.1174197593027, 623.6778966007926, 640.0039873923488, 710.2812167570019, 607.8314547902504, 561.2852519456048], \"Total\": [2875.0, 2114.0, 1781.0, 2719.0, 1522.0, 1256.0, 1696.0, 1213.0, 1039.0, 1364.0, 1475.0, 902.0, 1717.0, 1478.0, 1686.0, 2108.0, 1436.0, 2382.0, 1079.0, 800.0, 1092.0, 1367.0, 1328.0, 668.0, 678.0, 645.0, 1502.0, 696.0, 1576.0, 789.0, 902.037391879455, 645.6513227225862, 446.34697382582885, 1781.8878358208772, 337.75580365712966, 302.1804028612697, 444.2948553090078, 230.9545695297899, 216.3473107401409, 182.29782530153554, 219.18442972180748, 168.29910095163203, 156.3788068919846, 148.58839598007856, 137.98147108970971, 135.98682169972216, 472.59113500975127, 133.75954836614082, 126.92467565429254, 125.40053995524752, 120.65808792127592, 118.96647251851225, 137.55291097925138, 110.55595924855736, 119.71497068528511, 108.37656350711052, 104.14081413906291, 102.71242830197905, 108.24553719053836, 98.2549522334681, 261.44328223858895, 123.31437060858285, 1522.099367391394, 339.37795131266404, 201.8915831553838, 1364.5309401363954, 487.04552231331087, 1079.4772076781176, 229.54016474516084, 163.11269095091268, 191.8487645847327, 186.64419296273803, 194.32672440076314, 347.75703122496645, 477.413340522526, 524.0301601302809, 617.9559102338638, 746.2793678209331, 325.06842826999696, 483.16044608023566, 484.69680906822083, 538.4098839772421, 500.4312093096163, 1320.9236910542068, 1073.0582530509596, 1534.5924673674035, 1298.9254542052129, 502.1430227668741, 1379.4759994973986, 1457.019377274642, 1256.2480089914689, 696.4167349870871, 282.80464551864776, 271.634215952493, 233.69577187801445, 199.68312792448222, 2875.973590921978, 187.4748215265019, 386.0115588048222, 167.4064494802745, 154.2329206097972, 195.31689802116773, 142.71813732965313, 135.69145166235782, 134.85648607773487, 129.20104157699566, 121.90317016061906, 114.83890736990787, 108.76960010315457, 109.68068948018173, 103.03015745588026, 96.57217922356523, 89.8318094209563, 88.66375463868964, 86.52165700906467, 88.78946520023383, 83.54330940947955, 82.87412842126372, 81.59113000229556, 183.83471848192997, 575.933439518874, 568.9052076724109, 578.405298941104, 386.17214025597076, 446.5321872880795, 343.9962807418429, 323.2084884306337, 283.77198669176124, 153.90060180637388, 395.9551395858888, 177.9871349552177, 590.9664223328125, 535.5340338403205, 335.6255201761703, 541.7366890234815, 649.1005677061426, 190.4998015230776, 806.8262150152825, 904.6825281264038, 1379.7566206846006, 1231.6418204453503, 742.3339982590304, 1168.7580843265177, 773.4975575321189, 1157.4911319840878, 703.2894289198135, 1310.378288083891, 1555.4248541728905, 1291.6852856221576, 1414.7553866796031, 777.6036166207194, 1612.0260909862277, 1316.3761720961845, 1649.6770778581006, 214.75017802778837, 201.8878768305041, 139.92228346791146, 96.74952345993265, 94.2048569451322, 96.68460082848993, 71.08904389944426, 68.53735208661976, 68.05114321294151, 66.4946164240107, 66.47203581546101, 66.05915519651107, 65.05130620138519, 64.75109111392858, 62.69283678369443, 60.897370453799525, 60.714319329951, 59.35752865968147, 58.359655984603265, 58.04567389087543, 58.034124234393595, 58.0063472180758, 57.964227628982165, 57.32568479512049, 56.23360207340143, 56.16897985007414, 55.245269344850676, 54.76136386913748, 53.78309556343808, 51.266887661893676, 438.8807327567124, 200.33368195463004, 176.23255529932072, 216.3947486703295, 297.9988568575842, 239.77736105480847, 247.35436808174214, 124.07151485831976, 146.85612391908998, 119.58181392328905, 210.91873433002854, 218.4222445236682, 108.99968714945027, 598.350956273875, 1696.0206193895358, 201.38992411762084, 1328.7108755584202, 208.8033051303939, 296.4059375955453, 215.5986393962365, 1436.1691350037654, 662.9325241538423, 469.50213886824804, 213.40945632175232, 1501.2228683922629, 420.684095049655, 976.8487396535636, 443.12831229627864, 432.0365201548618, 1367.5312102730513, 531.6599846127941, 837.680547115733, 950.627364467677, 2382.7097568123545, 1320.9236910542068, 1548.6961413029132, 1084.0155910030658, 722.3519623252512, 728.7337924834912, 1354.9230443177, 1534.5924673674035, 1126.849784817914, 1380.7394207580455, 1398.4318533194262, 962.5461983962018, 959.5405512072438, 1494.251954323913, 821.5303087706917, 351.96430696114624, 314.22927590992987, 299.05750083015045, 269.87356890195144, 214.40593223156145, 412.14922110294754, 166.0713205440443, 2114.216330990447, 134.1079207510772, 106.4059169992806, 105.86688777539838, 86.54705385103951, 85.7244776435598, 78.92093380267863, 73.65885360878471, 72.57176846691321, 70.71325449069163, 66.732016986874, 66.67009527911422, 58.899669526972886, 57.777576756993554, 55.63181223624048, 54.29579543187066, 52.852548323294116, 52.51246763322707, 51.48863502747168, 320.9861984076678, 50.272688606724294, 49.135728991742845, 47.96210774167669, 800.216624680569, 211.55016830528476, 332.95177668688723, 528.5748455715818, 206.7537800674504, 455.83714960095404, 407.76178673574725, 1213.1706777628772, 270.86052849267026, 194.77112541331564, 205.26125744623187, 148.17017262618512, 148.20580726938712, 506.79350705062274, 137.3838089068149, 401.9383895599453, 321.69179962697274, 387.80936163346246, 473.7231936674098, 820.4540154345914, 377.07362524565315, 925.3005020560983, 1718.089655070843, 1307.377945565917, 1686.2778614013669, 1250.2115103793305, 1045.3989167172356, 1171.3520024249242, 798.2780856121292, 1157.4911319840878, 94.90445708995968, 115.82725381753494, 72.40777873091145, 70.93451828560023, 65.94799297275864, 65.76206077725134, 63.86582542509486, 61.27979130881033, 58.81795659155073, 56.635005178464404, 56.29971241954895, 55.46157241988904, 54.61665541750881, 52.28974425792426, 50.93738406334139, 46.44564679117854, 45.47577316722749, 45.24933448484088, 44.750527644520545, 43.65466857551362, 43.385516789510945, 43.2273899219556, 42.45350404208114, 41.73868321455599, 48.52552201824967, 40.341078298537575, 40.29597380679598, 39.54538908560161, 38.78064126404763, 38.734200504245464, 332.37497130969814, 186.3771219047046, 87.6699708274847, 89.6306773129274, 473.1571361349859, 1367.5900967231898, 225.45753046934203, 99.106178833337, 105.43553682405576, 719.3437071329586, 1717.4416176576647, 963.679803372629, 336.0174077418251, 149.95010957141963, 184.57013631250547, 151.369510675459, 522.083566991602, 400.3199330972127, 1576.103686064244, 352.2957854132694, 327.7951393627221, 823.8518039297008, 196.88031319928535, 685.5637497678442, 927.4633971954917, 620.6861033084548, 260.7869360766577, 304.2536095958493, 278.22401970868304, 943.4811052346126, 1502.1679070648338, 1163.751861321405, 1570.1649816703114, 274.65780516349463, 591.0767291775112, 1250.2115103793305, 456.80196234236485, 581.8420949842562, 591.7106513043212, 701.9728696700661, 2719.23414727006, 1203.8806784184371, 1231.6418204453503, 1272.017619574687, 820.4540154345914, 728.7337924834912, 856.7211061917459, 892.7421940909647, 439.780196058604, 294.2162145354227, 260.5379370190108, 257.72014833850074, 235.41991520708578, 216.42555069164905, 173.7196410602875, 142.89454118026967, 141.9596777956311, 129.05359770896104, 122.81593451959955, 118.81872108691508, 105.76300191763964, 102.11576428561932, 98.73278886341171, 95.6545909669585, 89.60886438017098, 82.88035236026636, 81.67622752249936, 78.53316709441404, 74.61917192147807, 73.32210315492495, 69.62346570286327, 67.08510785141667, 194.21752723948933, 65.50018312586984, 65.34491805744987, 64.60520895879019, 280.5511997439725, 61.725944835068155, 224.44833943203272, 209.00120884920636, 156.7618078626999, 195.40913629504618, 338.82666308951553, 101.85400963264311, 427.80485237388154, 133.05608434857558, 358.8830419527065, 296.78219428415633, 1686.2778614013669, 234.4567343933697, 612.8291386807068, 222.7009614438893, 686.0476240314448, 222.41320070390913, 1705.2767438820408, 1123.9830910296407, 373.9363810188726, 799.0798127389345, 300.3083134378679, 1718.089655070843, 952.8598615578838, 1212.486645349662, 370.9905167666126, 1555.4248541728905, 670.9857621970299, 1354.9230443177, 1291.6852856221576, 1649.6770778581006, 452.3531693917409, 1389.349652006745, 865.6871568968048, 556.6357634207304, 659.7101411146198, 1149.531665650242, 1016.1464597746015, 817.0977608240099, 742.3339982590304, 1379.7566206846006, 904.6825281264038, 925.3775272543188, 1414.7553866796031, 1570.1649816703114, 1203.8806784184371, 714.2298998730269, 1455.6542232788568, 1039.16646746112, 668.0852370176978, 607.601819088564, 514.7971382016443, 478.63311019984326, 357.0035341888979, 344.3862094391071, 308.86679927263293, 298.75007052972296, 286.0158243127794, 276.3447313301063, 268.2618593326547, 241.151158747488, 240.86397528319364, 218.96073042333853, 165.63370944309122, 162.5485688538435, 153.9260221698252, 150.4230815894428, 187.00312272229607, 141.61689676093184, 140.91111879627795, 137.72687399056082, 137.19536004354222, 138.92692029111606, 135.62055277003523, 131.15131821819125, 128.4674960219941, 114.68227501589558, 108.2100402849488, 159.0325172021723, 183.60143197589474, 789.0103449545585, 671.8182529193924, 271.85524076600547, 506.97777605711343, 246.58639135989753, 254.39252091591544, 553.5227563776741, 687.3187340747276, 1149.531665650242, 413.2631243032953, 452.6582545057442, 1254.762147601739, 865.6871568968048, 1338.6655924471504, 1200.9970332932178, 1718.089655070843, 1705.2767438820408, 796.6434373465011, 1584.7296758100847, 931.6031664403132, 678.7637769365567, 208.9768470773976, 182.07240798783872, 173.97508857144481, 165.92656144135364, 215.27023189444478, 144.44486992029107, 135.72730626337471, 117.55550355205796, 117.00627213874148, 79.31478938540825, 82.57971586263471, 75.96853841014217, 73.79991998304247, 71.34091033237159, 66.94905669797873, 66.55483816357977, 63.861021150093976, 62.762538860635594, 60.92399691143958, 110.4881235448682, 60.98998082877022, 59.36916751058461, 56.355750355057786, 56.51684960505854, 55.51382506959026, 80.09872497910415, 53.891129462876556, 65.88734230068178, 52.04219619844811, 70.78062488512299, 175.1420663438882, 97.06117436026021, 76.52854049342658, 447.99888834613967, 115.52782843512843, 269.01984098890006, 399.72510043912985, 139.86661934305658, 204.89852175405184, 226.85822832084256, 262.8523816654546, 728.4403456826903, 352.8777577965998, 151.55881755948653, 324.75266623452984, 350.23636940695224, 165.54351431536583, 1696.0206193895358, 165.79215791932432, 288.81322788566604, 962.5461983962018, 950.627364467677, 767.9055853012877, 448.60287615382634, 749.9765937533142, 742.8117280922091, 681.071892612557, 976.4147456442, 1328.7108755584202, 1298.9254542052129, 1380.7394207580455, 980.0751281085014, 1316.3761720961845, 937.4902851800338, 1054.7976201811198, 489.61604768563893, 722.5382758635606, 959.5405512072438, 841.6651136617824, 1379.4759994973986, 1505.8995482404416, 1080.876957617355, 2382.7097568123545, 647.4460865855362, 562.0715004652511, 345.8803329203605, 288.0690483141777, 178.26178585563335, 171.57927182052288, 163.87518903183926, 134.50096380557446, 132.70524479818374, 132.07832735158058, 127.58906569334714, 118.89456638449565, 112.3774895423087, 101.28938291322751, 101.10122922255464, 97.2030947434747, 86.95842042545682, 86.43479672287138, 84.26099190894986, 81.43851788364765, 76.78447408486109, 73.77576320097319, 73.64154149396012, 73.49887308341646, 73.39274154779221, 72.78213434924002, 70.32314072401012, 69.88081763856817, 69.65643344332547, 68.53016415889789, 440.3451720708005, 173.66823532604354, 406.29752549817334, 102.01246024958316, 291.5742173613543, 117.23726008854656, 267.29915073031486, 255.9650821971368, 319.4646811951395, 277.33481184260546, 94.80008432730864, 161.53960409758238, 362.35169523710476, 350.77715681150835, 672.6900635385491, 1011.160251107754, 147.17964281831496, 183.08356205108888, 217.45194773970147, 1436.1691350037654, 569.9641512275684, 585.4362260333829, 370.41379222272167, 816.7860678418658, 532.0258804240832, 855.8411503095502, 222.77841086264723, 642.4445677014614, 435.26297475901, 402.2826785929153, 957.9452674058059, 692.4983698336551, 2108.4155397912355, 922.1683292759049, 931.6031664403132, 1548.6961413029132, 959.5405512072438, 1084.0155910030658, 1532.9798755072793, 701.9728696700661, 1092.8030043119118, 730.3467806403594, 656.0855652905079, 585.5194939464596, 525.5091119728614, 478.0182048329667, 425.3603024248995, 417.56280543760425, 407.77190578399416, 390.9249951813874, 391.5404326360489, 383.10572399017315, 333.2776540284494, 228.8838141226627, 207.92324539616672, 206.1375773090238, 205.45597805700856, 195.27197571107723, 193.4675423401562, 188.415615917299, 187.6769670519442, 173.8052550927722, 165.88039035044753, 167.04037297877056, 161.40759555324968, 156.91728117703764, 155.98722082278388, 155.332682560437, 150.30290251312806, 149.80692967134866, 500.2445604942603, 583.4137716896378, 1475.8498669436626, 622.2346413180941, 181.16760491683334, 1478.4143892326636, 729.0986256563423, 482.85739436096617, 351.0741766354209, 349.52701004939934, 325.9987454748138, 843.5457056140145, 304.817185289264, 963.0229169834614, 295.85904922812983, 660.3781067043604, 735.0747396826089, 2719.23414727006, 1090.5380276598974, 1014.9962295439984, 709.0487646758746, 606.9430394824201, 2108.4155397912355, 2382.7097568123545, 1526.6276692725921, 1126.849784817914, 617.119055968975, 742.4839243404224, 1580.0974946532876, 843.8361907841818, 946.2922576797048, 1532.9798755072793, 1502.1679070648338, 1254.5439552767084], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.455599784851074, -4.790200233459473, -5.159999847412109, -3.7757999897003174, -5.4394001960754395, -5.551000118255615, -5.165999889373779, -5.820799827575684, -5.8871002197265625, -6.0584001541137695, -5.874499797821045, -6.138700008392334, -6.212600231170654, -6.263999938964844, -6.338600158691406, -6.3531999588012695, -5.107600212097168, -6.369800090789795, -6.422699928283691, -6.434800148010254, -6.473700046539307, -6.4878997802734375, -6.343100070953369, -6.561800003051758, -6.4822998046875, -6.581900119781494, -6.622099876403809, -6.636099815368652, -6.583799839019775, -6.680799961090088, -5.703400135040283, -6.454400062561035, -3.9791998863220215, -5.461400032043457, -5.9807000160217285, -4.213799953460693, -5.19950008392334, -4.504300117492676, -5.907599925994873, -6.214000225067139, -6.095300197601318, -6.124499797821045, -6.09499979019165, -5.689899921417236, -5.525899887084961, -5.533299922943115, -5.445499897003174, -5.465700149536133, -5.894199848175049, -5.759500026702881, -5.76200008392334, -5.754300117492676, -5.787499904632568, -5.564700126647949, -5.6975998878479, -5.653299808502197, -5.732800006866455, -5.833700180053711, -5.782299995422363, -5.795100212097168, -4.3769001960754395, -4.968500137329102, -5.870500087738037, -5.910900115966797, -6.0619001388549805, -6.219900131225586, -3.552500009536743, -6.283299922943115, -5.561399936676025, -6.39709997177124, -6.479499816894531, -6.243500232696533, -6.557600021362305, -6.608399868011475, -6.61460018157959, -6.657700061798096, -6.716300010681152, -6.776500225067139, -6.831200122833252, -6.822999954223633, -6.885900020599365, -6.951200008392334, -7.0243000984191895, -7.037499904632568, -7.06220006942749, -7.0366997718811035, -7.097700119018555, -7.105800151824951, -7.121600151062012, -6.3094000816345215, -5.17080020904541, -5.200500011444092, -5.191800117492676, -5.595200061798096, -5.459000110626221, -5.714200019836426, -5.780099868774414, -5.929100036621094, -6.513700008392334, -5.6616997718811035, -6.386099815368652, -5.3155999183654785, -5.472099781036377, -5.889100074768066, -5.530200004577637, -5.3917999267578125, -6.348299980163574, -5.442200183868408, -5.3856000900268555, -5.130899906158447, -5.229300022125244, -5.567200183868408, -5.369500160217285, -5.587900161743164, -5.393199920654297, -5.640699863433838, -5.457399845123291, -5.397799968719482, -5.473599910736084, -5.480899810791016, -5.697999954223633, -5.587699890136719, -5.62470006942749, -5.630899906158447, -6.098199844360352, -6.160200119018555, -6.531799793243408, -6.900899887084961, -6.927700042724609, -6.903600215911865, -7.212600231170654, -7.2494001388549805, -7.256800174713135, -7.280099868774414, -7.280399799346924, -7.286900043487549, -7.3024001121521, -7.307000160217285, -7.339799880981445, -7.36929988861084, -7.372399806976318, -7.395599842071533, -7.412600040435791, -7.418000221252441, -7.4182000160217285, -7.418700218200684, -7.41949987411499, -7.430699825286865, -7.450300216674805, -7.451399803161621, -7.468299865722656, -7.477200031280518, -7.49560022354126, -7.544300079345703, -5.439300060272217, -6.229000091552734, -6.353400230407715, -6.163300037384033, -5.8734002113342285, -6.07919979095459, -6.05019998550415, -6.706399917602539, -6.552599906921387, -6.748700141906738, -6.256199836730957, -6.226200103759766, -6.872799873352051, -5.466599941253662, -4.623300075531006, -6.400300025939941, -4.89300012588501, -6.391900062561035, -6.137599945068359, -6.385900020599365, -4.951700210571289, -5.554100036621094, -5.824699878692627, -6.413599967956543, -5.055099964141846, -5.966400146484375, -5.428800106048584, -5.945499897003174, -5.96150016784668, -5.378300189971924, -5.914899826049805, -5.687399864196777, -5.660900115966797, -5.234000205993652, -5.512899875640869, -5.459099769592285, -5.651000022888184, -5.839000225067139, -5.845200061798096, -5.764400005340576, -5.791600227355957, -5.865300178527832, -5.829800128936768, -5.848899841308594, -5.909299850463867, -5.9116997718811035, -5.885799884796143, -5.93310022354126, -5.138800144195557, -5.252500057220459, -5.302199840545654, -5.405200004577637, -5.636199951171875, -4.982800006866455, -5.89300012588501, -3.349900007247925, -6.107900142669678, -6.341100215911865, -6.346199989318848, -6.549699783325195, -6.559999942779541, -6.64300012588501, -6.712800025939941, -6.72790002822876, -6.7540998458862305, -6.812900066375732, -6.815000057220459, -6.939599990844727, -6.959099769592285, -6.997600078582764, -7.022299766540527, -7.049699783325195, -7.056300163269043, -7.076300144195557, -5.246399879455566, -7.1006999015808105, -7.124000072479248, -7.148600101470947, -4.3850998878479, -5.691500186920166, -5.292900085449219, -4.87060022354126, -5.762199878692627, -5.03380012512207, -5.173099994659424, -4.258500099182129, -5.617000102996826, -5.923900127410889, -5.89300012588501, -6.166299819946289, -6.197800159454346, -5.29580020904541, -6.269100189208984, -5.527699947357178, -5.718599796295166, -5.63670015335083, -5.566100120544434, -5.286300182342529, -5.715000152587891, -5.289999961853027, -5.078400135040283, -5.224400043487549, -5.412199974060059, -5.566100120544434, -5.601099967956543, -5.623499870300293, -5.683300018310547, -5.684899806976318, -6.602200031280518, -6.404699802398682, -6.875800132751465, -6.896599769592285, -6.9704999923706055, -6.973299980163574, -7.002999782562256, -7.044899940490723, -7.086599826812744, -7.125, -7.13100004196167, -7.146299839019775, -7.161900043487549, -7.206200122833252, -7.232800006866455, -7.326900005340576, -7.348400115966797, -7.353499889373779, -7.364799976348877, -7.390200138092041, -7.396500110626221, -7.400199890136719, -7.418700218200684, -7.435999870300293, -7.285699844360352, -7.470799922943115, -7.4720001220703125, -7.491199970245361, -7.511199951171875, -7.512499809265137, -5.452000141143799, -6.024099826812744, -6.748700141906738, -6.754899978637695, -5.288400173187256, -4.381999969482422, -5.956500053405762, -6.677499771118164, -6.628699779510498, -4.986599922180176, -4.27839994430542, -4.779699802398682, -5.672800064086914, -6.352799892425537, -6.189199924468994, -6.353000164031982, -5.373499870300293, -5.598599910736084, -4.529900074005127, -5.700500011444092, -5.760000228881836, -5.053400039672852, -6.156300067901611, -5.227499961853027, -5.006999969482422, -5.319699764251709, -5.9618000984191895, -5.850800037384033, -5.931000232696533, -5.068299770355225, -4.751500129699707, -4.936299800872803, -4.813600063323975, -5.9644999504089355, -5.474899768829346, -5.048600196838379, -5.655799865722656, -5.5329999923706055, -5.538300037384033, -5.471799850463867, -4.817299842834473, -5.261499881744385, -5.256999969482422, -5.277900218963623, -5.493199825286865, -5.6153998374938965, -5.60699987411499, -5.60699987411499, -5.60129976272583, -6.004199981689453, -6.126200199127197, -6.1371002197265625, -6.228000164031982, -6.312399864196777, -6.533299922943115, -6.729700088500977, -6.736400127410889, -6.832300186157227, -6.882199764251709, -6.915599822998047, -7.033199787139893, -7.068299770355225, -7.10230016708374, -7.134300231933594, -7.200200080871582, -7.279099941253662, -7.293900012969971, -7.333600044250488, -7.38539981842041, -7.40310001373291, -7.45550012588501, -7.493199825286865, -6.4303998947143555, -7.517399787902832, -7.519800186157227, -7.531400203704834, -6.063600063323975, -7.577600002288818, -6.313199996948242, -6.390500068664551, -6.673500061035156, -6.466800212860107, -5.950699806213379, -7.093900203704834, -5.749000072479248, -6.846199989318848, -5.955599784851074, -6.13070011138916, -4.578400135040283, -6.408699989318848, -5.628699779510498, -6.4604997634887695, -5.619800090789795, -6.477399826049805, -4.992400169372559, -5.316800117492676, -6.125100135803223, -5.635900020599365, -6.283400058746338, -5.169099807739258, -5.547399997711182, -5.436100006103516, -6.154399871826172, -5.3094000816345215, -5.80679988861084, -5.423600196838379, -5.459499835968018, -5.387499809265137, -6.048399925231934, -5.507999897003174, -5.74970006942749, -5.950900077819824, -5.883800029754639, -5.654399871826172, -5.716599941253662, -5.8078999519348145, -5.85230016708374, -5.6828999519348145, -5.813799858093262, -5.836299896240234, -5.757999897003174, -5.771500110626221, -5.843100070953369, -5.909999847412109, -5.874899864196777, -4.368100166320801, -4.810400009155273, -4.905399799346924, -5.071400165557861, -5.144400119781494, -5.438199996948242, -5.474299907684326, -5.583399772644043, -5.616799831390381, -5.6605000495910645, -5.695000171661377, -5.724800109863281, -5.8317999839782715, -5.833000183105469, -5.928699970245361, -6.209099769592285, -6.228000164031982, -6.282800197601318, -6.306000232696533, -6.088600158691406, -6.366700172424316, -6.371699810028076, -6.394700050354004, -6.398600101470947, -6.386099815368652, -6.410299777984619, -6.443999767303467, -6.464799880981445, -6.57919979095459, -6.637700080871582, -6.257900238037109, -6.123899936676025, -4.851099967956543, -5.00439977645874, -5.8414998054504395, -5.36359977722168, -5.952400207519531, -5.975299835205078, -5.4644999504089355, -5.347499847412109, -5.0406999588012695, -5.679500102996826, -5.696700096130371, -5.414700031280518, -5.643599987030029, -5.559100151062012, -5.600200176239014, -5.585899829864502, -5.692299842834473, -5.82420015335083, -5.8059000968933105, -5.824999809265137, -4.856200218200684, -6.037300109863281, -6.17579984664917, -6.221499919891357, -6.269100189208984, -6.009099960327148, -6.408599853515625, -6.4721999168396, -6.616000175476074, -6.620699882507324, -7.013299942016602, -6.973100185394287, -7.0569000244140625, -7.08620023727417, -7.120500087738037, -7.184899806976318, -7.190899848937988, -7.232800006866455, -7.250400066375732, -7.280600070953369, -6.685400009155273, -7.279600143432617, -7.3069000244140625, -7.359799861907959, -7.3572001457214355, -7.375100135803223, -7.008600234985352, -7.405300140380859, -7.204400062561035, -7.440800189971924, -7.133299827575684, -6.2459001541137695, -6.82919979095459, -7.062099933624268, -5.360799789428711, -6.6666998863220215, -5.8765997886657715, -5.541500091552734, -6.508699893951416, -6.157400131225586, -6.119100093841553, -5.995800018310547, -5.110099792480469, -5.7444000244140625, -6.489500045776367, -5.871200084686279, -5.86329984664917, -6.453800201416016, -4.741000175476074, -6.47730016708374, -6.104899883270264, -5.309999942779541, -5.4054999351501465, -5.640900135040283, -5.940999984741211, -5.7104997634887695, -5.716000080108643, -5.759799957275391, -5.611700057983398, -5.494100093841553, -5.560999870300293, -5.539700031280518, -5.68310022354126, -5.5954999923706055, -5.765600204467773, -5.7403998374938965, -5.973599910736084, -5.8927001953125, -5.8394999504089355, -5.88070011138916, -5.812300205230713, -5.809199810028076, -5.878799915313721, -5.866600036621094, -5.037099838256836, -5.179500102996826, -5.665299892425537, -5.848700046539307, -6.330699920654297, -6.369100093841553, -6.415200233459473, -6.613999843597412, -6.627500057220459, -6.632299900054932, -6.667099952697754, -6.7382001876831055, -6.795000076293945, -6.899799823760986, -6.901700019836426, -6.941400051116943, -7.053899765014648, -7.059999942779541, -7.085700035095215, -7.120200157165527, -7.179699897766113, -7.220200061798096, -7.2220001220703125, -7.223999977111816, -7.225399971008301, -7.23390007019043, -7.268700122833252, -7.275100231170654, -7.27839994430542, -7.294899940490723, -5.441400051116943, -6.373000144958496, -5.53249979019165, -6.901899814605713, -5.8821001052856445, -6.767899990081787, -5.968900203704834, -6.01140022277832, -5.798699855804443, -5.940800189971924, -6.97730016708374, -6.481599807739258, -5.73360013961792, -5.791999816894531, -5.241600036621094, -4.936399936676025, -6.590799808502197, -6.421899795532227, -6.323800086975098, -4.930099964141846, -5.663000106811523, -5.662399768829346, -5.98859977722168, -5.502699851989746, -5.796000003814697, -5.51230001449585, -6.3242998123168945, -5.74399995803833, -5.968800067901611, -6.014900207519531, -5.60230016708374, -5.785099983215332, -5.3277997970581055, -5.709400177001953, -5.74970006942749, -5.637499809265137, -5.830900192260742, -5.876299858093262, -5.91510009765625, -5.959000110626221, -4.950500011444092, -5.353899955749512, -5.461400032043457, -5.575200080871582, -5.683499813079834, -5.77839994430542, -5.895299911499023, -5.913899898529053, -5.937699794769287, -5.980000019073486, -5.978400230407715, -6.000199794769287, -6.139900207519531, -6.516900062561035, -6.613399982452393, -6.622000217437744, -6.62529993057251, -6.676400184631348, -6.685699939727783, -6.712299823760986, -6.716300010681152, -6.793499946594238, -6.840400218963623, -6.833399772644043, -6.8678998947143555, -6.896200180053711, -6.902200222015381, -6.906400203704834, -6.939599990844727, -6.94290018081665, -5.740200042724609, -5.589700222015381, -4.685999870300293, -5.532899856567383, -6.754300117492676, -4.71019983291626, -5.401899814605713, -5.8024001121521, -6.112500190734863, -6.117300033569336, -6.1859002113342285, -5.280799865722656, -6.251800060272217, -5.162899971008301, -6.281899929046631, -5.551599979400635, -5.455399990081787, -4.288599967956543, -5.1132001876831055, -5.221199989318848, -5.535399913787842, -5.665900230407715, -4.668000221252441, -4.605599880218506, -4.978799819946289, -5.242400169372559, -5.676300048828125, -5.563700199127197, -5.1118998527526855, -5.510499954223633, -5.4847002029418945, -5.380499839782715, -5.536200046539307, -5.615900039672852], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.497, 2.4968, 2.4962, 2.4961, 2.4955, 2.4952, 2.4948, 2.4943, 2.4933, 2.4932, 2.4929, 2.4928, 2.4924, 2.4921, 2.4916, 2.4915, 2.4915, 2.4914, 2.491, 2.4909, 2.4907, 2.4906, 2.4902, 2.49, 2.4899, 2.4898, 2.4895, 2.4893, 2.4891, 2.4889, 2.4877, 2.4881, 2.4503, 2.4687, 2.4689, 2.3249, 2.3694, 2.2688, 2.4136, 2.4488, 2.4053, 2.4036, 2.3927, 2.2159, 2.063, 1.9625, 1.8853, 1.6765, 2.0791, 1.8174, 1.8117, 1.7143, 1.7543, 1.0065, 1.0814, 0.768, 0.8552, 1.7047, 0.7455, 0.678, 2.2445, 2.2429, 2.242, 2.2419, 2.2413, 2.2407, 2.2406, 2.2404, 2.24, 2.2398, 2.2393, 2.2392, 2.2388, 2.2385, 2.2385, 2.2382, 2.2377, 2.2373, 2.2368, 2.2367, 2.2364, 2.2358, 2.235, 2.2349, 2.2347, 2.2343, 2.2343, 2.2342, 2.234, 2.2338, 2.2305, 2.2131, 2.2052, 2.2058, 2.1968, 2.2025, 2.1989, 2.18, 2.2073, 2.1143, 2.1895, 2.0599, 2.0019, 2.0522, 1.9323, 1.89, 2.1594, 1.622, 1.5641, 1.3967, 1.4119, 1.5803, 1.3241, 1.5185, 1.31, 1.5608, 1.1218, 1.01, 1.12, 1.0216, 1.4031, 0.7843, 0.95, 0.7181, 2.2896, 2.2894, 2.2844, 2.2843, 2.2842, 2.2822, 2.2807, 2.2805, 2.2802, 2.2801, 2.2801, 2.2799, 2.2797, 2.2797, 2.2792, 2.2788, 2.2787, 2.2781, 2.2781, 2.278, 2.278, 2.278, 2.278, 2.2778, 2.2775, 2.2775, 2.2772, 2.2771, 2.2768, 2.2759, 2.2337, 2.2283, 2.2321, 2.2169, 2.1868, 2.1983, 2.1962, 2.23, 2.2152, 2.2246, 2.1496, 2.1447, 2.1932, 1.8966, 1.698, 2.0517, 1.6723, 2.024, 1.928, 1.9979, 1.5359, 1.7065, 1.7809, 1.9805, 1.3881, 1.749, 1.4442, 1.7179, 1.7273, 1.1582, 1.5663, 1.3392, 1.2393, 0.7473, 1.0583, 0.953, 1.1179, 1.3357, 1.3208, 0.7814, 0.6297, 0.8648, 0.6971, 0.6653, 0.9784, 0.9792, 0.5621, 1.1131, 2.7549, 2.7546, 2.7545, 2.7542, 2.7533, 2.7531, 2.7519, 2.7509, 2.7507, 2.7489, 2.7489, 2.7469, 2.7461, 2.7459, 2.745, 2.7448, 2.7445, 2.7437, 2.7426, 2.7419, 2.7416, 2.741, 2.7405, 2.7401, 2.74, 2.7396, 2.7395, 2.7392, 2.7387, 2.7383, 2.6873, 2.7113, 2.6564, 2.6165, 2.6635, 2.6014, 2.5735, 2.3978, 2.5387, 2.5615, 2.54, 2.5927, 2.5609, 2.2334, 2.5654, 2.2333, 2.2651, 2.1601, 2.0306, 1.7612, 2.1099, 1.6372, 1.2299, 1.3571, 0.9148, 1.0601, 1.204, 1.0679, 1.3916, 1.0184, 2.6022, 2.6005, 2.5991, 2.599, 2.598, 2.5979, 2.5975, 2.5969, 2.5963, 2.5957, 2.5956, 2.5953, 2.5951, 2.5943, 2.5938, 2.5921, 2.5917, 2.5916, 2.5913, 2.5908, 2.5907, 2.5906, 2.5902, 2.5898, 2.5895, 2.5891, 2.589, 2.5886, 2.5881, 2.5881, 2.499, 2.5054, 2.5351, 2.5067, 2.3095, 2.1545, 2.3826, 2.4836, 2.4705, 2.1923, 2.0303, 2.1068, 2.2673, 2.3941, 2.3501, 2.3845, 2.126, 2.1665, 1.8646, 2.1923, 2.2049, 1.9898, 2.3184, 1.9995, 1.9179, 2.0068, 2.2318, 2.1886, 2.1979, 1.8394, 1.6911, 1.7616, 1.5847, 2.1773, 1.9004, 1.5776, 1.9772, 1.8581, 1.836, 1.7316, 1.0319, 1.4025, 1.3841, 1.3311, 1.5542, 1.5506, 1.3972, 1.356, 2.0698, 2.0687, 2.0683, 2.0683, 2.068, 2.0676, 2.0666, 2.0654, 2.0654, 2.0647, 2.0644, 2.0641, 2.0629, 2.0629, 2.0626, 2.0623, 2.0616, 2.0608, 2.0606, 2.0602, 2.0595, 2.0593, 2.0587, 2.0581, 2.0579, 2.0578, 2.0578, 2.0576, 2.057, 2.057, 2.0304, 2.0245, 2.029, 2.0154, 1.9811, 2.0398, 1.9497, 2.0203, 1.9187, 1.9336, 1.7486, 1.8913, 1.7105, 1.891, 1.6065, 1.8754, 1.3234, 1.4159, 1.7081, 1.438, 1.7691, 1.1392, 1.3504, 1.2208, 1.6867, 1.0983, 1.4417, 1.1222, 1.1341, 0.9615, 1.5944, 1.0127, 1.244, 1.4844, 1.3816, 1.0558, 1.117, 1.2437, 1.2952, 0.8448, 1.1359, 1.0907, 0.7446, 0.6269, 0.8209, 1.276, 0.5992, 2.443, 2.4425, 2.4424, 2.4421, 2.442, 2.4413, 2.4412, 2.4409, 2.4408, 2.4407, 2.4406, 2.4405, 2.4401, 2.4401, 2.4397, 2.4384, 2.4383, 2.438, 2.4378, 2.4375, 2.4375, 2.4374, 2.4373, 2.4373, 2.4372, 2.4372, 2.4369, 2.4368, 2.4359, 2.4355, 2.4303, 2.4206, 2.2354, 2.2429, 2.3105, 2.1652, 2.2972, 2.2431, 1.9765, 1.877, 1.6695, 2.0537, 1.9454, 1.2079, 1.3502, 0.9987, 1.0662, 0.7225, 0.6235, 1.2527, 0.5832, 1.0954, 2.3808, 2.3778, 2.3771, 2.3769, 2.3766, 2.3763, 2.3758, 2.3744, 2.3744, 2.3743, 2.3706, 2.3704, 2.3701, 2.3697, 2.3693, 2.3684, 2.3683, 2.3678, 2.3675, 2.3671, 2.367, 2.367, 2.3667, 2.3658, 2.3656, 2.3656, 2.3654, 2.3651, 2.3649, 2.3645, 2.3644, 2.3458, 2.3528, 2.3575, 2.2917, 2.3411, 2.2859, 2.225, 2.3079, 2.2773, 2.2139, 2.1899, 2.0563, 2.1467, 2.2468, 2.103, 2.0354, 2.1942, 1.5802, 2.1692, 1.9866, 1.5777, 1.4947, 1.4727, 1.7102, 1.4268, 1.4309, 1.4738, 1.2617, 1.0712, 1.027, 0.9872, 1.1866, 0.9791, 1.1485, 1.0558, 1.5901, 1.2818, 1.0513, 1.1412, 0.7155, 0.6309, 0.893, 0.1147, 2.2471, 2.2462, 2.2459, 2.2454, 2.2433, 2.2432, 2.2429, 2.2417, 2.2416, 2.2416, 2.2414, 2.2408, 2.2404, 2.2395, 2.2395, 2.2391, 2.238, 2.2379, 2.2376, 2.2373, 2.2366, 2.2361, 2.2361, 2.236, 2.236, 2.2359, 2.2355, 2.2354, 2.2354, 2.2351, 2.2283, 2.2271, 2.2177, 2.2302, 2.1999, 2.2252, 2.2, 2.2009, 2.1919, 2.1913, 2.2282, 2.1909, 2.1311, 2.1051, 2.0044, 1.902, 2.1749, 2.1254, 2.0515, 1.5574, 1.7487, 1.7225, 1.854, 1.5492, 1.6846, 1.4929, 2.0269, 1.548, 1.7125, 1.7452, 1.2902, 1.4319, 0.7758, 1.2212, 1.1707, 0.7746, 1.06, 0.8926, 0.5073, 1.2444, 1.8103, 1.8099, 1.8096, 1.8096, 1.8094, 1.8092, 1.809, 1.809, 1.8089, 1.8088, 1.8088, 1.8088, 1.8084, 1.8072, 1.8068, 1.8067, 1.8067, 1.8065, 1.8064, 1.8063, 1.8063, 1.8059, 1.8057, 1.8056, 1.8055, 1.8053, 1.8053, 1.8053, 1.8051, 1.8051, 1.802, 1.7987, 1.7743, 1.7911, 1.8036, 1.7483, 1.7636, 1.7752, 1.7838, 1.7834, 1.7845, 1.7389, 1.7858, 1.7243, 1.7855, 1.7129, 1.7019, 1.5605, 1.6496, 1.6134, 1.6579, 1.6829, 1.4356, 1.3757, 1.4477, 1.4877, 1.6559, 1.5836, 1.2801, 1.5088, 1.4201, 1.0418, 0.9064, 1.0069]}, \"token.table\": {\"Topic\": [8, 9, 3, 8, 6, 10, 3, 5, 9, 9, 4, 1, 3, 8, 3, 10, 1, 4, 5, 6, 7, 8, 9, 10, 7, 7, 7, 7, 7, 1, 2, 3, 5, 6, 7, 8, 9, 10, 6, 7, 6, 8, 1, 2, 4, 2, 3, 6, 3, 5, 2, 6, 5, 9, 10, 5, 3, 7, 1, 2, 3, 6, 7, 8, 1, 2, 8, 8, 1, 2, 4, 1, 3, 5, 7, 8, 9, 10, 8, 1, 2, 3, 5, 6, 7, 8, 9, 10, 1, 2, 3, 6, 8, 9, 10, 4, 5, 2, 6, 2, 4, 6, 7, 2, 6, 2, 6, 7, 2, 6, 1, 6, 9, 5, 3, 5, 6, 9, 4, 5, 3, 10, 3, 5, 8, 9, 10, 5, 3, 6, 9, 6, 1, 1, 8, 4, 1, 10, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 6, 4, 1, 3, 5, 1, 10, 1, 3, 4, 5, 6, 8, 9, 10, 1, 4, 9, 5, 10, 3, 7, 9, 10, 2, 4, 5, 10, 4, 5, 6, 5, 10, 3, 6, 7, 2, 6, 2, 10, 7, 9, 8, 5, 3, 4, 1, 9, 3, 1, 2, 8, 10, 10, 2, 4, 5, 8, 9, 10, 3, 3, 6, 7, 8, 7, 7, 10, 9, 2, 4, 9, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 8, 4, 8, 3, 1, 4, 5, 5, 2, 6, 9, 1, 7, 6, 6, 2, 7, 10, 9, 2, 9, 5, 1, 8, 1, 9, 10, 6, 2, 8, 3, 9, 10, 3, 10, 3, 1, 8, 4, 4, 1, 2, 3, 4, 5, 7, 8, 9, 10, 7, 1, 2, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 7, 8, 9, 10, 3, 8, 5, 9, 8, 2, 3, 10, 5, 3, 4, 7, 8, 4, 5, 2, 7, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 8, 9, 1, 3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 6, 7, 9, 9, 8, 3, 5, 9, 10, 1, 10, 5, 1, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 6, 5, 6, 1, 4, 6, 8, 10, 3, 2, 6, 8, 1, 2, 4, 5, 8, 9, 10, 6, 2, 6, 10, 3, 5, 7, 9, 9, 7, 9, 5, 2, 2, 1, 9, 2, 5, 1, 3, 4, 5, 6, 7, 8, 9, 10, 5, 6, 7, 9, 4, 1, 6, 3, 2, 1, 2, 3, 4, 6, 8, 9, 10, 4, 1, 5, 8, 9, 8, 7, 7, 5, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 1, 1, 9, 9, 5, 5, 6, 2, 8, 10, 1, 10, 9, 6, 2, 3, 5, 6, 9, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 5, 9, 10, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 5, 6, 7, 9, 10, 1, 2, 3, 5, 6, 7, 9, 10, 3, 4, 5, 6, 7, 9, 3, 6, 7, 8, 9, 4, 5, 10, 5, 3, 3, 8, 5, 9, 10, 10, 2, 4, 5, 9, 10, 7, 4, 5, 7, 10, 1, 2, 4, 6, 9, 10, 7, 4, 6, 2, 6, 9, 4, 2, 3, 4, 6, 7, 8, 9, 5, 3, 8, 9, 10, 3, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 8, 2, 4, 6, 2, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 8, 1, 5, 8, 9, 4, 6, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 10, 4, 2, 3, 4, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 9, 10, 3, 8, 2, 3, 5, 8, 9, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 8, 3, 8, 1, 3, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 3, 4, 8, 9, 10, 2, 6, 7, 9, 10, 3, 4, 8, 10, 2, 6, 7, 2, 6, 8, 4, 3, 4, 5, 10, 3, 7, 9, 1, 2, 3, 4, 5, 6, 7, 9, 10, 5, 10, 1, 4, 1, 3, 4, 5, 6, 10, 1, 2, 6, 7, 8, 10, 4, 3, 4, 5, 6, 8, 9, 10, 3, 4, 5, 10, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 3, 2, 3, 7, 8, 9, 10, 3, 6, 3, 2, 3, 4, 5, 7, 10, 1, 3, 4, 5, 6, 8, 9, 10, 5, 3, 4, 5, 6, 7, 8, 9, 3, 4, 5, 6, 10, 3, 5, 6, 7, 9, 4, 4, 5, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 5, 6, 9, 10, 2, 3, 6, 7, 9, 10, 4, 3, 2, 3, 6, 7, 8, 9, 2, 9, 3, 4, 10, 1, 2, 3, 6, 7, 9, 10, 2, 2, 3, 7, 8, 8, 1, 3, 4, 6, 7, 8, 10, 3, 8, 9, 10, 2, 4, 5, 6, 7, 9, 3, 4, 5, 8, 10, 2, 5, 7, 8, 10, 4, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 5, 6, 9, 3, 4, 8, 9, 1, 9, 10, 4, 4, 2, 2, 4, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 6, 1, 6, 8, 4, 5, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 7, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 6, 9, 4, 7, 9, 4, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 2, 7, 8, 9, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 4, 10, 8, 5, 7, 9, 10, 5, 3, 5, 6, 7, 5, 9, 9, 3, 1, 10, 6, 7, 1, 4, 6, 7, 9, 10, 2, 6, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 7, 3, 4, 6, 7, 8, 9, 2, 4, 5, 6, 7, 9, 10, 6, 7, 3, 6, 7, 9, 1, 2, 3, 4, 6, 7, 8, 9, 10, 2, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 6, 7, 8, 9, 10, 1, 1, 4, 9, 6, 6, 2, 4, 6, 7, 9, 10, 2, 4, 5, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 5, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 4, 3, 8, 9, 2, 10, 1, 3, 5, 8, 10, 5, 9, 6, 7, 7, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 7, 1, 2, 3, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 10, 4, 10, 6, 6, 4, 5, 3, 10, 1, 2, 3, 6, 7, 9, 10, 3, 6, 7, 9, 9, 7, 9, 9, 2, 3, 4, 5, 6, 7, 9, 1, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 5, 6, 3, 5, 6, 9, 2, 3, 4, 6, 7, 8, 9, 2, 3, 4, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 2, 3, 6, 7, 8, 9, 10, 9, 1, 3, 4, 5, 6, 7, 8, 10, 1, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 7, 8, 9, 10, 6, 7, 7, 10, 1, 2, 3, 6, 7, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 3, 7, 8, 9, 3, 2, 9, 3, 4, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 9, 10, 2, 4, 6, 9, 6, 6, 10, 8, 6, 10, 7, 8, 1, 4, 5, 7, 9, 10, 2, 3, 4, 5, 6, 10, 5, 4, 6, 9, 3, 7, 5, 2, 3, 5, 6, 7, 8, 9, 10, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 7, 8, 9, 10, 9, 9, 3, 4, 9, 7, 1, 3, 5, 6, 7, 8, 9, 10, 9, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 5, 8, 10, 4, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 5, 8, 1, 10, 4, 1, 2, 4, 5, 6, 7, 8, 1, 1, 3, 5, 6, 7, 9, 4, 7, 10, 1, 2, 3, 4, 6, 7, 8, 9, 10, 2, 6, 2, 3, 5, 6, 7, 8, 9, 10, 10, 4, 5, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 4, 5, 9, 10, 1, 3, 4, 5, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 9, 10, 3, 4, 5, 6, 7, 9, 10, 1, 3, 9, 3, 10, 3, 4, 6, 10, 1, 3, 4, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 9, 5, 5, 2, 6, 7, 2, 6, 7, 1, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 5, 6, 7, 8, 10, 2, 2, 1, 3, 4, 5, 7, 9, 10, 3, 2, 3, 8, 8, 1, 3, 7, 9, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 8, 9, 10, 2, 9, 3, 4, 9, 10, 4, 9, 1, 7, 1, 2, 10, 1, 3, 4, 6, 7, 8, 10, 2, 1, 6, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 4, 5, 6, 7, 4, 5, 7, 3, 4, 5, 7, 1, 2, 3, 5, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 10, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 6, 7, 2, 1, 3, 6, 7, 8, 9, 9, 1, 2, 6, 5, 7, 8, 9, 10, 4, 6, 7, 9, 3, 4, 5, 9, 10, 4, 9, 7, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 7, 8, 9, 10, 9, 1, 3, 4, 8, 9, 10, 1, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 8, 10, 5, 3, 4, 3, 6, 8, 9, 1, 9, 5, 3, 8, 7, 10, 2, 4, 5, 6, 7, 8, 3, 8, 8, 1, 2, 3, 4, 6, 7, 8, 9, 10, 2, 3, 4, 6, 7, 7, 1, 2, 3, 4, 6, 7, 8, 9, 10, 3, 4, 7, 8, 10, 3, 10, 1, 3, 5, 6, 8, 9, 10, 3, 4, 5, 10, 1, 2, 3, 4, 6, 8, 9, 10, 8, 2, 3, 5, 7, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 3, 5, 6, 7, 10, 7, 3, 3, 10, 3, 3, 6, 7, 9, 2, 3, 6, 7, 8, 9, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 10, 3, 8, 10, 1, 6, 9, 10, 3, 7, 8, 10, 3, 4, 7, 10, 4, 3, 4, 2, 3, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 2, 6, 1, 2, 3, 4, 6, 7, 8, 9, 10, 10, 8], \"Freq\": [0.9848336130542662, 0.994615350388938, 0.01306702040248494, 0.9800265301863705, 0.9937398505717503, 0.9953669117061945, 0.03334442378395565, 0.8069350555717266, 0.15338434940619597, 0.9873954302720974, 0.9799402531085876, 0.9918760933391393, 0.98840033270471, 0.9878504140450912, 0.007996088945070888, 0.9915150291887901, 0.19350226056443728, 0.021660700809451934, 0.1400725319011225, 0.06498210242835581, 0.0693142425902462, 0.0548737753839449, 0.4418782965128195, 0.012996420485671161, 0.996174030967356, 0.9952264017578559, 0.9974893042589312, 0.9912214514209011, 0.998451548886948, 0.13148092381190224, 0.004152029173007439, 0.16608116692029756, 0.04982435007608926, 0.02906420421105207, 0.005536038897343252, 0.3321623338405951, 0.09272865153049946, 0.18684131278533475, 0.989378033089922, 0.9947223517858205, 0.9980337317368995, 0.9953255727078905, 0.989341302217283, 0.9940751132658958, 0.9921213375532678, 0.9976651838566467, 0.9791881594931158, 0.9917022407843171, 0.9889487089875214, 0.9667565083755782, 0.9979656792895516, 0.0014359218407043908, 0.8725710777526922, 0.009484468236442306, 0.11381361883730767, 0.9904049825555841, 0.9780629013985053, 0.9933280008714385, 0.753399576356834, 0.014377854510626602, 0.08914269796588493, 0.07764041435738366, 0.037382421727629164, 0.028755709021253205, 0.9945458449357718, 0.03462369244000889, 0.9608074652102466, 0.9759429987797845, 0.9930638549418336, 0.9907040875031962, 0.9761345160971701, 0.22611416161848033, 0.020555832874407303, 0.18793904342315249, 0.010277916437203652, 0.4037752886044292, 0.1248032710231872, 0.026428927981380818, 0.991663443576918, 0.016101276316304827, 0.0010734184210869887, 0.050450665791088464, 0.15349883421543936, 0.0021468368421739773, 0.2597672579030512, 0.0848000552658721, 0.3402736394845754, 0.093387402634568, 0.5070779323672415, 0.012418235078381426, 0.1490188209405771, 0.06002146954551023, 0.16971587940454616, 0.05795176369911332, 0.04346382277433499, 0.9548562481335252, 0.04254310016436499, 0.9844887639683904, 0.013890494024245368, 0.9607114582478321, 0.0025895187553849923, 0.02589518755384992, 0.007768556266154976, 0.9560392472994005, 0.043315694052400024, 0.968526904955454, 0.008788810389795409, 0.02109314493550898, 0.9373723005609235, 0.05990725229148759, 0.025516419174646206, 0.9568657190492327, 0.012758209587323103, 0.9850034693452964, 0.09298830441502416, 0.05789837822067542, 0.2421204907410063, 0.6070557231622332, 0.9947853326103686, 0.002426305689293582, 0.9082594876099083, 0.09174338258685942, 0.6949928252823772, 0.09109129263409797, 0.07084878315985398, 0.030363764211365992, 0.11470755368738263, 0.9856251429342174, 0.015352403970868239, 0.9467315782035415, 0.035822275932025895, 0.9931094941990144, 0.9888314679047846, 0.970818084323756, 0.024765767457238675, 0.9960879650491821, 0.9887104462697586, 0.9981559710043788, 0.9952745423627746, 0.9865172661728929, 0.16197451020962983, 0.1578565141873511, 0.10226356788658833, 0.0713785977194979, 0.06657426902683938, 0.05833827698228193, 0.06863326703797874, 0.06726060169721916, 0.12491254600912131, 0.12148088265722237, 0.9940507369966194, 0.9819685593015325, 0.9905098469359118, 0.18793143610325333, 0.0660299640362782, 0.7466465164102227, 0.9958668515122548, 0.9946135357481866, 0.05795772025118398, 0.10922801124261597, 0.013374858519503995, 0.08247829420360797, 0.06687429259751998, 0.5104737668277358, 0.03343714629875999, 0.12706115593528797, 0.9960400946776662, 0.05321402020530665, 0.9453314177648592, 0.9239195500519813, 0.06843848518903566, 0.9365972661348595, 0.016724951180979632, 0.008362475590489816, 0.04181237795244908, 0.05035004640098703, 0.18826539089064714, 0.5297700534364722, 0.22985890748276688, 0.09583809013032865, 0.01636260075395855, 0.8859179551071843, 0.6613375803881306, 0.33785724215480584, 0.986096696368686, 0.983824907104271, 0.9963609781737004, 0.99548897425104, 0.00452020840561073, 0.9593126974755096, 0.04069811443835495, 0.9956123163204605, 0.9929217254860488, 0.9907441962619915, 0.9884118476786702, 0.9768745057323183, 0.9746842939576925, 0.017274316137132508, 0.9788779144375088, 0.9928987308772749, 0.9945961958916937, 0.9974672784183194, 0.9969201403931025, 0.9968019995821316, 0.9977806532507804, 0.031047976022037852, 0.004435425146005407, 0.793941101134968, 0.008870850292010814, 0.03548340116804326, 0.12419190408815141, 0.9774592583289352, 0.9872102460085052, 0.9837776500399005, 0.010693235326520657, 0.9913998444668993, 0.9988774970154976, 0.9935340886932053, 0.9955596816776902, 0.9891076574338132, 0.9990065584323029, 0.009802724074621915, 0.9802724074621916, 0.14701961861689, 0.04055713617017655, 0.812410133908849, 0.1595288675467272, 0.27347805865153235, 0.15117259353237483, 0.034184757331441544, 0.0531762891822424, 0.014433564206608651, 0.0015193225480640686, 0.24613025278637912, 0.014433564206608651, 0.05165696663417833, 0.912176840850642, 0.005212439090575097, 0.07818658635862646, 0.993679116426296, 0.9799740158068274, 0.9821807557529967, 0.050952146804635334, 0.8225132269891133, 0.11646204983916648, 0.9716061986584993, 0.12804002642967394, 0.8693243899698914, 0.9932125070427914, 0.9928807417236666, 0.9939839790779267, 0.9931567219059605, 0.9923636377487884, 0.9971547655549573, 0.9952961657099009, 0.9983453906808218, 0.9946594171026756, 0.0679441790217173, 0.930835252597527, 0.9895378762340569, 0.9108239442195724, 0.08572460651478328, 0.9937724636579413, 0.9946856298011713, 0.9961663975576943, 0.9906321956302899, 0.06434701891182007, 0.929456939837401, 0.9819853260237572, 0.9980936580766607, 0.001779133080350554, 0.7309891636891785, 0.2670921944248922, 0.9838388148866594, 0.9970855946371308, 0.00225075754997095, 0.988642968638924, 0.9964638879572827, 0.04558580734756929, 0.03276479903106543, 0.011396451836892323, 0.0014245564796115404, 0.41454593556695823, 0.03703846846990005, 0.0056982259184461615, 0.3661110152601659, 0.08404883229708088, 0.9954243456661951, 0.19323664740528315, 0.11317046680707818, 0.008468538332502449, 0.04927149575274152, 0.09931285862661964, 0.06235923681206349, 0.25790548558075643, 0.1570528927118636, 0.06004963544865373, 0.10266987082176487, 0.09866974598455325, 0.03600112353490457, 0.0040001248372116185, 0.1080033706047137, 0.029334248806218533, 0.3840119843723154, 0.001333374945737206, 0.23600736539548547, 0.992561556850607, 0.983464264494764, 0.9860934204628892, 0.9922637839058925, 0.9858241961158597, 0.018313153079820864, 0.8607181947515805, 0.1190354950188356, 0.979870336368797, 0.992159719185815, 0.011419301152203134, 0.0171289517283047, 0.9649309473611648, 0.8048422603808782, 0.19198072265965901, 0.9900013988009152, 0.9956439042583086, 0.9888176708763585, 0.09811038978074435, 0.5047708459733948, 0.04834425003688852, 0.012797007362705785, 0.005687558827869237, 0.0625631471065616, 0.009953227948771166, 0.08531338241803856, 0.10237605890164628, 0.06825070593443085, 0.9927147684283937, 0.5034074816152898, 0.2785246312215743, 0.1856830874810495, 0.030947181246841586, 0.053256057666040725, 0.09012563605022277, 0.024579718922788027, 0.013314014416510181, 0.15259908831230898, 0.021507254057439522, 0.32568127572694133, 0.08910148109510659, 0.2283865549909054, 0.022298530650349663, 0.07878814163123547, 0.043110492590676015, 0.07135529808111893, 0.7834217101822848, 0.9872703053751241, 0.9891609640874099, 0.14338223590311414, 0.6650495197208273, 0.1006726337192078, 0.08846989023809171, 0.9872275930633384, 0.9937717273960901, 0.9928578655690298, 0.9502632756309923, 0.04291511567365772, 0.06636344134714701, 0.08342832626498482, 0.12324639107327304, 0.03792196648408401, 0.09196076872390373, 0.03792196648408401, 0.036025868159879806, 0.26545376538858806, 0.0056882949726126016, 0.2531291262812608, 0.04310276599491403, 0.7614821992434812, 0.19156784886628456, 0.9916776174971282, 0.9910451785677536, 0.9906546375272353, 0.007649842760828071, 0.9932053108318856, 0.9946414153246113, 0.9990312023878137, 0.9852642167122746, 0.9925137995633675, 0.9890735353799193, 0.9929799242274092, 0.456900973256275, 0.031574457501449896, 0.013001247206479369, 0.05757695191440863, 0.16715889265473474, 0.2043053132446758, 0.06872087809139095, 0.9932109309462452, 0.9949681425003861, 0.9719794081456717, 0.0196359476393065, 0.039638101313970615, 0.7993683764984073, 0.15855240525588246, 0.9918356980043351, 0.981023442939718, 0.9964130157605435, 0.9953831020695542, 0.9887093888705766, 0.9927549722343725, 0.9936489070518925, 0.9872983285078955, 0.9993110058199768, 0.9915985944111417, 0.9685624810450068, 0.1077344497288355, 0.1386681036113724, 0.006400066320524881, 0.059733952324898885, 0.1386681036113724, 0.0650673409253363, 0.29120301758388206, 0.08746757304717337, 0.10560109428866053, 0.04319493586885542, 0.12148575713115588, 0.15928132601640438, 0.674920872950866, 0.991548765726259, 0.9884934083855493, 0.988239226843625, 0.9826510844702491, 0.9929244926668417, 0.06770048125460734, 0.0022566827084869114, 0.561913994413241, 0.0067700481254607345, 0.11509081813283248, 0.02933687521032985, 0.06770048125460734, 0.14894105876013616, 0.9865418939208205, 0.647237883344025, 0.018851588835262865, 0.12358263792005655, 0.20946209816958739, 0.9834231497606406, 0.9971890076909802, 0.9959748404520471, 0.9769144039340127, 0.9839665646137871, 0.08189599551346276, 0.0010236999439182846, 0.4279065765578429, 0.004094799775673138, 0.13512839259721357, 0.06551679641077021, 0.03480579809322167, 0.09418039484048218, 0.06449309646685193, 0.09008559506480904, 0.08948931165994778, 0.10191838272382941, 0.1839502517454482, 0.022372327914986945, 0.6040528537046475, 0.9940277253446883, 0.9949712412398556, 0.9889784057625747, 0.9897834283009597, 0.9868256201890647, 0.9832286302748781, 0.9958574571309542, 0.9934966736017534, 0.9769380712582755, 0.9992651884111379, 0.9911829043884637, 0.9913314880062661, 0.9949696564421221, 0.9925780597120024, 0.013470979112750109, 0.053883916451000435, 0.08980652741833406, 0.8352007049905067, 0.004490326370916703, 0.4308107534991033, 0.005144008997004219, 0.03343605848052742, 0.03086405398202531, 0.25077043860395565, 0.09130615969682489, 0.03343605848052742, 0.021862038237267928, 0.10288017994008437, 0.04375960661595518, 0.0802259454625845, 0.5426191220378442, 0.020421149754112418, 0.31361051408101215, 0.16707514340882623, 0.041319659122612935, 0.003593013836748951, 0.06467424906148111, 0.5551206377777129, 0.12755199120458777, 0.03952315220423846, 0.01311862279634903, 0.0757964872677944, 0.017491497061798707, 0.001457624755149892, 0.6282362694696035, 0.12535572894289074, 0.05101686643024623, 0.08599986055384364, 0.00518844535550221, 0.07782668033253315, 0.002075378142200884, 0.6039350393804573, 0.028017604919711937, 0.028017604919711937, 0.03113067213301326, 0.22206546121549461, 0.02121601582393417, 0.5224443896643789, 0.17238012856946514, 0.07690805736176136, 0.007956005933975314, 0.19890014834938283, 0.08309868691160158, 0.006924890575966798, 0.14196025680731936, 0.6717143858687794, 0.09348602277555178, 0.8555687054936423, 0.05923167961109831, 0.08555687054936423, 0.9893176299032557, 0.9846805662348657, 0.9260764643014061, 0.06809385766922103, 0.8935690880384111, 0.006017300256150916, 0.09928545422649011, 0.9934861328337291, 0.0047402565138653, 0.029626603211658126, 0.1516882084436896, 0.07465904009337848, 0.7394800161629869, 0.9964483632497603, 0.0714248709948983, 0.7082966373660748, 0.011904145165816385, 0.20832254040178672, 0.02252591006936217, 0.3529059244200073, 0.04004606234553274, 0.5306103260783088, 0.005005757793191593, 0.04880613848361803, 0.9986772536492954, 0.16207681173381822, 0.8359751342060098, 0.7309824274848689, 0.26581179181267955, 0.9894848502094119, 0.9902410292960065, 0.03491829745090382, 0.023278864967269212, 0.19350556504042535, 0.12221404107816337, 0.5674223335771871, 0.023278864967269212, 0.03491829745090382, 0.9723899920503931, 0.9055833609777842, 0.05255617719960355, 0.004042782861507966, 0.032342262892063725, 0.7845476912127979, 0.06455139231497704, 0.06455139231497704, 0.004965491716536696, 0.029792950299220175, 0.049654917165366956, 0.0026628181717820174, 0.01397979540185559, 0.01797402265952862, 0.05591918160742236, 0.39809131668141157, 0.0033285227147275215, 0.03927656803378476, 0.06324193157982291, 0.4047483621108666, 0.177245754676886, 0.08406140571072902, 0.18962689195210966, 0.05604093714048602, 0.0032581940197956988, 0.20722113965900643, 0.08731959973052472, 0.11534006830076773, 0.001954916411877419, 0.07819665647509677, 0.9977622778085646, 0.867632742920107, 0.13275255082930598, 0.8308424665851578, 0.025382152747000748, 0.1438321988996709, 0.9949042356472214, 0.9438884447590524, 0.050565452397806375, 0.1933615093994712, 0.04810908367833733, 0.20538878031905553, 0.05458530648119043, 0.004625873430609359, 0.05458530648119043, 0.05366013179506856, 0.2257426234137367, 0.09344264329830905, 0.0656874027146529, 0.9988747529516029, 0.9889712066488542, 0.017955061195163016, 0.1167078977685596, 0.0583539488842798, 0.7990002231847542, 0.02734748013250028, 0.015627131504285876, 0.9532550217614383, 0.9941543648337704, 0.03671470836937098, 0.059661401100227836, 0.14532905396209345, 0.24629450197786362, 0.059661401100227836, 0.006884007819257058, 0.054307172796361235, 0.024476472246247317, 0.3656173041783193, 0.9890304981038115, 0.012892932700076859, 0.22949420206136809, 0.5492389330232742, 0.020628692320122974, 0.023207278860138344, 0.007735759620046115, 0.08767194236052264, 0.06704325004039967, 0.0008119243625865263, 0.4343795339837916, 0.008119243625865264, 0.03816044504156674, 0.29310469489373603, 0.025981579602768843, 0.07307319263278737, 0.06333010028174905, 0.004059621812932632, 0.0584585541062299, 0.8176341004488509, 0.05503306445328804, 0.12185892843228066, 0.16913981871049977, 0.827576970119231, 0.0007526091781101195, 0.5373629531706254, 0.012041746849761913, 0.2694340857634228, 0.0022578275343303586, 0.17836837521209833, 0.9975833551483578, 0.04164748159099249, 0.1678519712606667, 0.06184019993814036, 0.07509167135345615, 0.0807708733885915, 0.04858872852282457, 0.15586254474204767, 0.08013985094024313, 0.0719365591117143, 0.21644069978349129, 0.009050746522941076, 0.9865313710005774, 0.5512904674098497, 0.44869737507903273, 0.008808484041077768, 0.004743029868272644, 0.02235999795042818, 0.9641902146502819, 0.06921833483922434, 0.02630296723890525, 0.38346957500930284, 0.011074933574275895, 0.0622965013553019, 0.10798060234918996, 0.14258976976880214, 0.02630296723890525, 0.17027710370449187, 0.9937938986032293, 0.9680649928354452, 0.01992164751961929, 0.10890500644058544, 0.043827624543162434, 0.06773360156670558, 0.023905977023543145, 0.11554555561379187, 0.034530855700673435, 0.1733183334206878, 0.09828012776345516, 0.31343392097534345, 0.9894523364780337, 0.015047211058824313, 0.48339165526473105, 0.09968777326471108, 0.14106760367647794, 0.14482940644118403, 0.11473498432353539, 0.14679936141107727, 0.5186910769858064, 0.20373971977658603, 0.11921887532778397, 0.010676317193532892, 0.029674307712732616, 0.6981705175745702, 0.0016485726507073674, 0.2703659147160083, 0.7842638813973696, 0.19419867539363436, 0.02054024451278825, 0.9517790925244364, 0.0358316834832729, 0.008957920870818224, 0.9917385882588274, 0.8993323089426452, 0.02013430542408907, 0.06711435141363023, 0.013422870282726047, 0.016221495346683282, 0.8637946272108846, 0.11760584126345378, 0.02632220121917967, 0.32438242090694946, 0.04412839616156592, 0.06038622632635336, 0.0023225471663982063, 0.3917362887324975, 0.1091597168207157, 0.0038709119439970107, 0.0379349370511707, 0.025749083021446646, 0.9727431363657623, 0.015576993729960194, 0.9813506049874922, 0.99228099886282, 0.010807299874774875, 0.3263804562182012, 0.052955769386396886, 0.05403649937387438, 0.5565759435509061, 0.008298305537463106, 0.008298305537463106, 0.02726586105166449, 0.011854722196375865, 0.015411138855288626, 0.9305956924155054, 0.9910553371861582, 0.37736688326585305, 0.05900645811066065, 0.34580528939270894, 0.045284025991902364, 0.08096234950067392, 0.0658676741700398, 0.024700377813764926, 0.12881658418430508, 0.09185182524446102, 0.2845166294157695, 0.4928634525312543, 0.07148458504463066, 0.16135092052930922, 0.018381750440047886, 0.012254500293365257, 0.13888433665813957, 0.07761183519131329, 0.4534165108545145, 0.038805917595656644, 0.028593834017852267, 0.053262330251507305, 0.09356895854994526, 0.14323248270337777, 0.0316694936630584, 0.06693779342419162, 0.34692490785441243, 0.044625195616127745, 0.07485516683995622, 0.10076657074609491, 0.04390543439651278, 0.1048394410199052, 0.0034373587219641046, 0.47091814490908235, 0.017186793609820523, 0.0017186793609820523, 0.24233378989846938, 0.05671641891240773, 0.10312076165892314, 0.0009224959569766666, 0.008302463612789999, 0.30811364963020665, 0.04889228571976333, 0.04612479784883333, 0.10147455526743333, 0.07472217251511, 0.02490739083837, 0.25737637199649, 0.12914943397673334, 0.9978699454902089, 0.985439745421228, 0.022040196809297863, 0.08375274787533188, 0.008816078723719145, 0.8463435574770379, 0.03526431489487658, 0.004408039361859573, 0.9091767422954056, 0.08758124581744732, 0.9752883836005644, 0.05098004252665793, 0.06675957949919491, 0.04126955823586594, 0.5365042570662573, 0.0012138105363489983, 0.3010250130145516, 0.0031317029292542414, 0.22652651188272346, 0.005219504882090402, 0.026097524410452013, 0.03549263319821474, 0.19520948259018106, 0.38311165834543554, 0.12526811717016967, 0.9862085290292367, 0.06353334407449958, 0.0034654551313363403, 0.02194788249846349, 0.4366473465483789, 0.33499399602917956, 0.002310303420890894, 0.13630790183256272, 0.05121424710689508, 0.21563893518692667, 0.0485187604170585, 0.679262645838819, 0.9963929135120944, 0.006527104779337296, 0.01958131433801189, 0.6967684351942564, 0.06527104779337296, 0.21213090532846213, 0.9934426616981706, 0.8231796192590889, 0.1754317221371829, 0.9838693052588655, 0.9932397860397184, 0.04016893795358568, 0.05234134339406619, 0.3067446171001088, 0.06573098937859474, 0.08398959753931551, 0.05112410285001814, 0.03164825414524932, 0.010955164896432458, 0.08398959753931551, 0.2726618818667634, 0.006696008469170236, 0.2114025530980889, 0.12244129772197003, 0.017218307492152037, 0.16453049381389723, 0.47732974658799254, 0.23696478965422646, 0.014903445890202921, 0.5320530182802443, 0.16095721561419155, 0.03278758095844643, 0.02086482424628409, 0.9867872291416828, 0.9956021290409155, 0.4835180103131353, 0.06464144522902877, 0.23658768953824533, 0.18099604664128058, 0.019392433568708633, 0.015513946854966907, 0.8253246053953296, 0.17281165022718092, 0.005191984439645342, 0.07787976659468014, 0.9169044520413675, 0.016324870590957007, 0.017685276473536758, 0.008162435295478504, 0.01904568235611651, 0.006802029412898754, 0.035370552947073516, 0.8965074766200557, 0.9965789401859702, 0.011413250209078381, 0.11793691882714327, 0.04184858409995407, 0.825558431790003, 0.9872507957845235, 0.002518141365244142, 0.21278294536313, 0.003357521820325523, 0.014689157963924162, 0.015528538419005542, 0.10366348620255052, 0.6471623308677446, 0.23960602703015016, 0.032834900000427984, 0.0035497189189651877, 0.7232552297391569, 0.08199014318813767, 0.07003324730653426, 0.029038175712465426, 0.19131033410565457, 0.03587068764481023, 0.5910122821478258, 0.2657852739941089, 0.032768047478725755, 0.6480791612459094, 0.007281788328605723, 0.04369072997163434, 0.0032346289989141825, 0.49921107549908883, 0.0032346289989141825, 0.0938042409685113, 0.3989375765327492, 0.9967630438745603, 0.9322475652112187, 0.06623206562492572, 0.11226860974836396, 0.14730785737683424, 0.19593375204491542, 0.07508410206100774, 0.03217890088328903, 0.06221254170769213, 0.07508410206100774, 0.08724057572802804, 0.10368756951282021, 0.1086931763168874, 0.012434261627552578, 0.6123873851569644, 0.1802967935995124, 0.08082270057909176, 0.11501692005486135, 0.06504470189997308, 0.03502407025383166, 0.8555880019150305, 0.045030947469212136, 0.03428891390035845, 0.010972452448114706, 0.9532318064299651, 0.99726021377147, 0.976885882940015, 0.9932576339553324, 0.5062549411101344, 0.056373366804840286, 0.3924028473670255, 0.044214405337129635, 0.001105360133428241, 0.026465144496124162, 0.1826948684571152, 0.010244572063015805, 0.1844022971342845, 0.050369145976494376, 0.2748960170242574, 0.025611430157539514, 0.014513143755939057, 0.07341943311827993, 0.1570834382995757, 0.0043196875222960545, 0.3922276270244818, 0.011231187557969742, 0.1753793134052198, 0.012959062566888164, 0.10540037554402373, 0.1183594381109119, 0.050108375258634236, 0.12959062566888163, 0.03394603753160527, 0.21701216850561944, 0.0642549996133957, 0.09092688624537128, 0.029096603598518806, 0.329155328208244, 0.1436644802676866, 0.02424716966543234, 0.05334377326395115, 0.013335943315987787, 0.961263669295351, 0.0051866744746152035, 0.03284893833922962, 0.8787679598554495, 0.02463835401463877, 0.09444702372278195, 0.11919588097800739, 0.7693552317671386, 0.10835989179818853, 0.04862880140770134, 0.1350800039102815, 0.0583545616892416, 0.02809664081333855, 0.049709441438983586, 0.37498209085494144, 0.09185440265899142, 0.18262816528670056, 0.008645120250258015, 0.021612800625645037, 0.008458263891357261, 0.2059403382243507, 0.004413007247664658, 0.0025742542278043836, 0.778160278004868, 0.034863796335069405, 0.009094903391757236, 0.3046792636238674, 0.004547451695878618, 0.5017355037786075, 0.11671792686088453, 0.02576889294331217, 0.0030316344639190786, 0.02953500636088405, 0.9697327088490264, 0.07100582845538253, 0.038233907629821366, 0.8848418622901516, 0.023659915146291392, 0.9734365088759888, 0.981204188086129, 0.04342361478602026, 0.2320061704281654, 0.00496269883268803, 0.0502473256809663, 0.08064385603118049, 0.13523354319074882, 0.052728675097310315, 0.07133879571989044, 0.07382014513623444, 0.25619932723751954, 0.9981070157775827, 0.18146752055978835, 0.75742965103216, 0.053256772338198755, 0.007889892198251668, 0.020084267628305057, 0.010042133814152528, 0.03263693489599572, 0.09665553796121809, 0.35398521694887664, 0.30377454787811403, 0.08284760396675836, 0.07155020342583678, 0.028871134715688522, 0.003214221560797955, 0.016071107803989775, 0.9803375760433762, 0.9837681400236934, 0.9037084447906698, 0.011156894380131727, 0.07809826066092208, 0.011156894380131727, 0.9823021916920852, 0.03995893374587757, 0.03662902260038778, 0.7392402742987351, 0.18314511300193886, 0.04458556081414022, 0.9534450697177678, 0.9876228761373315, 0.9767021247527234, 0.9978181366174004, 0.0016836076545850402, 0.9982163139991092, 0.9946357969444942, 0.5858441428708525, 0.038165742206570194, 0.23281102746007817, 0.0038165742206570192, 0.13167181061266717, 0.0076331484413140385, 0.8763619039341459, 0.12122585414651009, 0.03957884258210967, 0.2171015923989251, 0.03201229914729459, 0.39346025861038436, 0.1786868334221716, 0.13852594903738386, 0.9991127640465765, 0.17325419223464403, 0.14280784882939276, 0.11671098305346313, 0.03117125634347152, 0.015223171702625627, 0.13048432887964823, 0.03914529866389447, 0.18920227687548993, 0.07611585851312813, 0.08626463964821188, 0.1213881325481018, 0.8754659256499463, 0.6718465071124546, 0.08857677830089576, 0.1019468580444272, 0.025068899519121442, 0.048466539070301455, 0.06350787878177432, 0.11654826221211997, 0.013374390745653112, 0.357924171383669, 0.23564402742341198, 0.08534135047226271, 0.12737514995860105, 0.06305069922950753, 0.9469690966548339, 0.04509376650737304, 0.4686077590702682, 0.023674091840102704, 0.0062666713694389505, 0.501333709555116, 0.06349606688897977, 0.07395424261187056, 0.16434276135971235, 0.05229087861445393, 0.2300798659035973, 0.23605596631667775, 0.06723112964715505, 0.03286855227194247, 0.08067735557658606, 0.06556869383703669, 0.008552438326570003, 0.03420975330628001, 0.022806502204186674, 0.8666470837590936, 0.08365389761632087, 0.15927702106147495, 0.1766770317656697, 0.012715392437680774, 0.013384623618611341, 0.10573852658702959, 0.1318385426433217, 0.1505770157093776, 0.037476946132111756, 0.12916161791959943, 0.9900197389422374, 0.005439668895287018, 0.9943952402642727, 0.05488487879132298, 0.02970240499295126, 0.2615103048292448, 0.07425601248237815, 0.03163951836205678, 0.02970240499295126, 0.009685566845527585, 0.11687250660269952, 0.2292250820108195, 0.16207181854849492, 0.5421098729733325, 0.016182384267860672, 0.22493514132326334, 0.014564145841074605, 0.04369243752322381, 0.11004021302145257, 0.022655337975004942, 0.025891814828577074, 0.9943215390944525, 0.9969822270457367, 0.9847253892220756, 0.9924759691573903, 0.9979352833404389, 0.9933564441553034, 0.2802090955573118, 0.014692611752068785, 0.48590566008627484, 0.16791556288078613, 0.04092941845219162, 0.010494722680049133, 0.041264035603198614, 0.008252807120639723, 0.018339571379199383, 0.006418849982719785, 0.0742752640857575, 0.8509561119948514, 0.08458235145277151, 0.0018796078100615894, 0.06766588116221721, 0.03195333277104702, 0.007518431240246357, 0.011277646860369537, 0.02819411715092384, 0.07706392021252516, 0.5695211664486616, 0.12217450765400331, 0.05486032696091971, 0.018675855986696074, 0.29647921378880016, 0.12372754591186148, 0.002334481998337009, 0.5030808706416254, 0.009898444188854277, 0.025619502606446364, 0.016303319840465867, 0.10655384038590192, 0.5589709659588298, 0.0244549797606988, 0.02270819549207746, 0.004658091382990248, 0.04483412956128114, 0.18632365531960993, 0.9753346611992885, 0.9899490877235307, 0.08218143353970109, 0.7906420675026414, 0.12468907157747751, 0.9907403688479834, 0.9986197271316006, 0.03614405706505241, 0.06255702184335993, 0.6575438073757611, 0.012511404368671987, 0.23076590279995, 0.010548513823546615, 0.9810117855898353, 0.9521476028570619, 0.04306195188800783, 0.9983756009599281, 0.00581452973329221, 0.13124224255145273, 0.02741135445694899, 0.03156458998072914, 0.29820231060741476, 0.2865732511408303, 0.05980659154243416, 0.12625835992291656, 0.0332258841902412, 0.11020323789249793, 0.26195851630183936, 0.6268938286671604, 0.10273259876122051, 0.007782772633425796, 0.22725696089603323, 0.0918367170744244, 0.004669663580055478, 0.026461426953647706, 0.4965408940125658, 0.042026972220499295, 0.05081078216628798, 0.1256898295692387, 0.05883353724517555, 0.008022755078887576, 0.6953054401702565, 0.016045510157775153, 0.04546227878036293, 0.005519750622408786, 0.9935551120335816, 0.9794181690415856, 0.9917206322694926, 0.9932758390037658, 0.006148850431928074, 0.025635608082180898, 0.9741531071228742, 0.014788631325248278, 0.015658550814968766, 0.11656921162254526, 0.36188650772372255, 0.4610573295518581, 0.021747987243012173, 0.007829275407484383, 0.08615771304686347, 0.1634787375760999, 0.6075223355868578, 0.14138701628203235, 0.9850346894763302, 0.018167566053645133, 0.9810485668968372, 0.9912883206822506, 0.0005930220771379626, 0.02075577269982869, 0.15833689459583603, 0.07175567133369347, 0.7240799561854524, 0.0011860441542759252, 0.023720883085518504, 0.9723672345937869, 0.02651910639801237, 0.080766227818248, 0.07493773715095174, 0.09492113372453888, 0.03413830247987802, 0.009991698286793567, 0.16236509716039546, 0.25229038174153756, 0.19067490897297723, 0.03663622705157641, 0.06328075581635925, 0.9971873891628046, 0.99046981440395, 0.9927857388330013, 0.22992043434462583, 0.6585375403451011, 0.00283852388079785, 0.11070243135111614, 0.42833641175554615, 0.12900825937815094, 0.0072476550212444354, 0.2928052628582752, 0.08552232925068434, 0.004348593012746662, 0.05290788165508438, 0.1614040586356406, 0.5551092857749135, 0.03318588121480461, 0.024135186338039717, 0.02715208463029468, 0.16442095692789557, 0.012067593169019859, 0.024135186338039717, 0.07239011180119588, 0.03217338302275372, 0.03436702277430512, 0.005849706004137041, 0.6332306749478347, 0.01901154451344538, 0.024130037267065294, 0.04826007453413059, 0.005849706004137041, 0.12357503933739498, 0.09506181579142406, 0.1089554657917091, 0.3210164394802705, 0.03290601315856986, 0.0036562236842855407, 0.15502388421370691, 0.041680950000855164, 0.12211787105513705, 0.05045588684314046, 0.06946825000142527, 0.019127131023096173, 0.2295255722771541, 0.1633775774889465, 0.00876660171891908, 0.17055025162260753, 0.2908917843095876, 0.08049334305552973, 0.036660334460934335, 0.4395136917127024, 0.10853844216075882, 0.06699903837083877, 0.029479576883169063, 0.08039884604500654, 0.08307880757984008, 0.06431907683600523, 0.048239307627003916, 0.07905886527758975, 0.04337984977265153, 0.5366707129016604, 0.14873091350623383, 0.14873091350623383, 0.011154818512967537, 0.07064718391546107, 0.006197121396093076, 0.034703879818121224, 0.9966238822768241, 0.002113511955496679, 0.1342080091740391, 0.08242696626437047, 0.05706482279841033, 0.025362143465960146, 0.01796485162172177, 0.004227023910993358, 0.6763238257589372, 0.09657837730321575, 0.901398188163347, 0.07900227826149732, 0.1518217695286166, 0.14289107720340385, 0.09411575758108812, 0.007556739659795396, 0.22945009512469658, 0.05014927228773308, 0.0769413492633713, 0.04946229595502441, 0.119533881891309, 0.026976816038844696, 0.8227928891847632, 0.03596908805179293, 0.07643431211005997, 0.017984544025896464, 0.022480680032370578, 0.07200605011519948, 0.29059584510776937, 0.039217580866314, 0.02057315717577128, 0.3780317631047973, 0.11958147608417057, 0.009643667426142788, 0.06171947152731384, 0.009000756264399935, 0.9885822496506461, 0.010297731767194231, 0.9966252003465084, 0.994481465612073, 0.03384816559263177, 0.014103402330263238, 0.05218258862197398, 0.02256544372842118, 0.018334423029342208, 0.8574868616800049, 0.994692619491746, 0.00479918793755108, 0.07038808975074917, 0.04319269143795972, 0.18316900628319954, 0.35513990737877993, 0.0655889018131981, 0.02879512762530648, 0.03199458625034053, 0.02159634571897986, 0.19516697612707726, 0.04010781032887206, 0.09288124497212477, 0.48340466133219484, 0.03588593555741185, 0.027442186014491412, 0.08654843281493445, 0.01688749908584087, 0.09077030758639466, 0.12665624314380652, 0.9918115305586622, 0.0985365274164993, 0.12624992575238975, 0.7574995545143385, 0.018475598890593622, 0.9965067408340341, 0.04489352086309887, 0.953987318340851, 0.028009218154140144, 0.09061805873398282, 0.8798189702535787, 0.04673764516409657, 0.02921102822756036, 0.1881190217854887, 0.009347529032819315, 0.012852852420126558, 0.09931749597370522, 0.002336882258204829, 0.14021293549228972, 0.4697133338991706, 0.003505323387307243, 0.09236467331332192, 0.006481731460583995, 0.04213125449379596, 0.8555885527970872, 0.03605750007927333, 0.003605750007927333, 0.014423000031709331, 0.9447065020769612, 0.9982259409004856, 0.995866255918821, 0.996138590550623, 0.9940993611459126, 0.9918359679414975, 0.9986521657813501, 0.012484593234921982, 0.9862828655588366, 0.07743806250205391, 0.04496403629151518, 0.6394885161459937, 0.019984016129562302, 0.027478022178148164, 0.18735015121464657, 0.10567313938965008, 0.03592886739248102, 0.0021134627877930014, 0.7397119757275505, 0.07185773478496205, 0.044382718543653034, 0.9678386279232342, 0.04736919278075071, 0.8582183162630129, 0.09473838556150142, 0.01633974184032439, 0.974937929806022, 0.9887877616243979, 0.05923439054066477, 0.04173332060819563, 0.13596985101379866, 0.029617195270332384, 0.012116125337863248, 0.38636977466297245, 0.05654191824336182, 0.27867088277085467, 0.033454781502050425, 0.9069962985000337, 0.05575796917008404, 0.0586642191728906, 0.0847372054719531, 0.2027898934371527, 0.013760742768949648, 0.012312243530112843, 0.03259123287382811, 0.12239818568171003, 0.24769336984109366, 0.04417922678452255, 0.18251090409343743, 0.03026002116647622, 0.10627909873103843, 0.2206767397262534, 0.025831725386016285, 0.38673783149350094, 0.03542636624367947, 0.1313727748203114, 0.0036902464837166122, 0.059043943739465796, 0.9974548049236347, 0.9905761261253843, 0.9384343070306905, 0.05990006215089514, 0.9811848459783259, 0.9912871685808992, 0.002084330878443547, 0.2688786833192176, 0.006252992635330642, 0.09587922040840317, 0.04898177564342336, 0.26471002156233053, 0.3043123082527579, 0.009379488952995963, 0.989253759095783, 0.2903719033782738, 0.019358126891884916, 0.009679063445942458, 0.0024197658614856146, 0.6775344412159722, 0.4755898424647405, 0.06993968271540302, 0.013987936543080604, 0.00799310659604606, 0.013987936543080604, 0.03197242638418424, 0.07193795936441454, 0.11190349234464483, 0.18583972835807086, 0.01598621319209212, 0.17897104337790098, 0.06268110274986394, 0.05030983247028553, 0.06020684869394825, 0.42722120032144106, 0.0940216541247959, 0.017319778391409774, 0.10061966494057106, 0.009072264871690832, 0.14747931964950742, 0.3693077178000062, 0.3473686454554514, 0.052410006156436525, 0.08288093996831822, 0.988330931245933, 0.4520624397989245, 0.007965857970025102, 0.20910377171315891, 0.03982928985012551, 0.041820754342631786, 0.04779514782015061, 0.12347079853538907, 0.011948786955037653, 0.06571832825270708, 0.9005452057077578, 0.030875835624265983, 0.0668976438525763, 0.9927432549170008, 0.9912792483623529, 0.9899134257667985, 0.8405818924746027, 0.010992788480487393, 0.012458493611219045, 0.010992788480487393, 0.059361057794631925, 0.03590977570292549, 0.030046955179998874, 0.9988499458128964, 0.9960937147144792, 0.5985063256098486, 0.006389747248503721, 0.0681573039840397, 0.12353511347107195, 0.20021208045311661, 0.014497033869107659, 0.020710048384439513, 0.9650882547148812, 0.11990225021869758, 0.0552882598230661, 0.40433703268194127, 0.0013322472246521952, 0.10458140713519733, 0.0552882598230661, 0.12389899189265416, 0.0839315751530883, 0.05129151814910952, 0.9616596573560019, 0.032488501937702766, 0.00519455586477929, 0.26803908262261134, 0.03843971339936674, 0.014544756421382012, 0.033245157534587455, 0.4477707155439748, 0.002077822345911716, 0.19115965582387787, 0.9971137889075197, 0.34182010244068045, 0.6540596190932251, 0.9409457256573458, 0.04952345924512346, 0.01353462182673318, 0.008459138641708238, 0.14549718463738168, 0.09135869733044896, 0.4906300412190778, 0.011842794098391533, 0.003383655456683295, 0.02706924365346636, 0.2097866383143643, 0.0260859393995198, 0.057389066678943564, 0.22908197690851026, 0.6867716409182668, 0.04824669502759101, 0.05513908003153259, 0.02986700168374682, 0.16541724009459777, 0.5858527253350337, 0.11717054506700675, 0.9815973261961051, 0.011792289484964379, 0.06367836321880764, 0.03852147898421697, 0.10848906326167228, 0.2775118792128284, 0.1289290317022772, 0.04481070004286464, 0.14465208434889637, 0.18160125806845143, 0.00773360739443267, 0.16240575528308607, 0.4270669861147819, 0.25349046459529306, 0.03952732668265587, 0.10655192410107234, 0.0025778691314775567, 0.9890454655219082, 0.924236845990628, 0.0693177634492971, 0.022964584471696282, 0.974354512584828, 0.009743679956379004, 0.8038535964012679, 0.09743679956379003, 0.08769311960741104, 0.017140351128896184, 0.17630075446864646, 0.007345864769526936, 0.028159148283186587, 0.03305639146287121, 0.49707018273798936, 0.24118922659946773, 0.06149472963251047, 0.2940437646795903, 0.07704512103383496, 0.11450742759157122, 0.012016211537387104, 0.26506348979530375, 0.03887597850331122, 0.03534179863937383, 0.04523750225839851, 0.05654687782299814, 0.9349446577843689, 0.040299338697602105, 0.01611973547904084, 0.9805576312989359, 0.9791156059530128, 0.5145931627756388, 0.4593619594410807, 0.024247845366391355, 0.2851754087927814, 0.6211960455098572, 0.09284780751392883, 0.08675205758022154, 0.026025617274066465, 0.010844007197527693, 0.08349885542096323, 0.11928407917280462, 0.18326372163821802, 0.018434812235797078, 0.3578522375184139, 0.11494647629379355, 0.017238619579353222, 0.07086988049289658, 0.614844098330265, 0.028731032632255373, 0.02490022828128799, 0.05171585873805967, 0.19154021754836914, 0.9911085712876694, 0.9920061125411972, 0.026841835351531437, 0.007669095814723268, 0.015338191629446536, 0.6825495275103709, 0.03067638325889307, 0.09586369768404085, 0.1342091767576572, 0.9922529493363029, 0.0200893355633648, 0.06473230348195325, 0.9129486939351337, 0.994415834129841, 0.027592302862158014, 0.04598717143693003, 0.10117177716124606, 0.8231703687210474, 0.8503735790190533, 0.14847792649539027, 0.0832213760216706, 0.08077368849162146, 0.045282219305909005, 0.024476875300491353, 0.01590996894531938, 0.4369122241137707, 0.039163000480786164, 0.008566906355171974, 0.06608756331132666, 0.19948653369900454, 0.08923174064319893, 0.020591940148430524, 0.7220907012049637, 0.06314861645518693, 0.10433249675204798, 0.9926949203094935, 0.996288916423219, 0.07701346885052457, 0.8214770010722622, 0.07187923759382293, 0.030805387540209832, 0.8683727647002458, 0.13053969665428533, 0.9924011799127862, 0.004231987974041732, 0.008570246783032542, 0.0017140493566065085, 0.9872924294053488, 0.05565897833866141, 0.7421197111821521, 0.023191240974442254, 0.12059445306709972, 0.018552992779553804, 0.013914744584665352, 0.023191240974442254, 0.9970227451167681, 0.998991216002099, 0.07841142888269718, 0.8082408823293402, 0.08444307725828927, 0.030158241877960457, 0.24229812245584825, 0.08387242700394747, 0.08107667943714922, 0.09878308069353813, 0.036344718368377237, 0.07641710015915214, 0.11648948194992705, 0.0857362587151463, 0.17985976013068736, 0.01471447348715965, 0.8313677520245202, 0.012262061239299708, 0.009809648991439766, 0.13243026138443684, 0.9040348214842682, 0.04204813123182642, 0.0510584450672178, 0.07300803874802629, 0.5919570709299429, 0.234809638135544, 0.09865951182165715, 0.008415495176156392, 0.0031558106910586467, 0.3481911129134707, 0.07468751968838798, 0.013675179661254137, 0.41130732673464365, 0.0515449079539579, 0.08836269934964211, 0.047585701793062686, 0.047585701793062686, 0.00253790409563001, 0.01015161638252004, 0.47395358985890435, 0.012055044454242547, 0.08882664334705034, 0.05456493805604521, 0.05266150998432271, 0.21064603993729084, 0.9929192361283639, 0.20202457599772397, 0.7959768294310324, 0.05070045626839794, 0.21294191632727133, 0.013520121671572783, 0.45968413683347464, 0.008450076044732989, 0.04225038022366495, 0.043940395432611544, 0.1656214904767666, 0.0033800304178931958, 0.02025191490289755, 0.0613886170494082, 0.03607372342078626, 0.018986170221466453, 0.01265744681431097, 0.13796617027598956, 0.032276489376492974, 0.03354223405792407, 0.059490000027261555, 0.5879384045247446, 0.997205696399201, 0.9579041687011729, 0.035642945812136666, 0.9939707926651241, 0.6583229295410221, 0.18150024692953412, 0.049220405946992306, 0.04614413057530529, 0.006152550743374038, 0.058449232062053366, 0.9877423001001452, 0.992886935601146, 0.9947888638074714, 0.0025905959994986234, 0.5461697920946222, 0.02577792529060164, 0.038666887935902464, 0.08055601653313013, 0.3077239831565571, 0.011805446370503696, 0.9119707321214106, 0.05607587025989256, 0.014756807963129621, 0.0009852253347278584, 0.025615858702924318, 0.12216794150625443, 0.030541985376563607, 0.8206927038283061, 0.017059422904368855, 0.9809168170012093, 0.9971936146109773, 0.11797115547645869, 0.01913045764483114, 0.06376819214943713, 0.10681172185030718, 0.019927560046699103, 0.12115956508393054, 0.004782614411207785, 0.10043490263536348, 0.44717444744792784, 0.00791170340332878, 0.029668887762482922, 0.042525405792892185, 0.00791170340332878, 0.00791170340332878, 0.7071084916725097, 0.19680362215780337, 0.9962753887303096, 0.015519042485540653, 0.38439474464185314, 0.037006947465520024, 0.07162634993326455, 0.0011937724988877426, 0.4894467245439745, 0.9192291041276178, 0.03485228830815613, 0.04356536038519516, 0.0029320754053195866, 0.03459848978277112, 0.13370263848257316, 0.024629433404684528, 0.025802263566812363, 0.4732369704185813, 0.16185056237364118, 0.10672754475363296, 0.03577131994489896, 0.9833651258987871, 0.010437188547374394, 0.030659241357912283, 0.013046485684217993, 0.03326853849475588, 0.01630810710527249, 0.1911310152737936, 0.06588475270530086, 0.0006523242842108996, 0.175475232452732, 0.46315024178973874, 0.5670816900205119, 0.011573095714704325, 0.4189460648722966, 0.9810451617772518, 0.08706007693850996, 0.9092941369133263, 0.013798748745271499, 0.055194994981085994, 0.0386364964867602, 0.8886394191954845, 0.9532886164237453, 0.04598911312864381, 0.9864430559014641, 0.020605561525318415, 0.9684613916899655, 0.9872194866941052, 0.0062880222082427085, 0.11693334406662939, 0.592130550805485, 0.002487943490779349, 0.26620995351339033, 0.009951773963117395, 0.009951773963117395, 0.09760929375570032, 0.9028859672402281, 0.9941099917352093, 0.0457883044504159, 0.3250969615979529, 0.0625773494155684, 0.055709103748006014, 0.24573056721723202, 0.07784011756570704, 0.03739378196783966, 0.03052553630027727, 0.12057586838609521, 0.7009699615699385, 0.03389305308689813, 0.012324746577053864, 0.1817900120115445, 0.06932669949592798, 0.9990095173028503, 0.025508248585237356, 0.11733794349209183, 0.2254929174934982, 0.05611814688752218, 0.07346375592548358, 0.08366705535957852, 0.30303799319261976, 0.020406598868189883, 0.09489068473708295, 0.5800076657787591, 0.2495934627326627, 0.05704993433889433, 0.04516453135162468, 0.06655825672871005, 0.024539971736235004, 0.9723963800483121, 0.037765059344661296, 0.21877689551389995, 0.08594806609474641, 0.11069069118262795, 0.40239321853449456, 0.006511217128389879, 0.13543331627050947, 0.0922117035702225, 0.02543771132971655, 0.4621184224898507, 0.4197222369403231, 0.030064711073205165, 0.0012526962947168817, 0.025053925894337636, 0.2555500441222439, 0.29814171814261786, 0.02129583701018699, 0.045097066609807744, 0.3231956440369555, 0.9908549466456411, 0.050450941191147174, 0.050450941191147174, 0.8778463767259609, 0.020180376476458872, 0.9925910855359296, 0.007205424231070882, 0.07467439657655278, 0.03537208258889342, 0.032096889756588476, 0.07598447370947475, 0.00851550136399286, 0.0006550385664609893, 0.06550385664609892, 0.004585269965226925, 0.6949959190151096, 0.991420462593772, 0.02119997598022666, 0.0015142839985876186, 0.036342815966102844, 0.03179996397033999, 0.003028567997175237, 0.9070561151539835, 0.9951338629702335, 0.9845536288839066, 0.9934086019392118, 0.007146824474382818, 0.9882347469619309, 0.023815965003141627, 0.15182677689502788, 0.817185299170297, 0.004465493438089055, 0.04282821919779256, 0.002855214613186171, 0.005710429226372342, 0.21414109598896283, 0.7080932240701704, 0.02855214613186171, 0.9771296297144599, 0.12475270543551786, 0.10811901137744882, 0.03683175112858147, 0.01425745204977347, 0.08316847029034524, 0.038019872132729254, 0.0879209543069364, 0.2887134040079128, 0.17346566660557722, 0.04514859815761599, 0.22484266276045767, 0.08024687627140914, 0.29070566498321804, 0.038609346130583644, 0.08176096827653007, 0.01741205805889066, 0.05677845019203477, 0.060563680204837086, 0.1476239704992904, 0.1187657721922714, 0.870948996076657, 0.9976338295253846, 0.7948291950003279, 0.10097480449304866, 0.03890772283218388, 0.06484620472030647, 0.012175206174327402, 0.029761615092800314, 0.018262809261491104, 0.9388436761092464, 0.9410301459484233, 0.0455704671161464, 0.00683557006742196, 0.00455704671161464, 0.9935490333879763, 0.9419372017732971, 0.056743204926102235, 0.1624126909565422, 0.04200328214393333, 0.45083522834488443, 0.3136245066747022, 0.028002188095955553, 0.0028002188095955552, 0.0487697161323556, 0.3978582105534273, 0.05133654329721642, 0.04705849802244839, 0.003422436219814428, 0.2660944160905718, 0.04278045274768035, 0.003422436219814428, 0.043636061802633956, 0.09497260509985038, 0.9936711429463477, 0.9186361277064118, 0.07874023951769243, 0.07282414782649979, 0.15844172702792522, 0.17812392914319544, 0.033459743595959365, 0.3847870513535327, 0.03247563349019585, 0.02853919306714181, 0.003936440423054043, 0.10825211163398618, 0.9977941535510442, 0.9865324314246532], \"Term\": [\"AAA\", \"ADL\", \"AMA\", \"AMA\", \"ATF\", \"ATI\", \"Administration\", \"Administration\", \"Administration\", \"Alaska\", \"Allah\", \"Alomar\", \"Amanda\", \"Annual\", \"Apple\", \"Apple\", \"April\", \"April\", \"April\", \"April\", \"April\", \"April\", \"April\", \"April\", \"Arabs\", \"Argic\", \"Armenia\", \"Armenian\", \"Armenians\", \"Article\", \"Article\", \"Article\", \"Article\", \"Article\", \"Article\", \"Article\", \"Article\", \"Article\", \"Atheists\", \"Azerbaijan\", \"BATF\", \"BMW\", \"BOS\", \"BUF\", \"Baalke\", \"Banks\", \"BeHanna\", \"Beauchaine\", \"Beth\", \"Bethesda\", \"Bible\", \"Bible\", \"Board\", \"Board\", \"Board\", \"Bontchev\", \"Borland\", \"Bosnia\", \"Boston\", \"Boston\", \"Boston\", \"Boston\", \"Boston\", \"Boston\", \"Braves\", \"Buffalo\", \"Buffalo\", \"Bure\", \"CAL\", \"CHI\", \"CMOS\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canucks\", \"Center\", \"Center\", \"Center\", \"Center\", \"Center\", \"Center\", \"Center\", \"Center\", \"Center\", \"Chicago\", \"Chicago\", \"Chicago\", \"Chicago\", \"Chicago\", \"Chicago\", \"Chicago\", \"Chip\", \"Chip\", \"Christ\", \"Christ\", \"Christian\", \"Christian\", \"Christian\", \"Christian\", \"Christianity\", \"Christianity\", \"Christians\", \"Christians\", \"Christians\", \"Church\", \"Church\", \"Clayton\", \"Clayton\", \"Clayton\", \"Cliff\", \"Clinton\", \"Clinton\", \"Clinton\", \"Clinton\", \"Clipper\", \"Clipper\", \"Communication\", \"Communication\", \"Communications\", \"Communications\", \"Communications\", \"Communications\", \"Communications\", \"CompuServe\", \"Constitution\", \"Constitution\", \"Constitution\", \"Cramer\", \"Cubs\", \"Cup\", \"Cup\", \"DES\", \"DET\", \"DOS\", \"Dare\", \"Daryl\", \"David\", \"David\", \"David\", \"David\", \"David\", \"David\", \"David\", \"David\", \"David\", \"David\", \"Davidian\", \"Davidians\", \"Denning\", \"Denver\", \"Denver\", \"Denver\", \"Detroit\", \"Diamond\", \"Distribution\", \"Distribution\", \"Distribution\", \"Distribution\", \"Distribution\", \"Distribution\", \"Distribution\", \"Distribution\", \"ESPN\", \"Earth\", \"Earth\", \"Electronic\", \"Electronic\", \"Express\", \"Express\", \"Express\", \"Express\", \"FAQ\", \"FAQ\", \"FAQ\", \"FAQ\", \"FBI\", \"FBI\", \"FBI\", \"FTP\", \"FTP\", \"Frost\", \"GOD\", \"Gaza\", \"God\", \"God\", \"Gordon\", \"Gordon\", \"Greece\", \"Gun\", \"Halifax\", \"Hamburg\", \"Hard\", \"Hellman\", \"Henry\", \"Henry\", \"Hezbollah\", \"Hockey\", \"Holy\", \"Honda\", \"IDE\", \"ISA\", \"Information\", \"Information\", \"Information\", \"Information\", \"Information\", \"Information\", \"InterCon\", \"Intergraph\", \"Islam\", \"Islam\", \"Islanders\", \"Israel\", \"Israelis\", \"JPEG\", \"JPL\", \"Jesus\", \"Jet\", \"Jet\", \"Jews\", \"Jews\", \"Jews\", \"John\", \"John\", \"John\", \"John\", \"John\", \"John\", \"John\", \"John\", \"John\", \"John\", \"Jose\", \"Jose\", \"Jose\", \"Jupiter\", \"Keenan\", \"Keller\", \"Key\", \"Key\", \"Key\", \"Kipling\", \"Koresh\", \"Koresh\", \"Kratz\", \"Leafs\", \"Lebanon\", \"Livesey\", \"Livni\", \"Lord\", \"MSG\", \"Mac\", \"Mars\", \"Medical\", \"Medical\", \"Micro\", \"Minnesota\", \"Minnesota\", \"Montreal\", \"Moon\", \"Motif\", \"Mozumder\", \"Murray\", \"Murray\", \"Myrto\", \"NASA\", \"NASA\", \"NEC\", \"NEC\", \"NETCOM\", \"NHL\", \"NHL\", \"NIST\", \"NSA\", \"National\", \"National\", \"National\", \"National\", \"National\", \"National\", \"National\", \"National\", \"National\", \"Nazi\", \"New\", \"New\", \"New\", \"New\", \"New\", \"New\", \"New\", \"New\", \"New\", \"Nntp\", \"Nntp\", \"Nntp\", \"Nntp\", \"Nntp\", \"Nntp\", \"Nntp\", \"Nntp\", \"Nntp\", \"Novell\", \"Nye\", \"Nyx\", \"Observatory\", \"Oilers\", \"Online\", \"Online\", \"Online\", \"Operation\", \"Oracle\", \"Ottawa\", \"Ottawa\", \"Ottawa\", \"PGP\", \"PGP\", \"PIT\", \"Palestine\", \"Palestinians\", \"Paul\", \"Paul\", \"Paul\", \"Paul\", \"Paul\", \"Paul\", \"Paul\", \"Paul\", \"Paul\", \"Paul\", \"Pens\", \"Pittsburgh\", \"Pittsburgh\", \"Pittsburgh\", \"Pittsburgh\", \"Posting\", \"Posting\", \"Posting\", \"Posting\", \"Posting\", \"Posting\", \"Posting\", \"Posting\", \"Posting\", \"President\", \"President\", \"President\", \"President\", \"President\", \"Propulsion\", \"Pts\", \"Public\", \"Public\", \"Public\", \"Public\", \"QUE\", \"Quadra\", \"RISC\", \"Rangers\", \"Rangers\", \"Reply\", \"Reply\", \"Reply\", \"Reply\", \"Reply\", \"Reply\", \"Reply\", \"Reply\", \"Reply\", \"Reply\", \"Reserve\", \"Reserve\", \"Reserve\", \"Rider\", \"Roby\", \"Roger\", \"Roger\", \"Rushdie\", \"SALE\", \"SCSI\", \"SHO\", \"STL\", \"Sabbath\", \"Sale\", \"San\", \"San\", \"San\", \"San\", \"San\", \"San\", \"San\", \"Sandvik\", \"Satan\", \"Schneider\", \"Schneider\", \"Security\", \"Security\", \"Security\", \"Senate\", \"Senator\", \"Serdar\", \"Shuttle\", \"Singapore\", \"Skepticism\", \"Son\", \"Sox\", \"Space\", \"Spirit\", \"Standards\", \"State\", \"State\", \"State\", \"State\", \"State\", \"State\", \"State\", \"State\", \"State\", \"States\", \"States\", \"States\", \"States\", \"Sternlight\", \"TOR\", \"Tavares\", \"Templeton\", \"Testament\", \"Texas\", \"Texas\", \"Texas\", \"Texas\", \"Texas\", \"Texas\", \"Texas\", \"Texas\", \"Toal\", \"Toronto\", \"Toronto\", \"Toronto\", \"Toronto\", \"Toyota\", \"Turkey\", \"Turks\", \"Type\", \"UPS\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"United\", \"United\", \"United\", \"United\", \"United\", \"VAN\", \"VESA\", \"Veal\", \"Venus\", \"Vesselin\", \"Virus\", \"Waco\", \"Weiss\", \"Whalers\", \"Windows\", \"Wings\", \"Xlib\", \"Zoology\", \"abortion\", \"abuse\", \"abuse\", \"abuse\", \"abuse\", \"abuse\", \"accept\", \"accept\", \"accept\", \"accept\", \"accept\", \"accept\", \"accept\", \"accept\", \"accept\", \"access\", \"access\", \"access\", \"access\", \"access\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"address\", \"address\", \"address\", \"address\", \"address\", \"address\", \"address\", \"address\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"air\", \"air\", \"air\", \"air\", \"air\", \"algorithm\", \"algorithm\", \"algorithm\", \"alias\", \"aluminum\", \"amp\", \"amp\", \"anonymous\", \"anonymous\", \"anonymous\", \"app\", \"application\", \"application\", \"application\", \"application\", \"application\", \"arab\", \"archive\", \"archive\", \"archive\", \"archive\", \"argument\", \"argument\", \"argument\", \"argument\", \"argument\", \"argument\", \"armenian\", \"atheism\", \"atheism\", \"atheist\", \"atheist\", \"atmosphere\", \"atom\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"authorization\", \"auto\", \"auto\", \"auto\", \"auto\", \"automatic\", \"automatic\", \"automatic\", \"automatic\", \"automatic\", \"automatic\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"baseball\", \"battery\", \"battery\", \"belief\", \"belief\", \"belief\", \"bible\", \"biblical\", \"biblical\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"bike\", \"biker\", \"bill\", \"bill\", \"bill\", \"bill\", \"billion\", \"billion\", \"billion\", \"bios\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"blah\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"border\", \"border\", \"border\", \"brake\", \"brake\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"cache\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"captain\", \"captain\", \"car\", \"car\", \"card\", \"card\", \"card\", \"card\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"catholic\", \"cd\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"chastity\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"child\", \"child\", \"child\", \"child\", \"child\", \"chip\", \"chip\", \"chip\", \"chip\", \"christian\", \"christian\", \"christian\", \"church\", \"church\", \"church\", \"cipher\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"civilian\", \"civilian\", \"civilian\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"client\", \"client\", \"clipper\", \"clipper\", \"coach\", \"code\", \"code\", \"code\", \"code\", \"code\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"comet\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"computer\", \"computer\", \"computer\", \"computer\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"controller\", \"convertible\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"cop\", \"cop\", \"copper\", \"copy\", \"copy\", \"copy\", \"copy\", \"copy\", \"copy\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"countersteere\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"court\", \"court\", \"court\", \"court\", \"cpu\", \"crime\", \"crime\", \"crime\", \"crime\", \"crime\", \"crypto\", \"cryptography\", \"cryptography\", \"cryptosystem\", \"cult\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"decrypt\", \"detector\", \"die\", \"die\", \"die\", \"die\", \"die\", \"die\", \"disease\", \"disease\", \"disk\", \"disk\", \"disk\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"doctrine\", \"dog\", \"dog\", \"dog\", \"dog\", \"drain\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"driver\", \"driver\", \"driver\", \"driver\", \"drug\", \"drug\", \"drug\", \"drug\", \"drug\", \"drug\", \"electronic\", \"electronic\", \"electronic\", \"electronic\", \"electronic\", \"email\", \"email\", \"email\", \"email\", \"email\", \"encrypt\", \"encryption\", \"encryption\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"enforcement\", \"enforcement\", \"enforcement\", \"enforcement\", \"enforcement\", \"engine\", \"engine\", \"engine\", \"engine\", \"entry\", \"entry\", \"entry\", \"escrow\", \"escrowe\", \"eternal\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"faith\", \"faith\", \"faith\", \"fan\", \"fan\", \"fan\", \"faq\", \"faq\", \"faq\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"file\", \"file\", \"file\", \"file\", \"file\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"firearm\", \"firearm\", \"flight\", \"flight\", \"flight\", \"floppy\", \"floppy\", \"fluid\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"font\", \"food\", \"food\", \"food\", \"food\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"format\", \"format\", \"format\", \"forsale\", \"forum\", \"forum\", \"forum\", \"forum\", \"fpu\", \"freedom\", \"freedom\", \"freedom\", \"freedom\", \"fund\", \"fund\", \"funding\", \"fuse\", \"game\", \"game\", \"gay\", \"genocide\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"god\", \"god\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"graphic\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"greek\", \"greek\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"guilty\", \"guilty\", \"gun\", \"gun\", \"gun\", \"gun\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"health\", \"health\", \"health\", \"health\", \"health\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"heaven\", \"heaven\", \"helmet\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hitter\", \"hockey\", \"homeopathy\", \"homicide\", \"homosexual\", \"homosexuality\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"info\", \"info\", \"info\", \"info\", \"info\", \"info\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"infrastructure\", \"ink\", \"insurance\", \"insurance\", \"insurance\", \"intellect\", \"interface\", \"internet\", \"internet\", \"internet\", \"internet\", \"internet\", \"investment\", \"investment\", \"islamic\", \"islamic\", \"israeli\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"jewish\", \"jewish\", \"jewish\", \"job\", \"job\", \"job\", \"job\", \"job\", \"job\", \"job\", \"job\", \"judge\", \"judge\", \"judge\", \"judge\", \"judge\", \"judge\", \"judge\", \"jumper\", \"jumper\", \"jury\", \"justification\", \"key\", \"key\", \"keyboard\", \"keyboard\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"land\", \"land\", \"land\", \"land\", \"landing\", \"launch\", \"launch\", \"launcher\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"league\", \"league\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"lebanese\", \"led\", \"libertarian\", \"license\", \"license\", \"license\", \"license\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lunar\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"mailing\", \"mailing\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"marriage\", \"marriage\", \"massacre\", \"meg\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"menu\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"methodology\", \"mile\", \"mile\", \"mile\", \"mile\", \"militia\", \"mission\", \"mission\", \"mode\", \"mode\", \"mode\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"monitor\", \"monitor\", \"monitor\", \"monitor\", \"moon\", \"moon\", \"moon\", \"moon\", \"moral\", \"morality\", \"motherboard\", \"motorcycle\", \"motto\", \"mouse\", \"muscle\", \"muscle\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"newsgroup\", \"newsgroup\", \"newsgroup\", \"newsgroup\", \"newsgroup\", \"newsgroup\", \"nickname\", \"objective\", \"objective\", \"objective\", \"occupy\", \"occupy\", \"odometer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"oil\", \"oil\", \"oil\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"orbit\", \"orbital\", \"outlet\", \"outlet\", \"ozone\", \"palestinian\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"payload\", \"peace\", \"peace\", \"peace\", \"peace\", \"peace\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"physics\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pitch\", \"pitch\", \"pitch\", \"pitcher\", \"pixel\", \"plaintext\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"player\", \"playoff\", \"police\", \"police\", \"police\", \"police\", \"police\", \"port\", \"port\", \"port\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"prayer\", \"prayer\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"printer\", \"privacy\", \"privacy\", \"probe\", \"probe\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"program\", \"program\", \"program\", \"program\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"projection\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"puck\", \"radar\", \"radar\", \"ram\", \"ram\", \"random\", \"random\", \"random\", \"random\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"receiver\", \"receiver\", \"receiver\", \"recipient\", \"relay\", \"religion\", \"religion\", \"religion\", \"religious\", \"religious\", \"religious\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"request\", \"request\", \"request\", \"request\", \"request\", \"request\", \"request\", \"resurrection\", \"revelation\", \"review\", \"review\", \"review\", \"review\", \"review\", \"review\", \"review\", \"revolver\", \"ride\", \"ride\", \"ride\", \"rider\", \"rocket\", \"rocket\", \"rocket\", \"rocket\", \"rsa\", \"rsa\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"sale\", \"sale\", \"sale\", \"sale\", \"sale\", \"salvation\", \"satellite\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"science\", \"science\", \"score\", \"score\", \"screen\", \"screen\", \"screen\", \"screw\", \"screw\", \"screw\", \"screw\", \"screw\", \"screw\", \"screw\", \"scripture\", \"season\", \"seat\", \"seat\", \"seat\", \"seat\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"secret\", \"secret\", \"secret\", \"secret\", \"secret\", \"secure\", \"secure\", \"secure\", \"security\", \"security\", \"security\", \"security\", \"sell\", \"sell\", \"sell\", \"sell\", \"sell\", \"sell\", \"sell\", \"sell\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"sensor\", \"server\", \"server\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"sex\", \"sexual\", \"sexual\", \"shameful\", \"shot\", \"shot\", \"shot\", \"shot\", \"shot\", \"shot\", \"shuttle\", \"simm\", \"sin\", \"sin\", \"site\", \"site\", \"site\", \"site\", \"site\", \"society\", \"society\", \"society\", \"society\", \"software\", \"software\", \"software\", \"software\", \"software\", \"solar\", \"solar\", \"soldier\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"spacecraft\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"stat\", \"stat\", \"stat\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"steering\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"switch\", \"switch\", \"switch\", \"symmetric\", \"tap\", \"tap\", \"tax\", \"tax\", \"tax\", \"tax\", \"team\", \"team\", \"telnet\", \"temperature\", \"temperature\", \"territory\", \"territory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"ticket\", \"ticket\", \"tire\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"turkish\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"upgrade\", \"upgrade\", \"usa\", \"usa\", \"usa\", \"usa\", \"usa\", \"usa\", \"usa\", \"user\", \"user\", \"user\", \"user\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"valve\", \"van\", \"van\", \"van\", \"van\", \"verse\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"vga\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"village\", \"volt\", \"voltage\", \"voltage\", \"wagon\", \"war\", \"war\", \"war\", \"war\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"watt\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wheel\", \"wheel\", \"widget\", \"win\", \"win\", \"win\", \"win\", \"window\", \"window\", \"window\", \"window\", \"wire\", \"wire\", \"wire\", \"wire\", \"wiretap\", \"wiring\", \"wiring\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"workstation\", \"worship\", \"worship\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"xterm\", \"xxdate\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el818721406648530071849217669371\", ldavis_el818721406648530071849217669371_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el818721406648530071849217669371\", ldavis_el818721406648530071849217669371_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el818721406648530071849217669371\", ldavis_el818721406648530071849217669371_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0      0.085710 -0.223205  1       1        8.222936 \n",
       "1      0.124518  0.114647  2       1        10.589897\n",
       "2     -0.003980 -0.101310  3       1        10.087342\n",
       "3     -0.095830  0.139347  4       1        6.344695 \n",
       "4     -0.217733  0.084199  5       1        7.339931 \n",
       "5      0.142294  0.107310  6       1        12.595414\n",
       "6      0.172224  0.090780  7       1        8.682405 \n",
       "7      0.009875 -0.200369  8       1        9.235253 \n",
       "8     -0.005646  0.023338  9       1        10.555553\n",
       "9     -0.211433 -0.034737  10      1        16.346574, topic_info=             Term         Freq        Total Category  logprob  loglift\n",
       "438   God          2875.000000  2875.000000  Default  30.0000  30.0000\n",
       "629   key          2114.000000  2114.000000  Default  29.0000  29.0000\n",
       "1199  game         1781.000000  1781.000000  Default  28.0000  28.0000\n",
       "293   file         2719.000000  2719.000000  Default  27.0000  27.0000\n",
       "683   team         1522.000000  1522.000000  Default  26.0000  26.0000\n",
       "...    ...                 ...          ...      ...      ...      ...\n",
       "769   application  623.677897   843.836191   Topic10 -5.5105   1.5088 \n",
       "108   machine      640.003987   946.292258   Topic10 -5.4847   1.4201 \n",
       "277   support      710.281217   1532.979876  Topic10 -5.3805   1.0418 \n",
       "319   available    607.831455   1502.167907  Topic10 -5.5362   0.9064 \n",
       "676   source       561.285252   1254.543955  Topic10 -5.6159   1.0069 \n",
       "\n",
       "[707 rows x 6 columns], token_table=      Topic      Freq    Term\n",
       "term                         \n",
       "6092  8      0.984834  AAA   \n",
       "7216  9      0.994615  ADL   \n",
       "3220  3      0.013067  AMA   \n",
       "3220  8      0.980027  AMA   \n",
       "2248  6      0.993740  ATF   \n",
       "...  ..           ...  ...   \n",
       "407   8      0.028539  wrong \n",
       "407   9      0.003936  wrong \n",
       "407   10     0.108252  wrong \n",
       "5208  10     0.997794  xterm \n",
       "5656  8      0.986532  xxdate\n",
       "\n",
       "[2095 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda, doc_term_matrix, dictionary, sort_topics=False)\n",
    "vis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test on unseen documents \n",
    "\n",
    "In this particular data, we already know the label for each article. In this exercise, you will examine whether your LDA model is able to assign reasonable topics to unseen documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\\nSubject: Need info on 88-89 Bonneville\\nOrganization: University at Buffalo\\nLines: 10\\nNews-Software: VAX/VMS VNEWS 1.41\\nNntp-Posting-Host: ubvmsd.cc.buffalo.edu\\n\\n\\n I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy.\\n\\n\\t\\t\\tNeil Gandler\\n</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: Rick Miller &lt;rick@ee.uwm.edu&gt;\\nSubject: X-Face?\\nOrganization: Just me.\\nLines: 17\\nDistribution: world\\nNNTP-Posting-Host: 129.89.2.33\\nSummary: Go ahead... swamp me.  &lt;EEP!&gt;\\n\\nI'm not familiar at all with the format of these \"X-Face:\" thingies, but\\nafter seeing them in some folks' headers, I've *got* to *see* them (and\\nmaybe make one of my own)!\\n\\nI've got \"dpg-view\" on my Linux box (which displays \"uncompressed X-Faces\")\\nand I've managed to compile [un]compface too... but now that I'm *looking*\\nfor them, I can't seem to find any X-Face:'s in anyones news headers!  :-(\\n\\nCould you, would you, please send me your \"X-Face:\" header?\\n\\nI *know* I'll probably get a little swamped, but I can handle it.\\n\\n\\t...I hope.\\n\\nRick Miller  &lt;rick@ee.uwm.edu&gt; | &lt;ricxjo@discus.mil.wi.us&gt;   Ricxjo Muelisto\\nSend a postcard, get one back! | Enposxtigu bildkarton kaj vi ricevos alion!\\n          RICK MILLER // 16203 WOODS // MUSKEGO, WIS. 53150 // USA\\n</td>\n",
       "      <td>5</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: Re: STRONG &amp; weak Atheism\\nOrganization: Mantis Consultants, Cambridge. UK.\\nX-Newsreader: rusnews v1.02\\nLines: 9\\n\\nacooper@mac.cc.macalstr.edu (Turin Turambar, ME Department of Utter Misery) writes:\\n&gt; Did that FAQ ever got modified to re-define strong atheists as not those who\\n&gt; assert the nonexistence of God, but as those who assert that they BELIEVE in \\n&gt; the nonexistence of God?\\n\\nIn a word, yes.\\n\\n\\nmathew\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: bakken@cs.arizona.edu (Dave Bakken)\\nSubject: Re: Saudi clergy condemns debut of human rights group!\\nKeywords: international, non-usa government, government, civil rights, \\tsocial issues, politics\\nOrganization: U of Arizona CS Dept, Tucson\\nLines: 101\\n\\nIn article &lt;benali.737307554@alcor&gt; benali@alcor.concordia.ca ( ILYESS B. BDIRA ) writes:\\n&gt;It looks like Ben Baz's mind and heart are also blind, not only his eyes.\\n&gt;I used to respect him, today I lost the minimal amount of respect that\\n&gt;I struggled to keep for him.\\n&gt;To All Muslim netters: This is the same guy who gave a \"Fatwah\" that\\n&gt;Saudi Arabia can be used by the United Ststes to attack Iraq . \\n\\nThey were attacking the Iraqis to drive them out of Kuwait,\\na country whose citizens have close blood and business ties\\nto Saudi citizens.  And me thinks if the US had not helped out\\nthe Iraqis would have swallowed Saudi Arabia, too (or at \\nleast the eastern oilfields).  And no Muslim country was doing\\nmuch of anything to help liberate Kuwait and protect Saudi\\nArabia; indeed, in some masses of citizens were demonstrating\\nin favor of that butcher Saddam (who killed lotsa Muslims),\\njust because he was killing, raping, and looting relatively\\nrich Muslims and also thumbing his nose at the West.\\n\\nSo how would have *you* defended Saudi Arabia and rolled\\nback the Iraqi invasion, were you in charge of Saudi Arabia???\\n\\n&gt;Fatwah is as legitimate as this one. With that kind of \"Clergy\", it might\\n&gt;be an Islamic duty to separate religion and politics, if religion\\n&gt;means \"official Clergy\".\\n\\nI think that it is a very good idea to not have governments have an\\nofficial religion (de facto or de jure), because with human nature\\nlike it is, the ambitious and not the pious will always be the\\nones who rise to power.  There are just too many people in this\\nworld (or any country) for the citizens to really know if a \\nleader is really devout or if he is just a slick operator.\\n\\n&gt;\\n&gt;  \\tCAIRO, Egypt (UPI) -- The Cairo-based Arab Organization for Human\\n&gt;  Rights (AOHR) Thursday welcomed the establishement last week of the\\n&gt;  Committee for Defense of Legal Rights in Saudi Arabia and said it was\\n&gt;  necessary to have such groups operating in all Arab countries.\\n\\nYou make it sound like these guys are angels, Ilyess.  (In your\\nclarinet posting you edited out some stuff; was it the following???)\\nFriday's New York Times reported that this group definitely is\\nmore conservative than even Sheikh Baz and his followers (who\\nthink that the House of Saud does not rule the country conservatively\\nenough).  The NYT reported that, besides complaining that the\\ngovernment was not conservative enough, they have:\\n\\n\\t- asserted that the (approx. 500,000) Shiites in the Kingdom\\n\\t  are apostates, a charge that under Saudi (and Islamic) law\\n\\t  brings the death penalty.  \\n\\n\\t  Diplomatic guy (Sheikh bin Jibrin), isn't he Ilyess?\\n\\n\\t- called for severe punishment of the 40 or so women who\\n\\t  drove in public a while back to protest the ban on\\n\\t  women driving.  The guy from the group who said this,\\n\\t  Abdelhamoud al-Toweijri, said that these women should\\n\\t  be fired from their jobs, jailed, and branded as\\n\\t  prostitutes.\\n\\n\\t  Is this what you want to see happen, Ilyess?  I've\\n\\t  heard many Muslims say that the ban on women driving\\n\\t  has no basis in the Qur'an, the ahadith, etc.\\n\\t  Yet these folks not only like the ban, they want\\n\\t  these women falsely called prostitutes?  \\n\\n\\t  If I were you, I'd choose my heroes wisely,\\n\\t  Ilyess, not just reflexively rally behind\\n\\t  anyone who hates anyone you hate.\\n\\n\\t- say that women should not be allowed to work.\\n\\n\\t- say that TV and radio are too immoral in the Kingdom.\\n\\nNow, the House of Saud is neither my least nor my most favorite government\\non earth; I think they restrict religious and political reedom a lot, among\\nother things.  I just think that the most likely replacements\\nfor them are going to be a lot worse for the citizens of the country.\\nBut I think the House of Saud is feeling the heat lately.  In the\\nlast six months or so I've read there have been stepped up harassing\\nby the muttawain (religious police---*not* government) of Western women\\nnot fully veiled (something stupid for women to do, IMO, because it\\nsends the wrong signals about your morality).  And I've read that\\nthey've cracked down on the few, home-based expartiate religious\\ngatherings, and even posted rewards in (government-owned) newspapers\\noffering money for anyone who turns in a group of expartiates who\\ndare worship in their homes or any other secret place. So the\\ngovernment has grown even more intolerant to try to take some of\\nthe wind out of the sails of the more-conservative opposition.\\nAs unislamic as some of these things are, they're just a small\\ntaste of what would happen if these guys overthrow the House of\\nSaud, like they're trying to in the long run.\\n\\nIs this really what you (and Rached and others in the general\\nwest-is-evil-zionists-rule-hate-west-or-you-are-a-puppet crowd)\\nwant, Ilyess?\\n\\n--\\nDave Bakken\\n==&gt;\"the President is doing a fine job, but the problem is we don't know what\\n    to do with her husband.\" James Carville (Clinton campaign strategist),2/93\\n==&gt;\"Oh, please call Daddy. Mom's far too busy.\"  Chelsea to nurse, CSPAN, 2/93\\n</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey)\\nSubject: Re: After 2000 years, can we say that Christian Morality is\\nOrganization: sgi\\nLines: 22\\nDistribution: world\\nNNTP-Posting-Host: solntze.wpd.sgi.com\\n\\nIn article &lt;1993Apr21.141259.12012@st-andrews.ac.uk&gt;, nrp@st-andrews.ac.uk (Norman R. Paterson) writes:\\n|&gt; In article &lt;1r2m21$8mo@fido.asd.sgi.com&gt; livesey@solntze.wpd.sgi.com (Jon Livesey) writes:\\n|&gt; &gt;In article &lt;1993Apr19.151902.21216@st-andrews.ac.uk&gt;, nrp@st-andrews.ac.uk (Norman R. Paterson) writes:\\n&gt; &gt;Just as well, then, that I'm not claiming that my own moral system is\\n&gt; &gt;absolute.\\n&gt; &gt;\\n&gt; &gt;jon.\\n&gt; &gt;\\n&gt; &gt;[list of references stretching from here to Alpha Centauri deleted.]\\n&gt;\\n&gt; Jon-\\n&gt;\\n&gt; [and I thought to impress with my references!]\\n&gt;\\n&gt; Ok, so you don't claim to have an absolute moral system.  Do you claim\\n&gt; to have an objective one?  I'll assume your answer is \"yes,\" apologies\\n&gt; if not.\\n\\nI've just spent two solid months arguing that no such thing as an\\nobjective moral system exists.\\n\\njon.\\n</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text  \\\n",
       "0  From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\\nSubject: Need info on 88-89 Bonneville\\nOrganization: University at Buffalo\\nLines: 10\\nNews-Software: VAX/VMS VNEWS 1.41\\nNntp-Posting-Host: ubvmsd.cc.buffalo.edu\\n\\n\\n I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy.\\n\\n\\t\\t\\tNeil Gandler\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "1  From: Rick Miller <rick@ee.uwm.edu>\\nSubject: X-Face?\\nOrganization: Just me.\\nLines: 17\\nDistribution: world\\nNNTP-Posting-Host: 129.89.2.33\\nSummary: Go ahead... swamp me.  <EEP!>\\n\\nI'm not familiar at all with the format of these \"X-Face:\" thingies, but\\nafter seeing them in some folks' headers, I've *got* to *see* them (and\\nmaybe make one of my own)!\\n\\nI've got \"dpg-view\" on my Linux box (which displays \"uncompressed X-Faces\")\\nand I've managed to compile [un]compface too... but now that I'm *looking*\\nfor them, I can't seem to find any X-Face:'s in anyones news headers!  :-(\\n\\nCould you, would you, please send me your \"X-Face:\" header?\\n\\nI *know* I'll probably get a little swamped, but I can handle it.\\n\\n\\t...I hope.\\n\\nRick Miller  <rick@ee.uwm.edu> | <ricxjo@discus.mil.wi.us>   Ricxjo Muelisto\\nSend a postcard, get one back! | Enposxtigu bildkarton kaj vi ricevos alion!\\n          RICK MILLER // 16203 WOODS // MUSKEGO, WIS. 53150 // USA\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "2  From: mathew <mathew@mantis.co.uk>\\nSubject: Re: STRONG & weak Atheism\\nOrganization: Mantis Consultants, Cambridge. UK.\\nX-Newsreader: rusnews v1.02\\nLines: 9\\n\\nacooper@mac.cc.macalstr.edu (Turin Turambar, ME Department of Utter Misery) writes:\\n> Did that FAQ ever got modified to re-define strong atheists as not those who\\n> assert the nonexistence of God, but as those who assert that they BELIEVE in \\n> the nonexistence of God?\\n\\nIn a word, yes.\\n\\n\\nmathew\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "3  From: bakken@cs.arizona.edu (Dave Bakken)\\nSubject: Re: Saudi clergy condemns debut of human rights group!\\nKeywords: international, non-usa government, government, civil rights, \\tsocial issues, politics\\nOrganization: U of Arizona CS Dept, Tucson\\nLines: 101\\n\\nIn article <benali.737307554@alcor> benali@alcor.concordia.ca ( ILYESS B. BDIRA ) writes:\\n>It looks like Ben Baz's mind and heart are also blind, not only his eyes.\\n>I used to respect him, today I lost the minimal amount of respect that\\n>I struggled to keep for him.\\n>To All Muslim netters: This is the same guy who gave a \"Fatwah\" that\\n>Saudi Arabia can be used by the United Ststes to attack Iraq . \\n\\nThey were attacking the Iraqis to drive them out of Kuwait,\\na country whose citizens have close blood and business ties\\nto Saudi citizens.  And me thinks if the US had not helped out\\nthe Iraqis would have swallowed Saudi Arabia, too (or at \\nleast the eastern oilfields).  And no Muslim country was doing\\nmuch of anything to help liberate Kuwait and protect Saudi\\nArabia; indeed, in some masses of citizens were demonstrating\\nin favor of that butcher Saddam (who killed lotsa Muslims),\\njust because he was killing, raping, and looting relatively\\nrich Muslims and also thumbing his nose at the West.\\n\\nSo how would have *you* defended Saudi Arabia and rolled\\nback the Iraqi invasion, were you in charge of Saudi Arabia???\\n\\n>Fatwah is as legitimate as this one. With that kind of \"Clergy\", it might\\n>be an Islamic duty to separate religion and politics, if religion\\n>means \"official Clergy\".\\n\\nI think that it is a very good idea to not have governments have an\\nofficial religion (de facto or de jure), because with human nature\\nlike it is, the ambitious and not the pious will always be the\\nones who rise to power.  There are just too many people in this\\nworld (or any country) for the citizens to really know if a \\nleader is really devout or if he is just a slick operator.\\n\\n>\\n>  \\tCAIRO, Egypt (UPI) -- The Cairo-based Arab Organization for Human\\n>  Rights (AOHR) Thursday welcomed the establishement last week of the\\n>  Committee for Defense of Legal Rights in Saudi Arabia and said it was\\n>  necessary to have such groups operating in all Arab countries.\\n\\nYou make it sound like these guys are angels, Ilyess.  (In your\\nclarinet posting you edited out some stuff; was it the following???)\\nFriday's New York Times reported that this group definitely is\\nmore conservative than even Sheikh Baz and his followers (who\\nthink that the House of Saud does not rule the country conservatively\\nenough).  The NYT reported that, besides complaining that the\\ngovernment was not conservative enough, they have:\\n\\n\\t- asserted that the (approx. 500,000) Shiites in the Kingdom\\n\\t  are apostates, a charge that under Saudi (and Islamic) law\\n\\t  brings the death penalty.  \\n\\n\\t  Diplomatic guy (Sheikh bin Jibrin), isn't he Ilyess?\\n\\n\\t- called for severe punishment of the 40 or so women who\\n\\t  drove in public a while back to protest the ban on\\n\\t  women driving.  The guy from the group who said this,\\n\\t  Abdelhamoud al-Toweijri, said that these women should\\n\\t  be fired from their jobs, jailed, and branded as\\n\\t  prostitutes.\\n\\n\\t  Is this what you want to see happen, Ilyess?  I've\\n\\t  heard many Muslims say that the ban on women driving\\n\\t  has no basis in the Qur'an, the ahadith, etc.\\n\\t  Yet these folks not only like the ban, they want\\n\\t  these women falsely called prostitutes?  \\n\\n\\t  If I were you, I'd choose my heroes wisely,\\n\\t  Ilyess, not just reflexively rally behind\\n\\t  anyone who hates anyone you hate.\\n\\n\\t- say that women should not be allowed to work.\\n\\n\\t- say that TV and radio are too immoral in the Kingdom.\\n\\nNow, the House of Saud is neither my least nor my most favorite government\\non earth; I think they restrict religious and political reedom a lot, among\\nother things.  I just think that the most likely replacements\\nfor them are going to be a lot worse for the citizens of the country.\\nBut I think the House of Saud is feeling the heat lately.  In the\\nlast six months or so I've read there have been stepped up harassing\\nby the muttawain (religious police---*not* government) of Western women\\nnot fully veiled (something stupid for women to do, IMO, because it\\nsends the wrong signals about your morality).  And I've read that\\nthey've cracked down on the few, home-based expartiate religious\\ngatherings, and even posted rewards in (government-owned) newspapers\\noffering money for anyone who turns in a group of expartiates who\\ndare worship in their homes or any other secret place. So the\\ngovernment has grown even more intolerant to try to take some of\\nthe wind out of the sails of the more-conservative opposition.\\nAs unislamic as some of these things are, they're just a small\\ntaste of what would happen if these guys overthrow the House of\\nSaud, like they're trying to in the long run.\\n\\nIs this really what you (and Rached and others in the general\\nwest-is-evil-zionists-rule-hate-west-or-you-are-a-puppet crowd)\\nwant, Ilyess?\\n\\n--\\nDave Bakken\\n==>\"the President is doing a fine job, but the problem is we don't know what\\n    to do with her husband.\" James Carville (Clinton campaign strategist),2/93\\n==>\"Oh, please call Daddy. Mom's far too busy.\"  Chelsea to nurse, CSPAN, 2/93\\n   \n",
       "4  From: livesey@solntze.wpd.sgi.com (Jon Livesey)\\nSubject: Re: After 2000 years, can we say that Christian Morality is\\nOrganization: sgi\\nLines: 22\\nDistribution: world\\nNNTP-Posting-Host: solntze.wpd.sgi.com\\n\\nIn article <1993Apr21.141259.12012@st-andrews.ac.uk>, nrp@st-andrews.ac.uk (Norman R. Paterson) writes:\\n|> In article <1r2m21$8mo@fido.asd.sgi.com> livesey@solntze.wpd.sgi.com (Jon Livesey) writes:\\n|> >In article <1993Apr19.151902.21216@st-andrews.ac.uk>, nrp@st-andrews.ac.uk (Norman R. Paterson) writes:\\n> >Just as well, then, that I'm not claiming that my own moral system is\\n> >absolute.\\n> >\\n> >jon.\\n> >\\n> >[list of references stretching from here to Alpha Centauri deleted.]\\n>\\n> Jon-\\n>\\n> [and I thought to impress with my references!]\\n>\\n> Ok, so you don't claim to have an absolute moral system.  Do you claim\\n> to have an objective one?  I'll assume your answer is \"yes,\" apologies\\n> if not.\\n\\nI've just spent two solid months arguing that no such thing as an\\nobjective moral system exists.\\n\\njon.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "   target            target_name  \n",
       "0  7       rec.autos              \n",
       "1  5       comp.windows.x         \n",
       "2  0       alt.atheism            \n",
       "3  17      talk.politics.mideast  \n",
       "4  19      talk.religion.misc     "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = {'text':[], 'target':[]}\n",
    "data['text'] = newsgroups_test.data\n",
    "data['target_name'] = [newsgroups_test.target_names[target] for target in newsgroups_test.target]\n",
    "data['target'] = [target for target in newsgroups_test.target]\n",
    "test_df = pd.DataFrame(data)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
