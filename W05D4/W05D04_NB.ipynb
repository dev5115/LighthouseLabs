{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lighthouse Labs\n",
    "### W05D04 Naive Bayes\n",
    "Instructor: Socorro Dominguez  \n",
    "February 04, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# And import the libraries\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "%pylab inline\n",
    "# pip install git+git://github.com/mgelbart/plot-classifier.git\n",
    "from plot_classifier import plot_classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfTransformer,\n",
    "    TfidfVectorizer,\n",
    ")\n",
    "\n",
    "# train test split and cross validation\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Second Half Agenda:**\n",
    "* Conditional Probability Review\n",
    "    * Bayes theorem\n",
    "    \n",
    "    \n",
    "* Naive Bayes\n",
    "    * Multionomial\n",
    "    * Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review: Conditional probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Conditional probabilities are a way of using information we have about random variables.\n",
    "- For example, for a fair 6-sided dice, what if we already know the roll is odd, because someone told us. What are the 6 _conditional_ probabilities of each outcome?\n",
    "  - They are: ...\n",
    "- We write conditional probabilities with a vertical bar, `|`. The information we're conditioning on goes after the bar.\n",
    "  - E.g., $P(X=i \\mid \\text{X is odd})$ is a **conditional probability**\n",
    "  - The set of these values form the **conditional distribution**\n",
    "    - Conditional distributions are still probability distributions - they must sum up to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- So, what's the pattern here?\n",
    "  - The conditioning _eliminates some possible outcomes_.\n",
    "  - For the remaining outcomes, we _renormalized_ the distribution.\n",
    "  - That is, we took the proportion of the allowed outcomes that satisfy the event description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional probabilities - formalizing things\n",
    "\n",
    "The key equation with conditional probabilities is\n",
    "\n",
    "$$P(A\\mid B)=\\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "The \"renormalizing\" trick is a consequence of this. \n",
    "\n",
    "Consider, what's the probability of rolling a 6 given that the roll is not 1?\n",
    "\n",
    "- Let $A$ be the roll is a 6\n",
    "- Let $B$ be the roll is a not a 1\n",
    "\n",
    "$$P(A\\mid B)=\\frac{P(A \\cap B)}{P(B)}=\\frac{P(A)}{P(B)}=\\frac{1/6}{5/6}=\\frac{1}{5}$$\n",
    "\n",
    "In this case, we had the simplification that $P(A\\cap B)=P(A)$. This is often not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Brain teaser:** A heritable disease occurs randomly in 10% of the population. If someone has the disease, it is passed on to their children with probability 50%. A mother has 1 healthy child. Given this, what's the conditional probability that the mother has the disease? \n",
    "\n",
    "- Is the answer 10%? Less? More? How do we quantify it?\n",
    "  - Let $M$ be the event that the mother has the disease.\n",
    "  - Let $C$ be the event that the child has the disease.\n",
    "  - We want $P(M\\mid \\textrm{not } C)$. We have $P(M)=0.1$ and $P(\\textrm{not }C\\mid M)=0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Solution:\n",
    "\n",
    "$$P(M \\mid \\textrm{not } C) = \\frac{P(\\textrm{not } C \\mid M)P(M)}{P(\\textrm{not } C)}$$\n",
    "\n",
    "So we still need $P(\\textrm{not } C)$. This could happen in 2 ways (\"law of total probability\")\n",
    "\n",
    "$$P(\\textrm{not } C)=P(\\textrm{not } C \\mid M)P(M) + P(\\textrm{not } C \\mid \\textrm{not } M)P(\\textrm{not } M)$$\n",
    "\n",
    "We know $P(\\textrm{not } M)=1-P(M)=0.9$.   \n",
    "We assume $P( C \\mid \\textrm{not } M)=0.1$ because the child can randomly get the disease like anyone else,   \n",
    "so then $P(\\textrm{not } C \\mid \\textrm{not } M)=1-P( C \\mid \\textrm{not } M)=0.9$. \n",
    "\n",
    "Finally, then, we're left with:\n",
    "\n",
    "$$P(M \\mid \\textrm{not } C) = \\frac{0.5 \\times 0.1}{0.5\\times 0.1 + 0.9 \\times 0.9} = 0.058$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We can get what we need using **Bayes' Theorem**.\n",
    "- We've seen above that, for events $A$ and $B$, $P(A,B)=P(A\\mid B)P(B)$. \n",
    "- We can also write this as $P(A,B)=P(B\\mid A)P(A)$. \n",
    "- Since these are equal, we get the famous Bayes' theorem:\n",
    "​\n",
    "$$P(A\\mid B)=\\frac{P(B\\mid A)P(A)}{P(B)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If curious, you should also review:\n",
    "- Law of Total Probability  $P(X=x)=\\sum_y P(X=x\\mid Y=y)P(Y=y)$\n",
    "- Conditional Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Naive Bayes\n",
    "\n",
    "- For years, best spam filtering methods used naive Bayes.\n",
    "- Our first probabilistic classifier where we think of learning as a problem of statistical inference.\n",
    "\n",
    "- Classification technique based on Bayes’ Theorem **with an assumption of independence among predictors** - hence the Naive. \n",
    "    - The presence of a particular feature in a class is unrelated to the presence of any other feature.\n",
    "\n",
    "E.g. You receive a spam mail that contains the words \"Money\", \"URGENT!\", \"Prize!\". Even if these features depend on each other or others, all of these properties independently contribute to the probability that this email is SPAM.\n",
    "\n",
    "- Naive Bayes is easy to build and useful for very large data sets. \n",
    "\n",
    "- Naive Bayes outperforms even highly sophisticated classification methods and works well with text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "\n",
    "Before understanding the theory, let's try `scikit-learn`'s implementation of Naive Bayes on Kaggle's [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### We will use `CountVectorizer` to get bag-of-words (BOW) representation\n",
    "\n",
    "- So we used `CountVectorizer` to convert text data into feature vectors where\n",
    "    - each feature is a unique word in the text  \n",
    "    - each feature value represents the frequency or presence/absence of the word in the given message         \n",
    "    \n",
    "<img src='./images/bag-of-words.png' width=\"800\">\n",
    "\n",
    "[Source](https://web.stanford.edu/~jurafsky/slp3/4.pdf)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sms_df = pd.read_csv(\"data/spam.csv\", encoding=\"latin-1\")\n",
    "sms_df = sms_df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "sms_df = sms_df.rename(columns={\"v1\": \"target\", \"v2\": \"sms\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(sms_df, test_size=0.2, random_state=123)\n",
    "X_train, y_train = train_df[\"sms\"], train_df[\"target\"]\n",
    "X_test, y_test = test_df[\"sms\"], test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>ham</td>\n",
       "      <td>It took Mr owl 3 licks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well there's a pattern emerging of my friends telling me to drive up and come smoke with them and then telling me that I'm a weed fiend/make them smoke too much/impede their doing other things so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i thought so. Thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! Your mobile number *************** WON a å£2000 Bonus Caller prize on 10/06/03! This is the 2nd attempt to reach you! Call 09066368753 ASAP! Box 97N7QP, 150ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aiyah sorry lor... I watch tv watch until i forgot 2 check my phone.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  \\\n",
       "385     ham   \n",
       "4003    ham   \n",
       "1283    ham   \n",
       "2327   spam   \n",
       "1103    ham   \n",
       "\n",
       "                                                                                                                                                                                                          sms  \n",
       "385                                                                                                                                                                                    It took Mr owl 3 licks  \n",
       "4003  Well there's a pattern emerging of my friends telling me to drive up and come smoke with them and then telling me that I'm a weed fiend/make them smoke too much/impede their doing other things so ...  \n",
       "1283                                                                                                                                                                                Yes i thought so. Thanks.  \n",
       "2327                                  URGENT! Your mobile number *************** WON a å£2000 Bonus Caller prize on 10/06/03! This is the 2nd attempt to reach you! Call 09066368753 ASAP! Box 97N7QP, 150ppm  \n",
       "1103                                                                                                                                     Aiyah sorry lor... I watch tv watch until i forgot 2 check my phone.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc.:  0.9933\n",
      "Valid Acc.:  0.9865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipe_nb = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_nb.fit(X_train, y_train)\n",
    "print(\"Training Acc.: \", round(pipe_nb.score(X_train,y_train),4))\n",
    "print(\"Valid Acc.: \", round(pipe_nb.score(X_test,y_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes `predict`\n",
    "\n",
    "- Given a new message, we want to predict whether it's spam or non spam (ham).\n",
    "- Example: Predict whether the following message is spam or non spam (ham). \n",
    "> \"URGENT! Free!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_test = [\"URGENT! Free!!\", \"I like Socorro's classes!\"]\n",
    "pipe_nb.predict(deploy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probabilistic classifiers: `predict` by hand \n",
    "\n",
    "- What's it's doing under the hood? \n",
    "- Let's look at an example with a toy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X = [\n",
    "    \"URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!\",\n",
    "    \"Lol you are always so convincing.\",\n",
    "    \"Block 2 has interesting courses.\",\n",
    "    \"URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!\",\n",
    "    \"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!\",\n",
    "    \"Block 2 has been interesting so far.\",\n",
    "]\n",
    "y = [\"spam\", \"non spam\", \"non spam\", \"spam\", \"spam\", \"non spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pipe_nb_toy = make_pipeline(CountVectorizer(max_features = 4, stop_words='english'), MultinomialNB())\n",
    "pipe_nb_toy.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "data = pipe_nb_toy['countvectorizer'].transform(X)\n",
    "train_bow_df = pd.DataFrame(data.toarray(), columns=pipe_nb_toy['countvectorizer'].get_feature_names(), index=X)\n",
    "train_bow_df['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has interesting courses.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has been interesting so far.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              block  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      0   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  1   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       0   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              1   \n",
       "\n",
       "                                                                                                              free  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                     0   \n",
       "Lol you are always so convincing.                                                                                0   \n",
       "Block 2 has interesting courses.                                                                                 0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                      1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!     1   \n",
       "Block 2 has been interesting so far.                                                                             0   \n",
       "\n",
       "                                                                                                              prize  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      1   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              0   \n",
       "\n",
       "                                                                                                              urgent  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                       1   \n",
       "Lol you are always so convincing.                                                                                  0   \n",
       "Block 2 has interesting courses.                                                                                   0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                        1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!       0   \n",
       "Block 2 has been interesting so far.                                                                               0   \n",
       "\n",
       "                                                                                                                target  \n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      spam  \n",
       "Lol you are always so convincing.                                                                             non spam  \n",
       "Block 2 has interesting courses.                                                                              non spam  \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       spam  \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      spam  \n",
       "Block 2 has been interesting so far.                                                                          non spam  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose we are given text messages in `deploy_test` and we want to find the targets for these examples, how do we do it using naive Bayes?\n",
    "\n",
    "First, let's get numeric representation of our text messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>urgent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT! Free!!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like Week 5 block better.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             block  free  prize  urgent\n",
       "URGENT! Free!!                   0     1      0       1\n",
       "I like Week 5 block better.      1     0      0       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_test = [\"URGENT! Free!!\", \"I like Week 5 block better.\"]\n",
    "data = pipe_nb_toy['countvectorizer'].transform(deploy_test).toarray()\n",
    "bow_df = pd.DataFrame(data, columns=pipe_nb_toy['countvectorizer'].get_feature_names(), index=deploy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>urgent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT! Free!!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like Week 5 block better.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             block  free  prize  urgent\n",
       "URGENT! Free!!                   0     1      0       1\n",
       "I like Week 5 block better.      1     0      0       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes prediction idea\n",
    "\n",
    "Suppose we want to predict whether the following message is \"spam\" or \"non spam\".\n",
    "> \"URGENT! Free!!\"\n",
    "\n",
    "Representation of the message: `[0, 1, 0, 1]`\n",
    "\n",
    "To predict the correct class, naive Bayes calculates the following probability scores. \n",
    "\n",
    "- $P(\\text{spam} \\mid \\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent=1})$ \n",
    "- $P(\\text{non spam} \\mid  \\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent=1})$\n",
    "- Picks the label with higher probability scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applying Bayes' theorem \n",
    "\n",
    "Uses Bayes' theorem to calculate probabilities:\n",
    "\n",
    "$$P(A \\mid B) = \\frac{P(B \\mid A) \\times P(A)}{P(B)}$$\n",
    "\n",
    "$$P(\\text{spam} \\mid \\text{message})= \\frac{P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{spam}) \\times P(\\text{spam})}{P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent=1})}$$\n",
    "\n",
    "$$P(\\text{non spam} \\mid \\text{message}) = \\frac{P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{non spam}) \\times P( \\text{non spam})}{P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent=1})}$$\n",
    "\n",
    "- $P(\\text{message})$: marginal probability that a message has the given set of words \n",
    "    - Hard to calculate but can be ignored in our scenario as it occurs in the denominator for both $P(\\text{spam} \\mid \\text{message})$ and $P(\\text{non spam} \\mid \\text{message})$.\n",
    "    - So we ignore the denominator in both cases. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's focus on $P(\\text{spam} \\mid \\text{message})$\n",
    "\n",
    "- After ignoring the denominator: \n",
    "$$P(\\text{spam} \\mid \\text{message}) \\propto P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{spam}) \\times P(\\text{spam})$$\n",
    "\n",
    "- To calculate $P(\\text{spam} \\mid \\text{message})$, we need:  \n",
    "    - $P(\\text{spam})$: marginal probability that a message is spam\n",
    "    - $P(\\text{message}\\mid\\text{spam})$: conditional probability that message has words $w_1, w_2, \\dots, w_d$, given that it is spam.\n",
    "        - Hard to calculate because it would require huge numbers of parameters and impossibly large training sets. But we need it. \n",
    "        - with $d$ binary features, how many possible \"text messages\" are there?\n",
    "        - we cannot possibly have access to all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes' approximation to calculate $P(\\text{message}|\\text{spam})$\n",
    "\n",
    "- A common assmption is **naive Bayes** assumption, which states that **features are independent, conditioned on the target**. \n",
    "    - Example: In our spam classification example, **once you know that a message is spam**, the probability that the word \"urgent\" appears is independent of whether \"free\" also appeared. \n",
    "    \n",
    "- We can write this mathematically as \n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "& P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{spam}) \\\\\n",
    "&\\approx P(\\text{block} = 0 \\mid \\text{spam}) \\times P(\\text{free} = 1 \\mid \\text{spam}) \\times P(\\text{prize} = 0 \\mid \\text{spam}) \\times P(\\text{urgent} = 1 \\mid \\text{spam})\n",
    "\\end{split}\n",
    "\\end{equation}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes' approximation\n",
    "\n",
    "- In general, \n",
    "$$P(\\text{message} \\mid \\text{spam}) = P(w_1, w_2, . . . , w_d \\mid \\text{spam}) \\approx \\prod_{i=1}^{d}P(w_i \\mid \\text{spam})$$\n",
    "\n",
    "$$P(\\text{message} \\mid \\text{non spam}) = P(w_1, w_2, . . . , w_d \\mid \\text{non spam}) \\approx \\prod_{i=1}^{d}P(w_i \\mid \\text{non spam})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Going back to estimating $P(\\text{spam} \\mid \\text{message})$\n",
    "\n",
    "With naive Bayes' assumption, to calculate $P(\\text{spam} \\mid \\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1)$, we need the following:  \n",
    "1. Prior probability: $P(\\text{spam})$ \n",
    "2. Conditional probabilities: \n",
    "    1. $P(\\text{block} = 0 \\mid \\text{spam})$\n",
    "    2. $P(\\text{free} = 1 \\mid \\text{spam})$\n",
    "    3. $P(\\text{prize} = 0 \\mid \\text{spam})$\n",
    "    4. $P(\\text{urgent} = 1 \\mid \\text{spam})$\n",
    "\n",
    "We use our training data to calculate these probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has interesting courses.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has been interesting so far.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              block  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      0   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  1   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       0   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              1   \n",
       "\n",
       "                                                                                                              free  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                     0   \n",
       "Lol you are always so convincing.                                                                                0   \n",
       "Block 2 has interesting courses.                                                                                 0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                      1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!     1   \n",
       "Block 2 has been interesting so far.                                                                             0   \n",
       "\n",
       "                                                                                                              prize  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      1   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              0   \n",
       "\n",
       "                                                                                                              urgent  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                       1   \n",
       "Lol you are always so convincing.                                                                                  0   \n",
       "Block 2 has interesting courses.                                                                                   0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                        1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!       0   \n",
       "Block 2 has been interesting so far.                                                                               0   \n",
       "\n",
       "                                                                                                                target  \n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      spam  \n",
       "Lol you are always so convincing.                                                                             non spam  \n",
       "Block 2 has interesting courses.                                                                              non spam  \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       spam  \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      spam  \n",
       "Block 2 has been interesting so far.                                                                          non spam  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Prior probability\n",
    "    - $P(\\text{spam}) = 3/6$\n",
    "    \n",
    "- Conditional probabilities\n",
    "    - What is $P(\\text{block} = 0 \\mid \\text{spam})$? \n",
    "        - Given target is spam, how often \"block\" = 0? $3/3$\n",
    "    - $P(\\text{free} = 1 \\mid \\text{spam}) = 2/3$ \n",
    "    - $P(\\text{prize} = 0 \\mid \\text{spam}) = 1/3$\n",
    "    - $P(\\text{urgent} = 1 \\mid \\text{spam}) = 2/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimating $P(\\text{spam} \\mid \\text{message})$\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\text{spam} \\mid \\text{message}) &\\propto P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{spam}) \\times P(\\text{spam})\\\\\n",
    "&\\propto P(\\text{block} = 0 \\mid \\text{spam}) \\times P(\\text{free} = 1 \\mid \\text{spam}) \\\\\n",
    "& \\times P(\\text{prize} = 0 \\mid \\text{spam}) \\times P(\\text{urgent} = 1 \\mid \\text{spam}) \\times P(\\text{spam})\\\\\n",
    "&\\propto 3/3 \\times 2/3 \\times 1/3 \\times 2/3 \\times 3/6\\\\\n",
    "\\end{split}\n",
    "\\end{equation}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "spam_prior = 3/6\n",
    "block0_spam = 3/3\n",
    "free1_spam = 2/3\n",
    "prize0_spam = 1/3\n",
    "urgent1_spam = 2/3\n",
    "spam_prior * block0_spam * free1_spam * prize0_spam * urgent1_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's estimate $P(\\text{non spam} \\mid \\text{message})$\n",
    "\n",
    "With naive Bayes' assumption, to calculate $P(\\text{non spam} \\mid \\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1)$, we need the following:  \n",
    "1. Prior probability: $P(\\text{non spam})$ \n",
    "2. Conditional probabilities: \n",
    "    1. $P(\\text{block} = 0 \\mid \\text{non spam})$\n",
    "    2. $P(\\text{free} = 1 \\mid \\text{non spam})$\n",
    "    3. $P(\\text{prize} = 0 \\mid \\text{non spam})$\n",
    "    4. $P(\\text{urgent} = 1 \\mid \\text{non spam})$\n",
    "\n",
    "Again we use the data to calculate these probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Prior probability \n",
    "    - $P(\\text{non spam}) = 3/6$\n",
    "\n",
    "- Conditional probabilities \n",
    "    - What is $P(\\text{block} = 0 \\mid \\text{non spam})$? \n",
    "        - Given target is non spam, how often \"block\" = 0? $1/3$\n",
    "    - $P(\\text{free} = 1 \\mid \\text{non spam}) = 0/3$ \n",
    "    - $P(\\text{prize} = 0 \\mid \\text{non spam}) = 3/3$\n",
    "    - $P(\\text{urgent} = 1 \\mid \\text{non spam}) = 0/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimating $P(\\text{non spam} \\mid \\text{message})$\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\text{non spam} \\mid \\text{message}) &\\propto P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{non spam}) \\times P(\\text{non spam})\\\\\n",
    "&\\propto P(\\text{block} = 0 \\mid \\text{non spam}) \\times P(\\text{free} = 1 \\mid \\text{non spam}) \\\\\n",
    "& \\times P(\\text{prize} = 0 \\mid \\text{non spam}) \\times P(\\text{urgent} = 1 \\mid \\text{non spam}) \\times P(\\text{non spam})\\\\\n",
    "&\\propto 1/3 \\times 0 \\times 3/3 \\times 0 \\times 1/3\\\\\n",
    "\\end{split}\n",
    "\\end{equation}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_spam_prior = 3/6\n",
    "block0_non_spam = 0/3\n",
    "free1_non_spam = 1/3\n",
    "prize0_non_spam = 1/3\n",
    "urgent1_non_spam = 2/3\n",
    "non_spam_prior * block0_non_spam * free1_non_spam * prize0_non_spam * urgent1_non_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes prediction\n",
    "\n",
    "Since $(\\text{spam} \\mid \\text{message})$ (0.074) is proportional to a larger number compared to $(\\text{non spam} \\mid \\text{message})$ (0), we predict $spam$! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. `predict_proba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is our toy pipeline's prediction? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "deploy_test = [\"URGENT! Free!!\"]\n",
    "pipe_nb_toy.predict(deploy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier `predict_proba`\n",
    "- So far we have been looking into binary predictions but often a more granular information is useful. \n",
    "- Naive Bayes classifier gives you probability estimates for each class and we can get this information using `predict_proba` method of the classifier.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb_toy.predict_proba(deploy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb_toy.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: The classifier is \"76% confident\" that the class is spam! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting probabilities\n",
    "\n",
    "- We have a new and useful method, `predict_proba`.\n",
    "- `predict` returns the class with the highest probability.\n",
    "- `predict_proba` gives us the actual probability scores. \n",
    "- Looking at the probabilities can help us understand the model.\n",
    "- We can find the spam messages where our classifier is most confident and least confident. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes classifier `fit`\n",
    "\n",
    "- Calculate prior probabilities and conditional probabilities for each feature given each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that when we estimated probabilities in our toy example (e.g., $P(\\text{word} \\mid spam)$), we happened to have each feature value as either 0 or 1, i.e., just the existence of a word in the document's bag of words. We computed $P(\\text{word} \\mid spam)$ as a fraction of times the word appears among all words in all messages of the spam class. If we want to work with frequencies instead of existence, we first concatenate all documents with that class (e.g., spam class) into one big \"class c\" text. Then we use the frequency of the word (e.g., _urgent_ below) in this concatenated document to give a (maximum likelihood) estimate of the probability:\n",
    "\n",
    "$$P(\\text{urgent} \\mid \\text{spam}) = \\frac{Count(\\text{urgent}, \\text{spam})}{\\sum_{w \\in vocabulary} Count(w, \\text{spam})}$$ \n",
    "\n",
    "$$P(\\text{urgent} \\mid \\text{spam}) = \\frac{\\text{how often _urgent_ occurs with spam}}{\\text{total number of tokens (all occurrences of all words) in spam}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recall that when we worked through a toy example by hand, we estimated\n",
    "    - $P(\\text{non spam} \\mid \\text{message}) \\propto 0$\n",
    "    - $P(\\text{spam} \\mid \\text{message}) \\propto 0.074$\n",
    "- Why don't `predict_proba` scores match with the probability scores we calculated before? \n",
    "- The scores we computed are not normalized. Remember that we ignored the denominator.\n",
    "- These ones are normalized so that they sum to 1.\n",
    "- The model is using something called \"smoothing\" to avoid the problem of zero probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb_toy.predict_proba(deploy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Laplace smoothing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Remember when we calculated $P(\\text{non spam} \\mid \\text{message})$, some of our conditional probabilities were zero. \n",
    "    - $P(\\text{free} = 1 \\mid \\text{non spam}) = 0/3$ \n",
    "    - $P(\\text{urgent} = 1 \\mid \\text{non spam}) = 0/3$\n",
    "\n",
    "- Naive Bayes naively multiplies all the feature likelihoods together, and if any of the terms is zero, it's going to void all other evidence and the probability of the class is going to be zero. \n",
    "- Sounds worrisome! \n",
    "- We have limited data and if we do not see a feature occurring with a class, it doesn't mean it would never occur with that class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A simplest solution: Laplace smoothing\n",
    "\n",
    "- The simplest way to avoid zero probabilities is to add one to all the counts.\n",
    "- All the counts that used to be zero will now have a count of 1, the counts of 1 will be 2, and so on. \n",
    "- In `scikit-learn` we control it using hyperparameter `alpha` (by default `alpha=1.0`). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our previous bag of words representation becomes like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pipe_nb_toy['countvectorizer'].transform(X)\n",
    "train_bow_df = pd.DataFrame(data.toarray() + 1, columns=pipe_nb_toy['countvectorizer'].get_feature_names(), index=X)\n",
    "train_bow_df['target'] = y\n",
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the counts \n",
    "\n",
    "Note that the following calculations would change now with updated counts now: \n",
    "\n",
    "$$P(\\text{word} \\mid \\text{spam}) = \\frac{Count(\\text{word}, \\text{spam}) + 1}{\\sum_{w \\in vocabulary} Count(w, \\text{spam}) + |vocabulary|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `alpha` hyperparameter and the fundamental tradeoff \n",
    "\n",
    "- High alpha $\\rightarrow$ underfitting\n",
    "    - means we are adding large counts to everything and so we are diluting the data\n",
    "- Low alpha $\\rightarrow$ overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Gaussian Naive Bayes\n",
    "\n",
    "- Other datasets has continuous-valued features.\n",
    "- But so far, we've only seen how to use Naive Bayes for discrete features.\n",
    "- We can either discretize our continuous features into discrete bins (with counts), or...\n",
    "- Use _Gaussian_ naive Bayes (read more [here](https://machinelearningmastery.com/naive-bayes-for-machine-learning/) and [here](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes))\n",
    "- Now:\n",
    "    - Assume each feature is normally distributed \n",
    "    - Calculate the mean ($\\mu_k$) and standard deviation ($\\sigma_k$) for each feature for each class\n",
    "    - Use the following equation to calculate the conditional probability of observing feature value $v$ in class $C_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/gaus_nb.png' width=\"400\">\n",
    "\n",
    "\n",
    "Source: [Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gaussian naive Bayes assumes normality\n",
    "    - Are our features normal?\n",
    "    - Not really but in practice we transform our data to try and make it more normal\n",
    "    - Scikit-learn provides the `PowerTransformer()` for this process\n",
    "    - From the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer): \"*...Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like.*\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General comments on naive Bayes\n",
    "\n",
    "- Surprising accuracy \n",
    "- A fast and robust way to learn the corresponding parameters\n",
    "- Scales great; learning a naive Bayes classifier is just a matter of counting how many times each attribute co-occurs with each class\n",
    "- Can be easily used for multi-class classification. \n",
    "- It's closely related to linear classifiers we'll see in the next lecture. \n",
    "    - When we take the logarithms, the products turn into summations. \n",
    "- Can provides a informative set of features from which to predict the class (next class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General comments on naive Bayes\n",
    "\n",
    "- Assumes that spammers generate e-mails by picking words at random. It means that sentences have no syntax and content. Is that a fair assumption? \n",
    "    - oversimplification \n",
    "    - sometimes the best theories are the most oversimplified, provided their predictions are accurate, because they explain the most with the least. \n",
    "\n",
    "- Although naive Bayes is known as a decent classifier, it is known to be a **bad estimator**, so the probability outputs from `predict_proba` are not to be taken too seriously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
