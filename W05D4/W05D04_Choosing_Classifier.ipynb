{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lighthouse Labs\n",
    "### W05D04 Comparing Classifiers\n",
    "Instructor: Socorro Dominguez  \n",
    "October 15, 2020\n",
    "\n",
    "**Extra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# For tokenization\n",
    "import nltk\n",
    "# For converting words into frequency counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "The learning objectives are:\n",
    "\n",
    "1. to learn how to use classification methods with `scikit-learn`\n",
    "2. compare and contrast different classification methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and preprocessing\n",
    "\n",
    "We will focus on a task called sentiment analysis. We will assignpositive or negative label to a text based on the sentiment or attitude expressed in it. \n",
    "\n",
    "We will use a subset of 3,000 rows from the [IMDB movie review data set](https://www.kaggle.com/utathya/imdb-review-dataset) (original data is 50,000 examples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read IMDB movie reviews into a pandas DataFrame\n",
    "imdb_df = pd.read_csv('data/imdb_master.csv', encoding = \"ISO-8859-1\")\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Keep pos and neg reviews\n",
    "imdb_df = imdb_df[imdb_df['label'].str.startswith(('pos','neg'))]\n",
    "\n",
    "# Sample 3000 rows from the dataframe. \n",
    "imdb_df_subset = imdb_df.sample(n = 3000)\n",
    "\n",
    "# Convert a collection of text documents to a matrix of token presence or absence. \n",
    "# We are using only 5000 words, English stopwords, and tokenization is done using nltk\n",
    "movie_vec = CountVectorizer(max_features=5000, \n",
    "                            tokenizer=nltk.word_tokenize, \n",
    "                            stop_words='english', \n",
    "                            binary = True)\n",
    "\n",
    "# Create X and y\n",
    "X = movie_vec.fit_transform(imdb_df_subset['review'])\n",
    "y = imdb_df_subset.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of classifiers\n",
    "\n",
    "We will compare different classifiers covered so far in your Lighthouse Journey:\n",
    "  \n",
    "  * $k$-nearest neighbours  \n",
    "  * decision trees\n",
    "  * random forests\n",
    "  * SVM\n",
    "  * Logistic Regression\n",
    "  * naive Bayes  \n",
    "   \n",
    "For each classifier, we are going to use scikit-learn implementation with **default** hyperparameters. \n",
    "\n",
    "For an in-depth analysis, you will have to choose a model and do more work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical comparison\n",
    "\n",
    "Split the dataset into train and test split. Report the results for all classifiers in a table  with 3 columns: Classifier, Train Accuracy, and Test Accuracy. \n",
    "\n",
    "If time allows, let's discuss the following results:\n",
    "  - Are certain classifiers better for certain problems?\n",
    "  - Would you change any of the hyperparameters? \n",
    "  - What about speed? What would you do for a huge data set? \n",
    "  - Any other considerations?\n",
    "  \n",
    "**Note:** because all sklearn classifiers use the name fit/predict structure, you can put your 5 classifiers in a list/dict and iterate over them with a loop. \n",
    "\n",
    "This will probably be easier writing 15 calls to fit and 15 to predict, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {'Classifier':[],\n",
    "                'Train Accuracy':[], \n",
    "                'Test Accuracy':[]\n",
    "               }\n",
    "\n",
    "models = {\n",
    "    'knn'           : KNeighborsClassifier(),\n",
    "    'decision tree' : DecisionTreeClassifier(),\n",
    "    'random forest' : RandomForestClassifier(n_estimators=10),\n",
    "    'SVM'           : SVC(gamma='scale'),\n",
    "    'logistic regression': LogisticRegression(),\n",
    "    'Naive Bayes' : MultinomialNB()\n",
    "}                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on IMBD dataset\n",
      "Fitting knn...\n",
      "Fitting decision tree...\n",
      "Fitting random forest...\n",
      "Fitting SVM...\n",
      "Fitting logistic regression...\n",
      "Fitting Naive Bayes...\n"
     ]
    }
   ],
   "source": [
    "# Divide training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.20,\n",
    "                                                    random_state = 15)\n",
    "\n",
    "print('Working on IMBD dataset')\n",
    "\n",
    "# Looping through models\n",
    "for model_name, model in models.items():\n",
    "    print(\"Fitting %s...\" % model_name)\n",
    "    model.fit(X_train, y_train);\n",
    "    train_accuracy = model.score(X_train, y_train)*100\n",
    "    test_accuracy = model.score(X_test, y_test)*100\n",
    "    results_dict['Classifier'].append(model_name)\n",
    "    results_dict['Train Accuracy'].append(train_accuracy)\n",
    "    results_dict['Test Accuracy'].append(test_accuracy)  \n",
    "    \n",
    "results_df = pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>68.96</td>\n",
       "      <td>58.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>100.00</td>\n",
       "      <td>67.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random forest</td>\n",
       "      <td>99.29</td>\n",
       "      <td>76.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>98.54</td>\n",
       "      <td>84.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>100.00</td>\n",
       "      <td>84.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>92.38</td>\n",
       "      <td>84.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Train Accuracy  Test Accuracy\n",
       "0                  knn           68.96          58.67\n",
       "1        decision tree          100.00          67.50\n",
       "2        random forest           99.29          76.17\n",
       "3                  SVM           98.54          84.83\n",
       "4  logistic regression          100.00          84.50\n",
       "5          Naive Bayes           92.38          84.83"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels in SVM classification\n",
    "\n",
    "1. Let's try the three different kernels: linear, polynomial (with `gamma=0.001`), and RBF. \n",
    "2. Report the train and test accuracies in each case.\n",
    "3. Why do you think `scikit-learn` uses an RBF kernel by default? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "kernel_experiments = {'kernel':[], 'train_accuracy %':[], 'test_accuracy %':[]}\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "\n",
    "for kernel in kernels:\n",
    "    model = SVC(kernel = kernel, degree=2, gamma='scale') \n",
    "    model.fit(X_train, y_train)\n",
    "    train_accuracy = model.score(X_train, y_train)*100\n",
    "    test_accuracy = model.score(X_test, y_test)*100\n",
    "    \n",
    "    kernel_experiments['kernel'].append(kernel)\n",
    "    kernel_experiments['train_accuracy %'].append(train_accuracy)\n",
    "    kernel_experiments['test_accuracy %'].append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>train_accuracy %</th>\n",
       "      <th>test_accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>100.00</td>\n",
       "      <td>84.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>96.46</td>\n",
       "      <td>78.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rbf</td>\n",
       "      <td>98.54</td>\n",
       "      <td>84.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel  train_accuracy %  test_accuracy %\n",
       "0  linear            100.00            84.00\n",
       "1    poly             96.46            78.83\n",
       "2     rbf             98.54            84.83"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_df = pd.DataFrame(kernel_experiments)\n",
    "kernel_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`C` hyperparameters\n",
    "\n",
    "1. Play around with the `C` hyperparameters. Try 5 different values for each of these parameters. \n",
    "2. What effects do they have? Can you relate them to the fundamental tradeoff of ML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "C_experiments = {}\n",
    "C = [10.0**(i-1) for i in range(5)]\n",
    "\n",
    "for c in C:\n",
    "    model = SVC(C = c, gamma='scale')        \n",
    "    model.fit(X_train, y_train)\n",
    "    train_accuracy = model.score(X_train, y_train)*100\n",
    "    test_accuracy = model.score(X_test, y_test)*100\n",
    "    C_experiments[c] = {'train_accuracy':train_accuracy, 'test_accuracy':test_accuracy}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>98.541667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>58.166667</td>\n",
       "      <td>84.833333</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>84.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.1        1.0         10.0        100.0       1000.0\n",
       "train_accuracy  65.000000  98.541667  100.000000  100.000000  100.000000\n",
       "test_accuracy   58.166667  84.833333   84.166667   84.166667   84.166667"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_df = pd.DataFrame(C_experiments)\n",
    "C_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the `C` value also leads to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Being Naive with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_dict = {'Classifier':[],\n",
    "           'Train Accuracy':[], \n",
    "           'Test Accuracy':[]\n",
    "               }\n",
    "\n",
    "nb_models = {'Bernoulli' : BernoulliNB(),\n",
    "             'Multinomial' : MultinomialNB()\n",
    "}                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on IMBD dataset\n",
      "Fitting Bernoulli...\n",
      "Fitting Multinomial...\n"
     ]
    }
   ],
   "source": [
    "# Divide training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.20,\n",
    "                                                    random_state = 15)\n",
    "\n",
    "print('Working on IMBD dataset')\n",
    "\n",
    "# Looping through models\n",
    "for model_name, model in nb_models.items():\n",
    "    print(\"Fitting %s...\" % model_name)\n",
    "    model.fit(X_train, y_train);\n",
    "    train_accuracy = model.score(X_train, y_train)*100\n",
    "    test_accuracy = model.score(X_test, y_test)*100\n",
    "    nb_dict['Classifier'].append(model_name)\n",
    "    nb_dict['Train Accuracy'].append(train_accuracy)\n",
    "    nb_dict['Test Accuracy'].append(test_accuracy)  \n",
    "    \n",
    "nb_results_df = pd.DataFrame(nb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>92.54</td>\n",
       "      <td>85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multinomial</td>\n",
       "      <td>92.38</td>\n",
       "      <td>84.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>92.54</td>\n",
       "      <td>85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multinomial</td>\n",
       "      <td>92.38</td>\n",
       "      <td>84.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>92.54</td>\n",
       "      <td>85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multinomial</td>\n",
       "      <td>92.38</td>\n",
       "      <td>84.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Classifier  Train Accuracy  Test Accuracy\n",
       "0    Bernoulli           92.54          85.00\n",
       "1  Multinomial           92.38          84.83\n",
       "2    Bernoulli           92.54          85.00\n",
       "3  Multinomial           92.38          84.83\n",
       "4    Bernoulli           92.54          85.00\n",
       "5  Multinomial           92.38          84.83"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_results_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_reviews = ['This movie was excellent! The performances were oscar-worthy!',\n",
    "               'Unbelievably disappointing.', \n",
    "               'Full of zany characters and richly applied satire, and some great plot twists',\n",
    "               'This is the greatest screwball comedy ever filmed',\n",
    "               'It was pathetic. The worst part about it was the boxing scenes.', \n",
    "               '''It could have been a great movie. It could have been excellent, \n",
    "                and to all the people who have forgotten about the older, \n",
    "                greater movies before it, will think that as well. \n",
    "                It does have beautiful scenery, some of the best since Lord of the Rings. \n",
    "                The acting is well done, and I really liked the son of the leader of the Samurai.\n",
    "                He was a likeable chap, and I hated to see him die...\n",
    "                But, other than all that, this movie is nothing more than hidden rip-offs.\n",
    "                '''\n",
    "              ]\n",
    "realfake_labels = ['pos', 'neg', 'pos', 'pos', 'neg', 'neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word count encoding of the reviews.  \n",
    "fake_reviews_counts = movie_vec.transform(fake_reviews)\n",
    "fake_reviews_binary = fake_reviews_counts > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the Naive Bayes classifier\n",
    "predictions = model.predict(fake_reviews_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Real(Fake) labels</th>\n",
       "      <th>NB labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie was excellent! The performances were oscar-worthy!</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unbelievably disappointing.</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full of zany characters and richly applied satire, and some great plot twists</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the greatest screwball comedy ever filmed</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was pathetic. The worst part about it was the boxing scenes.</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It could have been a great movie. It could have been excellent, \\n                and to all the people who have forgotten about the older, \\n                greater movies before it, will think that as well. \\n                It does have beautiful scenery, some of the best since Lord of the Rings. \\n                The acting is well done, and I really liked the son of the leader of the Samurai.\\n                He was a likeable chap, and I hated to see him die...\\n                But, other than all that, this movie is nothing more than hidden rip-offs.\\n</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Review  \\\n",
       "0  This movie was excellent! The performances were oscar-worthy!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "1  Unbelievably disappointing.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "2  Full of zany characters and richly applied satire, and some great plot twists                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "3  This is the greatest screwball comedy ever filmed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "4  It was pathetic. The worst part about it was the boxing scenes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "5  It could have been a great movie. It could have been excellent, \\n                and to all the people who have forgotten about the older, \\n                greater movies before it, will think that as well. \\n                It does have beautiful scenery, some of the best since Lord of the Rings. \\n                The acting is well done, and I really liked the son of the leader of the Samurai.\\n                He was a likeable chap, and I hated to see him die...\\n                But, other than all that, this movie is nothing more than hidden rip-offs.\\n                   \n",
       "\n",
       "  Real(Fake) labels NB labels  \n",
       "0  pos               pos       \n",
       "1  neg               neg       \n",
       "2  pos               pos       \n",
       "3  pos               pos       \n",
       "4  neg               neg       \n",
       "5  neg               pos       "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 0)\n",
    "d = {'Review':fake_reviews, 'Real(Fake) labels':realfake_labels, 'NB labels':predictions}\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
